{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.733810310034856,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00366905155017428,
      "grad_norm": 0.3877936601638794,
      "learning_rate": 5.501222493887531e-07,
      "loss": 1.3825,
      "step": 10
    },
    {
      "epoch": 0.00733810310034856,
      "grad_norm": 0.3388456106185913,
      "learning_rate": 1.1613691931540342e-06,
      "loss": 1.3519,
      "step": 20
    },
    {
      "epoch": 0.01100715465052284,
      "grad_norm": 0.34713810682296753,
      "learning_rate": 1.7726161369193154e-06,
      "loss": 1.3608,
      "step": 30
    },
    {
      "epoch": 0.01467620620069712,
      "grad_norm": 0.4064188003540039,
      "learning_rate": 2.3838630806845967e-06,
      "loss": 1.3713,
      "step": 40
    },
    {
      "epoch": 0.0183452577508714,
      "grad_norm": 0.45421141386032104,
      "learning_rate": 2.9951100244498777e-06,
      "loss": 1.3726,
      "step": 50
    },
    {
      "epoch": 0.02201430930104568,
      "grad_norm": 0.4744616746902466,
      "learning_rate": 3.606356968215159e-06,
      "loss": 1.3487,
      "step": 60
    },
    {
      "epoch": 0.025683360851219958,
      "grad_norm": 0.6290422677993774,
      "learning_rate": 4.21760391198044e-06,
      "loss": 1.3523,
      "step": 70
    },
    {
      "epoch": 0.02935241240139424,
      "grad_norm": 0.5566685795783997,
      "learning_rate": 4.828850855745722e-06,
      "loss": 1.3289,
      "step": 80
    },
    {
      "epoch": 0.03302146395156852,
      "grad_norm": 0.46856987476348877,
      "learning_rate": 5.440097799511003e-06,
      "loss": 1.3306,
      "step": 90
    },
    {
      "epoch": 0.0366905155017428,
      "grad_norm": 0.35358479619026184,
      "learning_rate": 6.051344743276284e-06,
      "loss": 1.247,
      "step": 100
    },
    {
      "epoch": 0.04035956705191708,
      "grad_norm": 0.4844614565372467,
      "learning_rate": 6.662591687041565e-06,
      "loss": 1.2218,
      "step": 110
    },
    {
      "epoch": 0.04402861860209136,
      "grad_norm": 0.5792201161384583,
      "learning_rate": 7.273838630806847e-06,
      "loss": 1.2077,
      "step": 120
    },
    {
      "epoch": 0.04769767015226564,
      "grad_norm": 0.38933107256889343,
      "learning_rate": 7.885085574572127e-06,
      "loss": 1.1452,
      "step": 130
    },
    {
      "epoch": 0.051366721702439916,
      "grad_norm": 0.364145427942276,
      "learning_rate": 8.496332518337409e-06,
      "loss": 1.0986,
      "step": 140
    },
    {
      "epoch": 0.0550357732526142,
      "grad_norm": 0.4445214569568634,
      "learning_rate": 9.10757946210269e-06,
      "loss": 1.0758,
      "step": 150
    },
    {
      "epoch": 0.05870482480278848,
      "grad_norm": 0.48486754298210144,
      "learning_rate": 9.718826405867972e-06,
      "loss": 1.0014,
      "step": 160
    },
    {
      "epoch": 0.06237387635296276,
      "grad_norm": 0.33367639780044556,
      "learning_rate": 1.0330073349633253e-05,
      "loss": 0.9749,
      "step": 170
    },
    {
      "epoch": 0.06604292790313704,
      "grad_norm": 0.4073357880115509,
      "learning_rate": 1.0941320293398534e-05,
      "loss": 0.9964,
      "step": 180
    },
    {
      "epoch": 0.06971197945331131,
      "grad_norm": 0.489095002412796,
      "learning_rate": 1.1552567237163816e-05,
      "loss": 0.9409,
      "step": 190
    },
    {
      "epoch": 0.0733810310034856,
      "grad_norm": 0.3971366882324219,
      "learning_rate": 1.2163814180929096e-05,
      "loss": 0.9283,
      "step": 200
    },
    {
      "epoch": 0.07705008255365987,
      "grad_norm": 0.44291526079177856,
      "learning_rate": 1.2775061124694377e-05,
      "loss": 0.8758,
      "step": 210
    },
    {
      "epoch": 0.08071913410383416,
      "grad_norm": 0.6228989362716675,
      "learning_rate": 1.3386308068459657e-05,
      "loss": 0.9017,
      "step": 220
    },
    {
      "epoch": 0.08438818565400844,
      "grad_norm": 0.41784918308258057,
      "learning_rate": 1.3997555012224938e-05,
      "loss": 0.8486,
      "step": 230
    },
    {
      "epoch": 0.08805723720418272,
      "grad_norm": 0.49626976251602173,
      "learning_rate": 1.460880195599022e-05,
      "loss": 0.8642,
      "step": 240
    },
    {
      "epoch": 0.091726288754357,
      "grad_norm": 0.5728238224983215,
      "learning_rate": 1.5220048899755501e-05,
      "loss": 0.8622,
      "step": 250
    },
    {
      "epoch": 0.09539534030453128,
      "grad_norm": 0.468300998210907,
      "learning_rate": 1.583129584352078e-05,
      "loss": 0.8142,
      "step": 260
    },
    {
      "epoch": 0.09906439185470556,
      "grad_norm": 0.6429207921028137,
      "learning_rate": 1.6442542787286064e-05,
      "loss": 0.8135,
      "step": 270
    },
    {
      "epoch": 0.10273344340487983,
      "grad_norm": 0.4333305358886719,
      "learning_rate": 1.7053789731051344e-05,
      "loss": 0.7781,
      "step": 280
    },
    {
      "epoch": 0.10640249495505412,
      "grad_norm": 0.7538961172103882,
      "learning_rate": 1.7665036674816627e-05,
      "loss": 0.7782,
      "step": 290
    },
    {
      "epoch": 0.1100715465052284,
      "grad_norm": 0.5683786869049072,
      "learning_rate": 1.8276283618581907e-05,
      "loss": 0.7574,
      "step": 300
    },
    {
      "epoch": 0.11374059805540268,
      "grad_norm": 0.5173904895782471,
      "learning_rate": 1.888753056234719e-05,
      "loss": 0.7558,
      "step": 310
    },
    {
      "epoch": 0.11740964960557695,
      "grad_norm": 0.6803333163261414,
      "learning_rate": 1.949877750611247e-05,
      "loss": 0.7621,
      "step": 320
    },
    {
      "epoch": 0.12107870115575124,
      "grad_norm": 0.7055644989013672,
      "learning_rate": 2.0110024449877753e-05,
      "loss": 0.7509,
      "step": 330
    },
    {
      "epoch": 0.12474775270592552,
      "grad_norm": 0.6526551842689514,
      "learning_rate": 2.0721271393643033e-05,
      "loss": 0.7612,
      "step": 340
    },
    {
      "epoch": 0.1284168042560998,
      "grad_norm": 1.0160521268844604,
      "learning_rate": 2.1332518337408312e-05,
      "loss": 0.7526,
      "step": 350
    },
    {
      "epoch": 0.13208585580627408,
      "grad_norm": 0.6214171051979065,
      "learning_rate": 2.1943765281173596e-05,
      "loss": 0.7192,
      "step": 360
    },
    {
      "epoch": 0.13575490735644835,
      "grad_norm": 0.6929377317428589,
      "learning_rate": 2.2555012224938875e-05,
      "loss": 0.7006,
      "step": 370
    },
    {
      "epoch": 0.13942395890662262,
      "grad_norm": 0.7169085144996643,
      "learning_rate": 2.316625916870416e-05,
      "loss": 0.6955,
      "step": 380
    },
    {
      "epoch": 0.14309301045679693,
      "grad_norm": 0.8329369425773621,
      "learning_rate": 2.3777506112469438e-05,
      "loss": 0.7199,
      "step": 390
    },
    {
      "epoch": 0.1467620620069712,
      "grad_norm": 0.6524739265441895,
      "learning_rate": 2.438875305623472e-05,
      "loss": 0.6703,
      "step": 400
    },
    {
      "epoch": 0.15043111355714547,
      "grad_norm": 0.7267888784408569,
      "learning_rate": 2.5e-05,
      "loss": 0.6875,
      "step": 410
    },
    {
      "epoch": 0.15410016510731975,
      "grad_norm": 0.6155242323875427,
      "learning_rate": 2.561124694376528e-05,
      "loss": 0.7156,
      "step": 420
    },
    {
      "epoch": 0.15776921665749405,
      "grad_norm": 0.7568008303642273,
      "learning_rate": 2.6222493887530564e-05,
      "loss": 0.6965,
      "step": 430
    },
    {
      "epoch": 0.16143826820766832,
      "grad_norm": 0.6655860543251038,
      "learning_rate": 2.6833740831295844e-05,
      "loss": 0.6546,
      "step": 440
    },
    {
      "epoch": 0.1651073197578426,
      "grad_norm": 1.1648468971252441,
      "learning_rate": 2.7444987775061127e-05,
      "loss": 0.6819,
      "step": 450
    },
    {
      "epoch": 0.16877637130801687,
      "grad_norm": 0.68362957239151,
      "learning_rate": 2.8056234718826407e-05,
      "loss": 0.6855,
      "step": 460
    },
    {
      "epoch": 0.17244542285819114,
      "grad_norm": 0.6543752551078796,
      "learning_rate": 2.866748166259169e-05,
      "loss": 0.645,
      "step": 470
    },
    {
      "epoch": 0.17611447440836545,
      "grad_norm": 0.6918438076972961,
      "learning_rate": 2.927872860635697e-05,
      "loss": 0.6267,
      "step": 480
    },
    {
      "epoch": 0.17978352595853972,
      "grad_norm": 0.7780126333236694,
      "learning_rate": 2.988997555012225e-05,
      "loss": 0.6547,
      "step": 490
    },
    {
      "epoch": 0.183452577508714,
      "grad_norm": 0.6887812614440918,
      "learning_rate": 3.0501222493887533e-05,
      "loss": 0.6507,
      "step": 500
    },
    {
      "epoch": 0.183452577508714,
      "eval_loss": 0.6555390357971191,
      "eval_runtime": 241.4797,
      "eval_samples_per_second": 2.51,
      "eval_steps_per_second": 2.51,
      "step": 500
    },
    {
      "epoch": 0.18712162905888827,
      "grad_norm": 0.756022572517395,
      "learning_rate": 3.1112469437652816e-05,
      "loss": 0.6563,
      "step": 510
    },
    {
      "epoch": 0.19079068060906257,
      "grad_norm": 0.8010755777359009,
      "learning_rate": 3.1723716381418096e-05,
      "loss": 0.662,
      "step": 520
    },
    {
      "epoch": 0.19445973215923684,
      "grad_norm": 0.7894098162651062,
      "learning_rate": 3.2334963325183375e-05,
      "loss": 0.6657,
      "step": 530
    },
    {
      "epoch": 0.19812878370941112,
      "grad_norm": 1.0443938970565796,
      "learning_rate": 3.2946210268948655e-05,
      "loss": 0.6485,
      "step": 540
    },
    {
      "epoch": 0.2017978352595854,
      "grad_norm": 0.8169821500778198,
      "learning_rate": 3.355745721271394e-05,
      "loss": 0.6534,
      "step": 550
    },
    {
      "epoch": 0.20546688680975966,
      "grad_norm": 0.9781677722930908,
      "learning_rate": 3.416870415647922e-05,
      "loss": 0.6669,
      "step": 560
    },
    {
      "epoch": 0.20913593835993396,
      "grad_norm": 0.9551028609275818,
      "learning_rate": 3.47799511002445e-05,
      "loss": 0.638,
      "step": 570
    },
    {
      "epoch": 0.21280498991010824,
      "grad_norm": 0.7600991725921631,
      "learning_rate": 3.539119804400978e-05,
      "loss": 0.6364,
      "step": 580
    },
    {
      "epoch": 0.2164740414602825,
      "grad_norm": 0.8121793866157532,
      "learning_rate": 3.600244498777506e-05,
      "loss": 0.6195,
      "step": 590
    },
    {
      "epoch": 0.2201430930104568,
      "grad_norm": 0.867216944694519,
      "learning_rate": 3.661369193154035e-05,
      "loss": 0.6555,
      "step": 600
    },
    {
      "epoch": 0.2238121445606311,
      "grad_norm": 0.8910418152809143,
      "learning_rate": 3.722493887530563e-05,
      "loss": 0.6377,
      "step": 610
    },
    {
      "epoch": 0.22748119611080536,
      "grad_norm": 0.9751493334770203,
      "learning_rate": 3.783618581907091e-05,
      "loss": 0.6429,
      "step": 620
    },
    {
      "epoch": 0.23115024766097964,
      "grad_norm": 0.7061278223991394,
      "learning_rate": 3.8447432762836186e-05,
      "loss": 0.6308,
      "step": 630
    },
    {
      "epoch": 0.2348192992111539,
      "grad_norm": 1.1142009496688843,
      "learning_rate": 3.905867970660147e-05,
      "loss": 0.6392,
      "step": 640
    },
    {
      "epoch": 0.2384883507613282,
      "grad_norm": 0.9368607401847839,
      "learning_rate": 3.966992665036675e-05,
      "loss": 0.618,
      "step": 650
    },
    {
      "epoch": 0.24215740231150248,
      "grad_norm": 0.8624376058578491,
      "learning_rate": 4.028117359413203e-05,
      "loss": 0.6153,
      "step": 660
    },
    {
      "epoch": 0.24582645386167676,
      "grad_norm": 0.7143048048019409,
      "learning_rate": 4.089242053789731e-05,
      "loss": 0.593,
      "step": 670
    },
    {
      "epoch": 0.24949550541185103,
      "grad_norm": 0.9557223320007324,
      "learning_rate": 4.150366748166259e-05,
      "loss": 0.6289,
      "step": 680
    },
    {
      "epoch": 0.25316455696202533,
      "grad_norm": 0.6870782375335693,
      "learning_rate": 4.211491442542788e-05,
      "loss": 0.6068,
      "step": 690
    },
    {
      "epoch": 0.2568336085121996,
      "grad_norm": 0.8731458187103271,
      "learning_rate": 4.272616136919316e-05,
      "loss": 0.6428,
      "step": 700
    },
    {
      "epoch": 0.2605026600623739,
      "grad_norm": 1.0079413652420044,
      "learning_rate": 4.333740831295844e-05,
      "loss": 0.6517,
      "step": 710
    },
    {
      "epoch": 0.26417171161254815,
      "grad_norm": 0.8572641015052795,
      "learning_rate": 4.394865525672372e-05,
      "loss": 0.5917,
      "step": 720
    },
    {
      "epoch": 0.26784076316272243,
      "grad_norm": 0.8210773468017578,
      "learning_rate": 4.4559902200489e-05,
      "loss": 0.5923,
      "step": 730
    },
    {
      "epoch": 0.2715098147128967,
      "grad_norm": 1.3339871168136597,
      "learning_rate": 4.5171149144254284e-05,
      "loss": 0.6521,
      "step": 740
    },
    {
      "epoch": 0.275178866263071,
      "grad_norm": 0.8313754200935364,
      "learning_rate": 4.5782396088019564e-05,
      "loss": 0.6547,
      "step": 750
    },
    {
      "epoch": 0.27884791781324525,
      "grad_norm": 0.8662818670272827,
      "learning_rate": 4.6393643031784844e-05,
      "loss": 0.639,
      "step": 760
    },
    {
      "epoch": 0.2825169693634196,
      "grad_norm": 0.821679949760437,
      "learning_rate": 4.7004889975550123e-05,
      "loss": 0.6073,
      "step": 770
    },
    {
      "epoch": 0.28618602091359385,
      "grad_norm": 0.9807654619216919,
      "learning_rate": 4.761613691931541e-05,
      "loss": 0.5926,
      "step": 780
    },
    {
      "epoch": 0.2898550724637681,
      "grad_norm": 1.052196741104126,
      "learning_rate": 4.822738386308069e-05,
      "loss": 0.6106,
      "step": 790
    },
    {
      "epoch": 0.2935241240139424,
      "grad_norm": 0.9126512408256531,
      "learning_rate": 4.883863080684597e-05,
      "loss": 0.608,
      "step": 800
    },
    {
      "epoch": 0.2971931755641167,
      "grad_norm": 0.7981895208358765,
      "learning_rate": 4.944987775061125e-05,
      "loss": 0.5572,
      "step": 810
    },
    {
      "epoch": 0.30086222711429095,
      "grad_norm": 1.0812228918075562,
      "learning_rate": 4.999999772252235e-05,
      "loss": 0.5998,
      "step": 820
    },
    {
      "epoch": 0.3045312786644652,
      "grad_norm": 1.0476435422897339,
      "learning_rate": 4.999972442570682e-05,
      "loss": 0.6393,
      "step": 830
    },
    {
      "epoch": 0.3082003302146395,
      "grad_norm": 0.8512653708457947,
      "learning_rate": 4.9998995639067493e-05,
      "loss": 0.6259,
      "step": 840
    },
    {
      "epoch": 0.31186938176481377,
      "grad_norm": 0.8550739288330078,
      "learning_rate": 4.99978113758827e-05,
      "loss": 0.5873,
      "step": 850
    },
    {
      "epoch": 0.3155384333149881,
      "grad_norm": 0.8724313378334045,
      "learning_rate": 4.999617165772949e-05,
      "loss": 0.579,
      "step": 860
    },
    {
      "epoch": 0.31920748486516237,
      "grad_norm": 0.8744262456893921,
      "learning_rate": 4.999407651448318e-05,
      "loss": 0.5672,
      "step": 870
    },
    {
      "epoch": 0.32287653641533665,
      "grad_norm": 0.7632190585136414,
      "learning_rate": 4.999152598431685e-05,
      "loss": 0.6068,
      "step": 880
    },
    {
      "epoch": 0.3265455879655109,
      "grad_norm": 0.8382863998413086,
      "learning_rate": 4.9988520113700626e-05,
      "loss": 0.5769,
      "step": 890
    },
    {
      "epoch": 0.3302146395156852,
      "grad_norm": 0.862323522567749,
      "learning_rate": 4.998505895740087e-05,
      "loss": 0.5912,
      "step": 900
    },
    {
      "epoch": 0.33388369106585947,
      "grad_norm": 1.0637726783752441,
      "learning_rate": 4.9981142578479115e-05,
      "loss": 0.6381,
      "step": 910
    },
    {
      "epoch": 0.33755274261603374,
      "grad_norm": 1.0006047487258911,
      "learning_rate": 4.997677104829098e-05,
      "loss": 0.5963,
      "step": 920
    },
    {
      "epoch": 0.341221794166208,
      "grad_norm": 0.7697986960411072,
      "learning_rate": 4.9971944446484865e-05,
      "loss": 0.6031,
      "step": 930
    },
    {
      "epoch": 0.3448908457163823,
      "grad_norm": 0.9483711123466492,
      "learning_rate": 4.996666286100043e-05,
      "loss": 0.5832,
      "step": 940
    },
    {
      "epoch": 0.3485598972665566,
      "grad_norm": 0.8196538090705872,
      "learning_rate": 4.99609263880671e-05,
      "loss": 0.582,
      "step": 950
    },
    {
      "epoch": 0.3522289488167309,
      "grad_norm": 0.9448139071464539,
      "learning_rate": 4.995473513220221e-05,
      "loss": 0.597,
      "step": 960
    },
    {
      "epoch": 0.35589800036690517,
      "grad_norm": 0.9995883107185364,
      "learning_rate": 4.994808920620918e-05,
      "loss": 0.5681,
      "step": 970
    },
    {
      "epoch": 0.35956705191707944,
      "grad_norm": 0.7747149467468262,
      "learning_rate": 4.99409887311754e-05,
      "loss": 0.6065,
      "step": 980
    },
    {
      "epoch": 0.3632361034672537,
      "grad_norm": 0.8338237404823303,
      "learning_rate": 4.9933433836470056e-05,
      "loss": 0.5884,
      "step": 990
    },
    {
      "epoch": 0.366905155017428,
      "grad_norm": 1.0708411931991577,
      "learning_rate": 4.992542465974178e-05,
      "loss": 0.5889,
      "step": 1000
    },
    {
      "epoch": 0.366905155017428,
      "eval_loss": 0.5883203744888306,
      "eval_runtime": 237.62,
      "eval_samples_per_second": 2.55,
      "eval_steps_per_second": 2.55,
      "step": 1000
    },
    {
      "epoch": 0.37057420656760226,
      "grad_norm": 0.74204021692276,
      "learning_rate": 4.991696134691613e-05,
      "loss": 0.6142,
      "step": 1010
    },
    {
      "epoch": 0.37424325811777653,
      "grad_norm": 1.1142209768295288,
      "learning_rate": 4.99080440521929e-05,
      "loss": 0.5405,
      "step": 1020
    },
    {
      "epoch": 0.3779123096679508,
      "grad_norm": 0.9425484538078308,
      "learning_rate": 4.9898672938043385e-05,
      "loss": 0.6005,
      "step": 1030
    },
    {
      "epoch": 0.38158136121812514,
      "grad_norm": 0.7661627531051636,
      "learning_rate": 4.988884817520732e-05,
      "loss": 0.5774,
      "step": 1040
    },
    {
      "epoch": 0.3852504127682994,
      "grad_norm": 0.8633294105529785,
      "learning_rate": 4.98785699426899e-05,
      "loss": 0.5964,
      "step": 1050
    },
    {
      "epoch": 0.3889194643184737,
      "grad_norm": 0.8688271641731262,
      "learning_rate": 4.986783842775836e-05,
      "loss": 0.5866,
      "step": 1060
    },
    {
      "epoch": 0.39258851586864796,
      "grad_norm": 0.875762403011322,
      "learning_rate": 4.9856653825938715e-05,
      "loss": 0.5631,
      "step": 1070
    },
    {
      "epoch": 0.39625756741882223,
      "grad_norm": 0.7623623609542847,
      "learning_rate": 4.9845016341012095e-05,
      "loss": 0.5777,
      "step": 1080
    },
    {
      "epoch": 0.3999266189689965,
      "grad_norm": 1.0272465944290161,
      "learning_rate": 4.9832926185011084e-05,
      "loss": 0.5653,
      "step": 1090
    },
    {
      "epoch": 0.4035956705191708,
      "grad_norm": 0.7474942207336426,
      "learning_rate": 4.9820383578215815e-05,
      "loss": 0.5838,
      "step": 1100
    },
    {
      "epoch": 0.40726472206934505,
      "grad_norm": 0.8431952595710754,
      "learning_rate": 4.980738874915001e-05,
      "loss": 0.5779,
      "step": 1110
    },
    {
      "epoch": 0.4109337736195193,
      "grad_norm": 0.7840742468833923,
      "learning_rate": 4.9793941934576774e-05,
      "loss": 0.5956,
      "step": 1120
    },
    {
      "epoch": 0.41460282516969366,
      "grad_norm": 0.7531408667564392,
      "learning_rate": 4.978004337949429e-05,
      "loss": 0.5619,
      "step": 1130
    },
    {
      "epoch": 0.41827187671986793,
      "grad_norm": 0.8034108877182007,
      "learning_rate": 4.976569333713137e-05,
      "loss": 0.5715,
      "step": 1140
    },
    {
      "epoch": 0.4219409282700422,
      "grad_norm": 0.6612378358840942,
      "learning_rate": 4.975089206894283e-05,
      "loss": 0.5776,
      "step": 1150
    },
    {
      "epoch": 0.4256099798202165,
      "grad_norm": 0.741470217704773,
      "learning_rate": 4.9735639844604706e-05,
      "loss": 0.551,
      "step": 1160
    },
    {
      "epoch": 0.42927903137039075,
      "grad_norm": 0.8484413027763367,
      "learning_rate": 4.9719936942009406e-05,
      "loss": 0.5912,
      "step": 1170
    },
    {
      "epoch": 0.432948082920565,
      "grad_norm": 0.9448020458221436,
      "learning_rate": 4.970378364726056e-05,
      "loss": 0.5932,
      "step": 1180
    },
    {
      "epoch": 0.4366171344707393,
      "grad_norm": 0.7909348011016846,
      "learning_rate": 4.968718025466788e-05,
      "loss": 0.584,
      "step": 1190
    },
    {
      "epoch": 0.4402861860209136,
      "grad_norm": 0.7125610709190369,
      "learning_rate": 4.967012706674174e-05,
      "loss": 0.5537,
      "step": 1200
    },
    {
      "epoch": 0.44395523757108785,
      "grad_norm": 0.8675113916397095,
      "learning_rate": 4.965262439418772e-05,
      "loss": 0.5583,
      "step": 1210
    },
    {
      "epoch": 0.4476242891212622,
      "grad_norm": 0.9049820303916931,
      "learning_rate": 4.96346725559009e-05,
      "loss": 0.5909,
      "step": 1220
    },
    {
      "epoch": 0.45129334067143645,
      "grad_norm": 0.9292231202125549,
      "learning_rate": 4.961627187896006e-05,
      "loss": 0.5983,
      "step": 1230
    },
    {
      "epoch": 0.4549623922216107,
      "grad_norm": 0.7964368462562561,
      "learning_rate": 4.9597422698621764e-05,
      "loss": 0.5753,
      "step": 1240
    },
    {
      "epoch": 0.458631443771785,
      "grad_norm": 0.6815668940544128,
      "learning_rate": 4.9578125358314175e-05,
      "loss": 0.5955,
      "step": 1250
    },
    {
      "epoch": 0.46230049532195927,
      "grad_norm": 0.9475581049919128,
      "learning_rate": 4.9558380209630864e-05,
      "loss": 0.5887,
      "step": 1260
    },
    {
      "epoch": 0.46596954687213354,
      "grad_norm": 1.021878719329834,
      "learning_rate": 4.953818761232435e-05,
      "loss": 0.5716,
      "step": 1270
    },
    {
      "epoch": 0.4696385984223078,
      "grad_norm": 0.915371835231781,
      "learning_rate": 4.9517547934299604e-05,
      "loss": 0.5975,
      "step": 1280
    },
    {
      "epoch": 0.4733076499724821,
      "grad_norm": 0.8428240418434143,
      "learning_rate": 4.94964615516073e-05,
      "loss": 0.5626,
      "step": 1290
    },
    {
      "epoch": 0.4769767015226564,
      "grad_norm": 0.8997093439102173,
      "learning_rate": 4.947492884843699e-05,
      "loss": 0.5735,
      "step": 1300
    },
    {
      "epoch": 0.4806457530728307,
      "grad_norm": 1.0769418478012085,
      "learning_rate": 4.945295021711008e-05,
      "loss": 0.6035,
      "step": 1310
    },
    {
      "epoch": 0.48431480462300497,
      "grad_norm": 0.9459863305091858,
      "learning_rate": 4.94305260580727e-05,
      "loss": 0.5842,
      "step": 1320
    },
    {
      "epoch": 0.48798385617317924,
      "grad_norm": 0.8330615758895874,
      "learning_rate": 4.940765677988841e-05,
      "loss": 0.5616,
      "step": 1330
    },
    {
      "epoch": 0.4916529077233535,
      "grad_norm": 0.9455893039703369,
      "learning_rate": 4.938434279923073e-05,
      "loss": 0.616,
      "step": 1340
    },
    {
      "epoch": 0.4953219592735278,
      "grad_norm": 0.8248706459999084,
      "learning_rate": 4.9360584540875585e-05,
      "loss": 0.5723,
      "step": 1350
    },
    {
      "epoch": 0.49899101082370206,
      "grad_norm": 0.7279864549636841,
      "learning_rate": 4.933638243769355e-05,
      "loss": 0.5578,
      "step": 1360
    },
    {
      "epoch": 0.5026600623738764,
      "grad_norm": 0.8937111496925354,
      "learning_rate": 4.931173693064195e-05,
      "loss": 0.5792,
      "step": 1370
    },
    {
      "epoch": 0.5063291139240507,
      "grad_norm": 0.9426361918449402,
      "learning_rate": 4.9286648468756844e-05,
      "loss": 0.5458,
      "step": 1380
    },
    {
      "epoch": 0.5099981654742249,
      "grad_norm": 0.8062474727630615,
      "learning_rate": 4.9261117509144825e-05,
      "loss": 0.5862,
      "step": 1390
    },
    {
      "epoch": 0.5136672170243992,
      "grad_norm": 0.9370191097259521,
      "learning_rate": 4.923514451697472e-05,
      "loss": 0.5358,
      "step": 1400
    },
    {
      "epoch": 0.5173362685745735,
      "grad_norm": 0.8648721575737,
      "learning_rate": 4.9208729965469087e-05,
      "loss": 0.537,
      "step": 1410
    },
    {
      "epoch": 0.5210053201247478,
      "grad_norm": 0.9978837966918945,
      "learning_rate": 4.9181874335895604e-05,
      "loss": 0.5568,
      "step": 1420
    },
    {
      "epoch": 0.524674371674922,
      "grad_norm": 0.8308568596839905,
      "learning_rate": 4.915457811755832e-05,
      "loss": 0.5836,
      "step": 1430
    },
    {
      "epoch": 0.5283434232250963,
      "grad_norm": 0.9117475152015686,
      "learning_rate": 4.912684180778869e-05,
      "loss": 0.5697,
      "step": 1440
    },
    {
      "epoch": 0.5320124747752706,
      "grad_norm": 0.7363874912261963,
      "learning_rate": 4.909866591193656e-05,
      "loss": 0.5637,
      "step": 1450
    },
    {
      "epoch": 0.5356815263254449,
      "grad_norm": 1.0187169313430786,
      "learning_rate": 4.9070050943360935e-05,
      "loss": 0.5644,
      "step": 1460
    },
    {
      "epoch": 0.5393505778756191,
      "grad_norm": 0.9083443284034729,
      "learning_rate": 4.9040997423420656e-05,
      "loss": 0.5591,
      "step": 1470
    },
    {
      "epoch": 0.5430196294257934,
      "grad_norm": 0.793476939201355,
      "learning_rate": 4.901150588146487e-05,
      "loss": 0.5445,
      "step": 1480
    },
    {
      "epoch": 0.5466886809759677,
      "grad_norm": 0.9009830951690674,
      "learning_rate": 4.8981576854823367e-05,
      "loss": 0.551,
      "step": 1490
    },
    {
      "epoch": 0.550357732526142,
      "grad_norm": 0.9271986484527588,
      "learning_rate": 4.895121088879685e-05,
      "loss": 0.5739,
      "step": 1500
    },
    {
      "epoch": 0.550357732526142,
      "eval_loss": 0.5655648708343506,
      "eval_runtime": 240.2058,
      "eval_samples_per_second": 2.523,
      "eval_steps_per_second": 2.523,
      "step": 1500
    },
    {
      "epoch": 0.5540267840763162,
      "grad_norm": 0.8860954642295837,
      "learning_rate": 4.8920408536646975e-05,
      "loss": 0.5868,
      "step": 1510
    },
    {
      "epoch": 0.5576958356264905,
      "grad_norm": 0.8972140550613403,
      "learning_rate": 4.8889170359586226e-05,
      "loss": 0.5674,
      "step": 1520
    },
    {
      "epoch": 0.5613648871766649,
      "grad_norm": 0.8974564075469971,
      "learning_rate": 4.885749692676775e-05,
      "loss": 0.5776,
      "step": 1530
    },
    {
      "epoch": 0.5650339387268392,
      "grad_norm": 0.8998370170593262,
      "learning_rate": 4.882538881527497e-05,
      "loss": 0.5535,
      "step": 1540
    },
    {
      "epoch": 0.5687029902770134,
      "grad_norm": 0.9352656006813049,
      "learning_rate": 4.8792846610111046e-05,
      "loss": 0.5702,
      "step": 1550
    },
    {
      "epoch": 0.5723720418271877,
      "grad_norm": 1.009832739830017,
      "learning_rate": 4.875987090418826e-05,
      "loss": 0.5824,
      "step": 1560
    },
    {
      "epoch": 0.576041093377362,
      "grad_norm": 0.8600253462791443,
      "learning_rate": 4.872646229831716e-05,
      "loss": 0.556,
      "step": 1570
    },
    {
      "epoch": 0.5797101449275363,
      "grad_norm": 0.7715021967887878,
      "learning_rate": 4.869262140119566e-05,
      "loss": 0.5362,
      "step": 1580
    },
    {
      "epoch": 0.5833791964777105,
      "grad_norm": 0.9116750955581665,
      "learning_rate": 4.865834882939794e-05,
      "loss": 0.5574,
      "step": 1590
    },
    {
      "epoch": 0.5870482480278848,
      "grad_norm": 0.8421168327331543,
      "learning_rate": 4.862364520736317e-05,
      "loss": 0.5805,
      "step": 1600
    },
    {
      "epoch": 0.5907172995780591,
      "grad_norm": 0.8925551772117615,
      "learning_rate": 4.858851116738419e-05,
      "loss": 0.5944,
      "step": 1610
    },
    {
      "epoch": 0.5943863511282333,
      "grad_norm": 0.8234690427780151,
      "learning_rate": 4.855294734959597e-05,
      "loss": 0.5491,
      "step": 1620
    },
    {
      "epoch": 0.5980554026784076,
      "grad_norm": 1.1261595487594604,
      "learning_rate": 4.851695440196394e-05,
      "loss": 0.568,
      "step": 1630
    },
    {
      "epoch": 0.6017244542285819,
      "grad_norm": 0.7588224411010742,
      "learning_rate": 4.8480532980272184e-05,
      "loss": 0.5545,
      "step": 1640
    },
    {
      "epoch": 0.6053935057787562,
      "grad_norm": 0.8019400238990784,
      "learning_rate": 4.844368374811149e-05,
      "loss": 0.5615,
      "step": 1650
    },
    {
      "epoch": 0.6090625573289304,
      "grad_norm": 0.9038190245628357,
      "learning_rate": 4.840640737686727e-05,
      "loss": 0.5828,
      "step": 1660
    },
    {
      "epoch": 0.6127316088791047,
      "grad_norm": 0.7243975400924683,
      "learning_rate": 4.836870454570731e-05,
      "loss": 0.5662,
      "step": 1670
    },
    {
      "epoch": 0.616400660429279,
      "grad_norm": 0.9103299975395203,
      "learning_rate": 4.833057594156944e-05,
      "loss": 0.5528,
      "step": 1680
    },
    {
      "epoch": 0.6200697119794533,
      "grad_norm": 1.1013984680175781,
      "learning_rate": 4.829202225914895e-05,
      "loss": 0.5556,
      "step": 1690
    },
    {
      "epoch": 0.6237387635296275,
      "grad_norm": 0.7952206134796143,
      "learning_rate": 4.825304420088599e-05,
      "loss": 0.5452,
      "step": 1700
    },
    {
      "epoch": 0.6274078150798019,
      "grad_norm": 0.8104619383811951,
      "learning_rate": 4.821364247695274e-05,
      "loss": 0.5591,
      "step": 1710
    },
    {
      "epoch": 0.6310768666299762,
      "grad_norm": 0.7545372247695923,
      "learning_rate": 4.8173817805240487e-05,
      "loss": 0.5738,
      "step": 1720
    },
    {
      "epoch": 0.6347459181801505,
      "grad_norm": 0.9334061145782471,
      "learning_rate": 4.813357091134654e-05,
      "loss": 0.5709,
      "step": 1730
    },
    {
      "epoch": 0.6384149697303247,
      "grad_norm": 0.6794409155845642,
      "learning_rate": 4.8092902528561e-05,
      "loss": 0.591,
      "step": 1740
    },
    {
      "epoch": 0.642084021280499,
      "grad_norm": 1.0061829090118408,
      "learning_rate": 4.805181339785342e-05,
      "loss": 0.5723,
      "step": 1750
    },
    {
      "epoch": 0.6457530728306733,
      "grad_norm": 1.2289650440216064,
      "learning_rate": 4.801030426785928e-05,
      "loss": 0.5788,
      "step": 1760
    },
    {
      "epoch": 0.6494221243808476,
      "grad_norm": 1.067782998085022,
      "learning_rate": 4.796837589486639e-05,
      "loss": 0.5468,
      "step": 1770
    },
    {
      "epoch": 0.6530911759310218,
      "grad_norm": 0.8999747037887573,
      "learning_rate": 4.792602904280104e-05,
      "loss": 0.5634,
      "step": 1780
    },
    {
      "epoch": 0.6567602274811961,
      "grad_norm": 0.8649622797966003,
      "learning_rate": 4.788326448321415e-05,
      "loss": 0.5892,
      "step": 1790
    },
    {
      "epoch": 0.6604292790313704,
      "grad_norm": 0.863810122013092,
      "learning_rate": 4.784008299526716e-05,
      "loss": 0.5562,
      "step": 1800
    },
    {
      "epoch": 0.6640983305815447,
      "grad_norm": 0.8143636584281921,
      "learning_rate": 4.779648536571791e-05,
      "loss": 0.5553,
      "step": 1810
    },
    {
      "epoch": 0.6677673821317189,
      "grad_norm": 0.9549927115440369,
      "learning_rate": 4.775247238890619e-05,
      "loss": 0.5448,
      "step": 1820
    },
    {
      "epoch": 0.6714364336818932,
      "grad_norm": 1.003637671470642,
      "learning_rate": 4.770804486673938e-05,
      "loss": 0.5678,
      "step": 1830
    },
    {
      "epoch": 0.6751054852320675,
      "grad_norm": 0.825347363948822,
      "learning_rate": 4.766320360867775e-05,
      "loss": 0.5374,
      "step": 1840
    },
    {
      "epoch": 0.6787745367822418,
      "grad_norm": 1.002130150794983,
      "learning_rate": 4.76179494317198e-05,
      "loss": 0.5441,
      "step": 1850
    },
    {
      "epoch": 0.682443588332416,
      "grad_norm": 0.9000377655029297,
      "learning_rate": 4.757228316038729e-05,
      "loss": 0.5404,
      "step": 1860
    },
    {
      "epoch": 0.6861126398825903,
      "grad_norm": 0.7789478302001953,
      "learning_rate": 4.752620562671027e-05,
      "loss": 0.5275,
      "step": 1870
    },
    {
      "epoch": 0.6897816914327646,
      "grad_norm": 0.7302083969116211,
      "learning_rate": 4.7479717670211904e-05,
      "loss": 0.5562,
      "step": 1880
    },
    {
      "epoch": 0.693450742982939,
      "grad_norm": 0.8888310194015503,
      "learning_rate": 4.743282013789316e-05,
      "loss": 0.5606,
      "step": 1890
    },
    {
      "epoch": 0.6971197945331132,
      "grad_norm": 0.8932925462722778,
      "learning_rate": 4.738551388421743e-05,
      "loss": 0.5819,
      "step": 1900
    },
    {
      "epoch": 0.7007888460832875,
      "grad_norm": 0.8947935700416565,
      "learning_rate": 4.733779977109487e-05,
      "loss": 0.5537,
      "step": 1910
    },
    {
      "epoch": 0.7044578976334618,
      "grad_norm": 0.8630931973457336,
      "learning_rate": 4.728967866786681e-05,
      "loss": 0.5539,
      "step": 1920
    },
    {
      "epoch": 0.7081269491836361,
      "grad_norm": 0.8323912024497986,
      "learning_rate": 4.7241151451289813e-05,
      "loss": 0.5714,
      "step": 1930
    },
    {
      "epoch": 0.7117960007338103,
      "grad_norm": 0.8414443731307983,
      "learning_rate": 4.719221900551976e-05,
      "loss": 0.5625,
      "step": 1940
    },
    {
      "epoch": 0.7154650522839846,
      "grad_norm": 0.8163629174232483,
      "learning_rate": 4.714288222209573e-05,
      "loss": 0.5594,
      "step": 1950
    },
    {
      "epoch": 0.7191341038341589,
      "grad_norm": 0.9008724689483643,
      "learning_rate": 4.7093141999923726e-05,
      "loss": 0.5762,
      "step": 1960
    },
    {
      "epoch": 0.7228031553843332,
      "grad_norm": 0.8228312730789185,
      "learning_rate": 4.7042999245260356e-05,
      "loss": 0.5703,
      "step": 1970
    },
    {
      "epoch": 0.7264722069345074,
      "grad_norm": 1.0673984289169312,
      "learning_rate": 4.6992454871696265e-05,
      "loss": 0.57,
      "step": 1980
    },
    {
      "epoch": 0.7301412584846817,
      "grad_norm": 0.7121770977973938,
      "learning_rate": 4.694150980013952e-05,
      "loss": 0.5426,
      "step": 1990
    },
    {
      "epoch": 0.733810310034856,
      "grad_norm": 0.7347238063812256,
      "learning_rate": 4.68901649587988e-05,
      "loss": 0.5766,
      "step": 2000
    },
    {
      "epoch": 0.733810310034856,
      "eval_loss": 0.552966833114624,
      "eval_runtime": 240.4235,
      "eval_samples_per_second": 2.521,
      "eval_steps_per_second": 2.521,
      "step": 2000
    }
  ],
  "logging_steps": 10,
  "max_steps": 8178,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.3217914628315546e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
