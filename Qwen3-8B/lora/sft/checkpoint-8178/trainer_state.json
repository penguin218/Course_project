{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 8178,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00366905155017428,
      "grad_norm": 0.3877936601638794,
      "learning_rate": 5.501222493887531e-07,
      "loss": 1.3825,
      "step": 10
    },
    {
      "epoch": 0.00733810310034856,
      "grad_norm": 0.3388456106185913,
      "learning_rate": 1.1613691931540342e-06,
      "loss": 1.3519,
      "step": 20
    },
    {
      "epoch": 0.01100715465052284,
      "grad_norm": 0.34713810682296753,
      "learning_rate": 1.7726161369193154e-06,
      "loss": 1.3608,
      "step": 30
    },
    {
      "epoch": 0.01467620620069712,
      "grad_norm": 0.4064188003540039,
      "learning_rate": 2.3838630806845967e-06,
      "loss": 1.3713,
      "step": 40
    },
    {
      "epoch": 0.0183452577508714,
      "grad_norm": 0.45421141386032104,
      "learning_rate": 2.9951100244498777e-06,
      "loss": 1.3726,
      "step": 50
    },
    {
      "epoch": 0.02201430930104568,
      "grad_norm": 0.4744616746902466,
      "learning_rate": 3.606356968215159e-06,
      "loss": 1.3487,
      "step": 60
    },
    {
      "epoch": 0.025683360851219958,
      "grad_norm": 0.6290422677993774,
      "learning_rate": 4.21760391198044e-06,
      "loss": 1.3523,
      "step": 70
    },
    {
      "epoch": 0.02935241240139424,
      "grad_norm": 0.5566685795783997,
      "learning_rate": 4.828850855745722e-06,
      "loss": 1.3289,
      "step": 80
    },
    {
      "epoch": 0.03302146395156852,
      "grad_norm": 0.46856987476348877,
      "learning_rate": 5.440097799511003e-06,
      "loss": 1.3306,
      "step": 90
    },
    {
      "epoch": 0.0366905155017428,
      "grad_norm": 0.35358479619026184,
      "learning_rate": 6.051344743276284e-06,
      "loss": 1.247,
      "step": 100
    },
    {
      "epoch": 0.04035956705191708,
      "grad_norm": 0.4844614565372467,
      "learning_rate": 6.662591687041565e-06,
      "loss": 1.2218,
      "step": 110
    },
    {
      "epoch": 0.04402861860209136,
      "grad_norm": 0.5792201161384583,
      "learning_rate": 7.273838630806847e-06,
      "loss": 1.2077,
      "step": 120
    },
    {
      "epoch": 0.04769767015226564,
      "grad_norm": 0.38933107256889343,
      "learning_rate": 7.885085574572127e-06,
      "loss": 1.1452,
      "step": 130
    },
    {
      "epoch": 0.051366721702439916,
      "grad_norm": 0.364145427942276,
      "learning_rate": 8.496332518337409e-06,
      "loss": 1.0986,
      "step": 140
    },
    {
      "epoch": 0.0550357732526142,
      "grad_norm": 0.4445214569568634,
      "learning_rate": 9.10757946210269e-06,
      "loss": 1.0758,
      "step": 150
    },
    {
      "epoch": 0.05870482480278848,
      "grad_norm": 0.48486754298210144,
      "learning_rate": 9.718826405867972e-06,
      "loss": 1.0014,
      "step": 160
    },
    {
      "epoch": 0.06237387635296276,
      "grad_norm": 0.33367639780044556,
      "learning_rate": 1.0330073349633253e-05,
      "loss": 0.9749,
      "step": 170
    },
    {
      "epoch": 0.06604292790313704,
      "grad_norm": 0.4073357880115509,
      "learning_rate": 1.0941320293398534e-05,
      "loss": 0.9964,
      "step": 180
    },
    {
      "epoch": 0.06971197945331131,
      "grad_norm": 0.489095002412796,
      "learning_rate": 1.1552567237163816e-05,
      "loss": 0.9409,
      "step": 190
    },
    {
      "epoch": 0.0733810310034856,
      "grad_norm": 0.3971366882324219,
      "learning_rate": 1.2163814180929096e-05,
      "loss": 0.9283,
      "step": 200
    },
    {
      "epoch": 0.07705008255365987,
      "grad_norm": 0.44291526079177856,
      "learning_rate": 1.2775061124694377e-05,
      "loss": 0.8758,
      "step": 210
    },
    {
      "epoch": 0.08071913410383416,
      "grad_norm": 0.6228989362716675,
      "learning_rate": 1.3386308068459657e-05,
      "loss": 0.9017,
      "step": 220
    },
    {
      "epoch": 0.08438818565400844,
      "grad_norm": 0.41784918308258057,
      "learning_rate": 1.3997555012224938e-05,
      "loss": 0.8486,
      "step": 230
    },
    {
      "epoch": 0.08805723720418272,
      "grad_norm": 0.49626976251602173,
      "learning_rate": 1.460880195599022e-05,
      "loss": 0.8642,
      "step": 240
    },
    {
      "epoch": 0.091726288754357,
      "grad_norm": 0.5728238224983215,
      "learning_rate": 1.5220048899755501e-05,
      "loss": 0.8622,
      "step": 250
    },
    {
      "epoch": 0.09539534030453128,
      "grad_norm": 0.468300998210907,
      "learning_rate": 1.583129584352078e-05,
      "loss": 0.8142,
      "step": 260
    },
    {
      "epoch": 0.09906439185470556,
      "grad_norm": 0.6429207921028137,
      "learning_rate": 1.6442542787286064e-05,
      "loss": 0.8135,
      "step": 270
    },
    {
      "epoch": 0.10273344340487983,
      "grad_norm": 0.4333305358886719,
      "learning_rate": 1.7053789731051344e-05,
      "loss": 0.7781,
      "step": 280
    },
    {
      "epoch": 0.10640249495505412,
      "grad_norm": 0.7538961172103882,
      "learning_rate": 1.7665036674816627e-05,
      "loss": 0.7782,
      "step": 290
    },
    {
      "epoch": 0.1100715465052284,
      "grad_norm": 0.5683786869049072,
      "learning_rate": 1.8276283618581907e-05,
      "loss": 0.7574,
      "step": 300
    },
    {
      "epoch": 0.11374059805540268,
      "grad_norm": 0.5173904895782471,
      "learning_rate": 1.888753056234719e-05,
      "loss": 0.7558,
      "step": 310
    },
    {
      "epoch": 0.11740964960557695,
      "grad_norm": 0.6803333163261414,
      "learning_rate": 1.949877750611247e-05,
      "loss": 0.7621,
      "step": 320
    },
    {
      "epoch": 0.12107870115575124,
      "grad_norm": 0.7055644989013672,
      "learning_rate": 2.0110024449877753e-05,
      "loss": 0.7509,
      "step": 330
    },
    {
      "epoch": 0.12474775270592552,
      "grad_norm": 0.6526551842689514,
      "learning_rate": 2.0721271393643033e-05,
      "loss": 0.7612,
      "step": 340
    },
    {
      "epoch": 0.1284168042560998,
      "grad_norm": 1.0160521268844604,
      "learning_rate": 2.1332518337408312e-05,
      "loss": 0.7526,
      "step": 350
    },
    {
      "epoch": 0.13208585580627408,
      "grad_norm": 0.6214171051979065,
      "learning_rate": 2.1943765281173596e-05,
      "loss": 0.7192,
      "step": 360
    },
    {
      "epoch": 0.13575490735644835,
      "grad_norm": 0.6929377317428589,
      "learning_rate": 2.2555012224938875e-05,
      "loss": 0.7006,
      "step": 370
    },
    {
      "epoch": 0.13942395890662262,
      "grad_norm": 0.7169085144996643,
      "learning_rate": 2.316625916870416e-05,
      "loss": 0.6955,
      "step": 380
    },
    {
      "epoch": 0.14309301045679693,
      "grad_norm": 0.8329369425773621,
      "learning_rate": 2.3777506112469438e-05,
      "loss": 0.7199,
      "step": 390
    },
    {
      "epoch": 0.1467620620069712,
      "grad_norm": 0.6524739265441895,
      "learning_rate": 2.438875305623472e-05,
      "loss": 0.6703,
      "step": 400
    },
    {
      "epoch": 0.15043111355714547,
      "grad_norm": 0.7267888784408569,
      "learning_rate": 2.5e-05,
      "loss": 0.6875,
      "step": 410
    },
    {
      "epoch": 0.15410016510731975,
      "grad_norm": 0.6155242323875427,
      "learning_rate": 2.561124694376528e-05,
      "loss": 0.7156,
      "step": 420
    },
    {
      "epoch": 0.15776921665749405,
      "grad_norm": 0.7568008303642273,
      "learning_rate": 2.6222493887530564e-05,
      "loss": 0.6965,
      "step": 430
    },
    {
      "epoch": 0.16143826820766832,
      "grad_norm": 0.6655860543251038,
      "learning_rate": 2.6833740831295844e-05,
      "loss": 0.6546,
      "step": 440
    },
    {
      "epoch": 0.1651073197578426,
      "grad_norm": 1.1648468971252441,
      "learning_rate": 2.7444987775061127e-05,
      "loss": 0.6819,
      "step": 450
    },
    {
      "epoch": 0.16877637130801687,
      "grad_norm": 0.68362957239151,
      "learning_rate": 2.8056234718826407e-05,
      "loss": 0.6855,
      "step": 460
    },
    {
      "epoch": 0.17244542285819114,
      "grad_norm": 0.6543752551078796,
      "learning_rate": 2.866748166259169e-05,
      "loss": 0.645,
      "step": 470
    },
    {
      "epoch": 0.17611447440836545,
      "grad_norm": 0.6918438076972961,
      "learning_rate": 2.927872860635697e-05,
      "loss": 0.6267,
      "step": 480
    },
    {
      "epoch": 0.17978352595853972,
      "grad_norm": 0.7780126333236694,
      "learning_rate": 2.988997555012225e-05,
      "loss": 0.6547,
      "step": 490
    },
    {
      "epoch": 0.183452577508714,
      "grad_norm": 0.6887812614440918,
      "learning_rate": 3.0501222493887533e-05,
      "loss": 0.6507,
      "step": 500
    },
    {
      "epoch": 0.183452577508714,
      "eval_loss": 0.6555390357971191,
      "eval_runtime": 241.4797,
      "eval_samples_per_second": 2.51,
      "eval_steps_per_second": 2.51,
      "step": 500
    },
    {
      "epoch": 0.18712162905888827,
      "grad_norm": 0.756022572517395,
      "learning_rate": 3.1112469437652816e-05,
      "loss": 0.6563,
      "step": 510
    },
    {
      "epoch": 0.19079068060906257,
      "grad_norm": 0.8010755777359009,
      "learning_rate": 3.1723716381418096e-05,
      "loss": 0.662,
      "step": 520
    },
    {
      "epoch": 0.19445973215923684,
      "grad_norm": 0.7894098162651062,
      "learning_rate": 3.2334963325183375e-05,
      "loss": 0.6657,
      "step": 530
    },
    {
      "epoch": 0.19812878370941112,
      "grad_norm": 1.0443938970565796,
      "learning_rate": 3.2946210268948655e-05,
      "loss": 0.6485,
      "step": 540
    },
    {
      "epoch": 0.2017978352595854,
      "grad_norm": 0.8169821500778198,
      "learning_rate": 3.355745721271394e-05,
      "loss": 0.6534,
      "step": 550
    },
    {
      "epoch": 0.20546688680975966,
      "grad_norm": 0.9781677722930908,
      "learning_rate": 3.416870415647922e-05,
      "loss": 0.6669,
      "step": 560
    },
    {
      "epoch": 0.20913593835993396,
      "grad_norm": 0.9551028609275818,
      "learning_rate": 3.47799511002445e-05,
      "loss": 0.638,
      "step": 570
    },
    {
      "epoch": 0.21280498991010824,
      "grad_norm": 0.7600991725921631,
      "learning_rate": 3.539119804400978e-05,
      "loss": 0.6364,
      "step": 580
    },
    {
      "epoch": 0.2164740414602825,
      "grad_norm": 0.8121793866157532,
      "learning_rate": 3.600244498777506e-05,
      "loss": 0.6195,
      "step": 590
    },
    {
      "epoch": 0.2201430930104568,
      "grad_norm": 0.867216944694519,
      "learning_rate": 3.661369193154035e-05,
      "loss": 0.6555,
      "step": 600
    },
    {
      "epoch": 0.2238121445606311,
      "grad_norm": 0.8910418152809143,
      "learning_rate": 3.722493887530563e-05,
      "loss": 0.6377,
      "step": 610
    },
    {
      "epoch": 0.22748119611080536,
      "grad_norm": 0.9751493334770203,
      "learning_rate": 3.783618581907091e-05,
      "loss": 0.6429,
      "step": 620
    },
    {
      "epoch": 0.23115024766097964,
      "grad_norm": 0.7061278223991394,
      "learning_rate": 3.8447432762836186e-05,
      "loss": 0.6308,
      "step": 630
    },
    {
      "epoch": 0.2348192992111539,
      "grad_norm": 1.1142009496688843,
      "learning_rate": 3.905867970660147e-05,
      "loss": 0.6392,
      "step": 640
    },
    {
      "epoch": 0.2384883507613282,
      "grad_norm": 0.9368607401847839,
      "learning_rate": 3.966992665036675e-05,
      "loss": 0.618,
      "step": 650
    },
    {
      "epoch": 0.24215740231150248,
      "grad_norm": 0.8624376058578491,
      "learning_rate": 4.028117359413203e-05,
      "loss": 0.6153,
      "step": 660
    },
    {
      "epoch": 0.24582645386167676,
      "grad_norm": 0.7143048048019409,
      "learning_rate": 4.089242053789731e-05,
      "loss": 0.593,
      "step": 670
    },
    {
      "epoch": 0.24949550541185103,
      "grad_norm": 0.9557223320007324,
      "learning_rate": 4.150366748166259e-05,
      "loss": 0.6289,
      "step": 680
    },
    {
      "epoch": 0.25316455696202533,
      "grad_norm": 0.6870782375335693,
      "learning_rate": 4.211491442542788e-05,
      "loss": 0.6068,
      "step": 690
    },
    {
      "epoch": 0.2568336085121996,
      "grad_norm": 0.8731458187103271,
      "learning_rate": 4.272616136919316e-05,
      "loss": 0.6428,
      "step": 700
    },
    {
      "epoch": 0.2605026600623739,
      "grad_norm": 1.0079413652420044,
      "learning_rate": 4.333740831295844e-05,
      "loss": 0.6517,
      "step": 710
    },
    {
      "epoch": 0.26417171161254815,
      "grad_norm": 0.8572641015052795,
      "learning_rate": 4.394865525672372e-05,
      "loss": 0.5917,
      "step": 720
    },
    {
      "epoch": 0.26784076316272243,
      "grad_norm": 0.8210773468017578,
      "learning_rate": 4.4559902200489e-05,
      "loss": 0.5923,
      "step": 730
    },
    {
      "epoch": 0.2715098147128967,
      "grad_norm": 1.3339871168136597,
      "learning_rate": 4.5171149144254284e-05,
      "loss": 0.6521,
      "step": 740
    },
    {
      "epoch": 0.275178866263071,
      "grad_norm": 0.8313754200935364,
      "learning_rate": 4.5782396088019564e-05,
      "loss": 0.6547,
      "step": 750
    },
    {
      "epoch": 0.27884791781324525,
      "grad_norm": 0.8662818670272827,
      "learning_rate": 4.6393643031784844e-05,
      "loss": 0.639,
      "step": 760
    },
    {
      "epoch": 0.2825169693634196,
      "grad_norm": 0.821679949760437,
      "learning_rate": 4.7004889975550123e-05,
      "loss": 0.6073,
      "step": 770
    },
    {
      "epoch": 0.28618602091359385,
      "grad_norm": 0.9807654619216919,
      "learning_rate": 4.761613691931541e-05,
      "loss": 0.5926,
      "step": 780
    },
    {
      "epoch": 0.2898550724637681,
      "grad_norm": 1.052196741104126,
      "learning_rate": 4.822738386308069e-05,
      "loss": 0.6106,
      "step": 790
    },
    {
      "epoch": 0.2935241240139424,
      "grad_norm": 0.9126512408256531,
      "learning_rate": 4.883863080684597e-05,
      "loss": 0.608,
      "step": 800
    },
    {
      "epoch": 0.2971931755641167,
      "grad_norm": 0.7981895208358765,
      "learning_rate": 4.944987775061125e-05,
      "loss": 0.5572,
      "step": 810
    },
    {
      "epoch": 0.30086222711429095,
      "grad_norm": 1.0812228918075562,
      "learning_rate": 4.999999772252235e-05,
      "loss": 0.5998,
      "step": 820
    },
    {
      "epoch": 0.3045312786644652,
      "grad_norm": 1.0476435422897339,
      "learning_rate": 4.999972442570682e-05,
      "loss": 0.6393,
      "step": 830
    },
    {
      "epoch": 0.3082003302146395,
      "grad_norm": 0.8512653708457947,
      "learning_rate": 4.9998995639067493e-05,
      "loss": 0.6259,
      "step": 840
    },
    {
      "epoch": 0.31186938176481377,
      "grad_norm": 0.8550739288330078,
      "learning_rate": 4.99978113758827e-05,
      "loss": 0.5873,
      "step": 850
    },
    {
      "epoch": 0.3155384333149881,
      "grad_norm": 0.8724313378334045,
      "learning_rate": 4.999617165772949e-05,
      "loss": 0.579,
      "step": 860
    },
    {
      "epoch": 0.31920748486516237,
      "grad_norm": 0.8744262456893921,
      "learning_rate": 4.999407651448318e-05,
      "loss": 0.5672,
      "step": 870
    },
    {
      "epoch": 0.32287653641533665,
      "grad_norm": 0.7632190585136414,
      "learning_rate": 4.999152598431685e-05,
      "loss": 0.6068,
      "step": 880
    },
    {
      "epoch": 0.3265455879655109,
      "grad_norm": 0.8382863998413086,
      "learning_rate": 4.9988520113700626e-05,
      "loss": 0.5769,
      "step": 890
    },
    {
      "epoch": 0.3302146395156852,
      "grad_norm": 0.862323522567749,
      "learning_rate": 4.998505895740087e-05,
      "loss": 0.5912,
      "step": 900
    },
    {
      "epoch": 0.33388369106585947,
      "grad_norm": 1.0637726783752441,
      "learning_rate": 4.9981142578479115e-05,
      "loss": 0.6381,
      "step": 910
    },
    {
      "epoch": 0.33755274261603374,
      "grad_norm": 1.0006047487258911,
      "learning_rate": 4.997677104829098e-05,
      "loss": 0.5963,
      "step": 920
    },
    {
      "epoch": 0.341221794166208,
      "grad_norm": 0.7697986960411072,
      "learning_rate": 4.9971944446484865e-05,
      "loss": 0.6031,
      "step": 930
    },
    {
      "epoch": 0.3448908457163823,
      "grad_norm": 0.9483711123466492,
      "learning_rate": 4.996666286100043e-05,
      "loss": 0.5832,
      "step": 940
    },
    {
      "epoch": 0.3485598972665566,
      "grad_norm": 0.8196538090705872,
      "learning_rate": 4.99609263880671e-05,
      "loss": 0.582,
      "step": 950
    },
    {
      "epoch": 0.3522289488167309,
      "grad_norm": 0.9448139071464539,
      "learning_rate": 4.995473513220221e-05,
      "loss": 0.597,
      "step": 960
    },
    {
      "epoch": 0.35589800036690517,
      "grad_norm": 0.9995883107185364,
      "learning_rate": 4.994808920620918e-05,
      "loss": 0.5681,
      "step": 970
    },
    {
      "epoch": 0.35956705191707944,
      "grad_norm": 0.7747149467468262,
      "learning_rate": 4.99409887311754e-05,
      "loss": 0.6065,
      "step": 980
    },
    {
      "epoch": 0.3632361034672537,
      "grad_norm": 0.8338237404823303,
      "learning_rate": 4.9933433836470056e-05,
      "loss": 0.5884,
      "step": 990
    },
    {
      "epoch": 0.366905155017428,
      "grad_norm": 1.0708411931991577,
      "learning_rate": 4.992542465974178e-05,
      "loss": 0.5889,
      "step": 1000
    },
    {
      "epoch": 0.366905155017428,
      "eval_loss": 0.5883203744888306,
      "eval_runtime": 237.62,
      "eval_samples_per_second": 2.55,
      "eval_steps_per_second": 2.55,
      "step": 1000
    },
    {
      "epoch": 0.37057420656760226,
      "grad_norm": 0.74204021692276,
      "learning_rate": 4.991696134691613e-05,
      "loss": 0.6142,
      "step": 1010
    },
    {
      "epoch": 0.37424325811777653,
      "grad_norm": 1.1142209768295288,
      "learning_rate": 4.99080440521929e-05,
      "loss": 0.5405,
      "step": 1020
    },
    {
      "epoch": 0.3779123096679508,
      "grad_norm": 0.9425484538078308,
      "learning_rate": 4.9898672938043385e-05,
      "loss": 0.6005,
      "step": 1030
    },
    {
      "epoch": 0.38158136121812514,
      "grad_norm": 0.7661627531051636,
      "learning_rate": 4.988884817520732e-05,
      "loss": 0.5774,
      "step": 1040
    },
    {
      "epoch": 0.3852504127682994,
      "grad_norm": 0.8633294105529785,
      "learning_rate": 4.98785699426899e-05,
      "loss": 0.5964,
      "step": 1050
    },
    {
      "epoch": 0.3889194643184737,
      "grad_norm": 0.8688271641731262,
      "learning_rate": 4.986783842775836e-05,
      "loss": 0.5866,
      "step": 1060
    },
    {
      "epoch": 0.39258851586864796,
      "grad_norm": 0.875762403011322,
      "learning_rate": 4.9856653825938715e-05,
      "loss": 0.5631,
      "step": 1070
    },
    {
      "epoch": 0.39625756741882223,
      "grad_norm": 0.7623623609542847,
      "learning_rate": 4.9845016341012095e-05,
      "loss": 0.5777,
      "step": 1080
    },
    {
      "epoch": 0.3999266189689965,
      "grad_norm": 1.0272465944290161,
      "learning_rate": 4.9832926185011084e-05,
      "loss": 0.5653,
      "step": 1090
    },
    {
      "epoch": 0.4035956705191708,
      "grad_norm": 0.7474942207336426,
      "learning_rate": 4.9820383578215815e-05,
      "loss": 0.5838,
      "step": 1100
    },
    {
      "epoch": 0.40726472206934505,
      "grad_norm": 0.8431952595710754,
      "learning_rate": 4.980738874915001e-05,
      "loss": 0.5779,
      "step": 1110
    },
    {
      "epoch": 0.4109337736195193,
      "grad_norm": 0.7840742468833923,
      "learning_rate": 4.9793941934576774e-05,
      "loss": 0.5956,
      "step": 1120
    },
    {
      "epoch": 0.41460282516969366,
      "grad_norm": 0.7531408667564392,
      "learning_rate": 4.978004337949429e-05,
      "loss": 0.5619,
      "step": 1130
    },
    {
      "epoch": 0.41827187671986793,
      "grad_norm": 0.8034108877182007,
      "learning_rate": 4.976569333713137e-05,
      "loss": 0.5715,
      "step": 1140
    },
    {
      "epoch": 0.4219409282700422,
      "grad_norm": 0.6612378358840942,
      "learning_rate": 4.975089206894283e-05,
      "loss": 0.5776,
      "step": 1150
    },
    {
      "epoch": 0.4256099798202165,
      "grad_norm": 0.741470217704773,
      "learning_rate": 4.9735639844604706e-05,
      "loss": 0.551,
      "step": 1160
    },
    {
      "epoch": 0.42927903137039075,
      "grad_norm": 0.8484413027763367,
      "learning_rate": 4.9719936942009406e-05,
      "loss": 0.5912,
      "step": 1170
    },
    {
      "epoch": 0.432948082920565,
      "grad_norm": 0.9448020458221436,
      "learning_rate": 4.970378364726056e-05,
      "loss": 0.5932,
      "step": 1180
    },
    {
      "epoch": 0.4366171344707393,
      "grad_norm": 0.7909348011016846,
      "learning_rate": 4.968718025466788e-05,
      "loss": 0.584,
      "step": 1190
    },
    {
      "epoch": 0.4402861860209136,
      "grad_norm": 0.7125610709190369,
      "learning_rate": 4.967012706674174e-05,
      "loss": 0.5537,
      "step": 1200
    },
    {
      "epoch": 0.44395523757108785,
      "grad_norm": 0.8675113916397095,
      "learning_rate": 4.965262439418772e-05,
      "loss": 0.5583,
      "step": 1210
    },
    {
      "epoch": 0.4476242891212622,
      "grad_norm": 0.9049820303916931,
      "learning_rate": 4.96346725559009e-05,
      "loss": 0.5909,
      "step": 1220
    },
    {
      "epoch": 0.45129334067143645,
      "grad_norm": 0.9292231202125549,
      "learning_rate": 4.961627187896006e-05,
      "loss": 0.5983,
      "step": 1230
    },
    {
      "epoch": 0.4549623922216107,
      "grad_norm": 0.7964368462562561,
      "learning_rate": 4.9597422698621764e-05,
      "loss": 0.5753,
      "step": 1240
    },
    {
      "epoch": 0.458631443771785,
      "grad_norm": 0.6815668940544128,
      "learning_rate": 4.9578125358314175e-05,
      "loss": 0.5955,
      "step": 1250
    },
    {
      "epoch": 0.46230049532195927,
      "grad_norm": 0.9475581049919128,
      "learning_rate": 4.9558380209630864e-05,
      "loss": 0.5887,
      "step": 1260
    },
    {
      "epoch": 0.46596954687213354,
      "grad_norm": 1.021878719329834,
      "learning_rate": 4.953818761232435e-05,
      "loss": 0.5716,
      "step": 1270
    },
    {
      "epoch": 0.4696385984223078,
      "grad_norm": 0.915371835231781,
      "learning_rate": 4.9517547934299604e-05,
      "loss": 0.5975,
      "step": 1280
    },
    {
      "epoch": 0.4733076499724821,
      "grad_norm": 0.8428240418434143,
      "learning_rate": 4.94964615516073e-05,
      "loss": 0.5626,
      "step": 1290
    },
    {
      "epoch": 0.4769767015226564,
      "grad_norm": 0.8997093439102173,
      "learning_rate": 4.947492884843699e-05,
      "loss": 0.5735,
      "step": 1300
    },
    {
      "epoch": 0.4806457530728307,
      "grad_norm": 1.0769418478012085,
      "learning_rate": 4.945295021711008e-05,
      "loss": 0.6035,
      "step": 1310
    },
    {
      "epoch": 0.48431480462300497,
      "grad_norm": 0.9459863305091858,
      "learning_rate": 4.94305260580727e-05,
      "loss": 0.5842,
      "step": 1320
    },
    {
      "epoch": 0.48798385617317924,
      "grad_norm": 0.8330615758895874,
      "learning_rate": 4.940765677988841e-05,
      "loss": 0.5616,
      "step": 1330
    },
    {
      "epoch": 0.4916529077233535,
      "grad_norm": 0.9455893039703369,
      "learning_rate": 4.938434279923073e-05,
      "loss": 0.616,
      "step": 1340
    },
    {
      "epoch": 0.4953219592735278,
      "grad_norm": 0.8248706459999084,
      "learning_rate": 4.9360584540875585e-05,
      "loss": 0.5723,
      "step": 1350
    },
    {
      "epoch": 0.49899101082370206,
      "grad_norm": 0.7279864549636841,
      "learning_rate": 4.933638243769355e-05,
      "loss": 0.5578,
      "step": 1360
    },
    {
      "epoch": 0.5026600623738764,
      "grad_norm": 0.8937111496925354,
      "learning_rate": 4.931173693064195e-05,
      "loss": 0.5792,
      "step": 1370
    },
    {
      "epoch": 0.5063291139240507,
      "grad_norm": 0.9426361918449402,
      "learning_rate": 4.9286648468756844e-05,
      "loss": 0.5458,
      "step": 1380
    },
    {
      "epoch": 0.5099981654742249,
      "grad_norm": 0.8062474727630615,
      "learning_rate": 4.9261117509144825e-05,
      "loss": 0.5862,
      "step": 1390
    },
    {
      "epoch": 0.5136672170243992,
      "grad_norm": 0.9370191097259521,
      "learning_rate": 4.923514451697472e-05,
      "loss": 0.5358,
      "step": 1400
    },
    {
      "epoch": 0.5173362685745735,
      "grad_norm": 0.8648721575737,
      "learning_rate": 4.9208729965469087e-05,
      "loss": 0.537,
      "step": 1410
    },
    {
      "epoch": 0.5210053201247478,
      "grad_norm": 0.9978837966918945,
      "learning_rate": 4.9181874335895604e-05,
      "loss": 0.5568,
      "step": 1420
    },
    {
      "epoch": 0.524674371674922,
      "grad_norm": 0.8308568596839905,
      "learning_rate": 4.915457811755832e-05,
      "loss": 0.5836,
      "step": 1430
    },
    {
      "epoch": 0.5283434232250963,
      "grad_norm": 0.9117475152015686,
      "learning_rate": 4.912684180778869e-05,
      "loss": 0.5697,
      "step": 1440
    },
    {
      "epoch": 0.5320124747752706,
      "grad_norm": 0.7363874912261963,
      "learning_rate": 4.909866591193656e-05,
      "loss": 0.5637,
      "step": 1450
    },
    {
      "epoch": 0.5356815263254449,
      "grad_norm": 1.0187169313430786,
      "learning_rate": 4.9070050943360935e-05,
      "loss": 0.5644,
      "step": 1460
    },
    {
      "epoch": 0.5393505778756191,
      "grad_norm": 0.9083443284034729,
      "learning_rate": 4.9040997423420656e-05,
      "loss": 0.5591,
      "step": 1470
    },
    {
      "epoch": 0.5430196294257934,
      "grad_norm": 0.793476939201355,
      "learning_rate": 4.901150588146487e-05,
      "loss": 0.5445,
      "step": 1480
    },
    {
      "epoch": 0.5466886809759677,
      "grad_norm": 0.9009830951690674,
      "learning_rate": 4.8981576854823367e-05,
      "loss": 0.551,
      "step": 1490
    },
    {
      "epoch": 0.550357732526142,
      "grad_norm": 0.9271986484527588,
      "learning_rate": 4.895121088879685e-05,
      "loss": 0.5739,
      "step": 1500
    },
    {
      "epoch": 0.550357732526142,
      "eval_loss": 0.5655648708343506,
      "eval_runtime": 240.2058,
      "eval_samples_per_second": 2.523,
      "eval_steps_per_second": 2.523,
      "step": 1500
    },
    {
      "epoch": 0.5540267840763162,
      "grad_norm": 0.8860954642295837,
      "learning_rate": 4.8920408536646975e-05,
      "loss": 0.5868,
      "step": 1510
    },
    {
      "epoch": 0.5576958356264905,
      "grad_norm": 0.8972140550613403,
      "learning_rate": 4.8889170359586226e-05,
      "loss": 0.5674,
      "step": 1520
    },
    {
      "epoch": 0.5613648871766649,
      "grad_norm": 0.8974564075469971,
      "learning_rate": 4.885749692676775e-05,
      "loss": 0.5776,
      "step": 1530
    },
    {
      "epoch": 0.5650339387268392,
      "grad_norm": 0.8998370170593262,
      "learning_rate": 4.882538881527497e-05,
      "loss": 0.5535,
      "step": 1540
    },
    {
      "epoch": 0.5687029902770134,
      "grad_norm": 0.9352656006813049,
      "learning_rate": 4.8792846610111046e-05,
      "loss": 0.5702,
      "step": 1550
    },
    {
      "epoch": 0.5723720418271877,
      "grad_norm": 1.009832739830017,
      "learning_rate": 4.875987090418826e-05,
      "loss": 0.5824,
      "step": 1560
    },
    {
      "epoch": 0.576041093377362,
      "grad_norm": 0.8600253462791443,
      "learning_rate": 4.872646229831716e-05,
      "loss": 0.556,
      "step": 1570
    },
    {
      "epoch": 0.5797101449275363,
      "grad_norm": 0.7715021967887878,
      "learning_rate": 4.869262140119566e-05,
      "loss": 0.5362,
      "step": 1580
    },
    {
      "epoch": 0.5833791964777105,
      "grad_norm": 0.9116750955581665,
      "learning_rate": 4.865834882939794e-05,
      "loss": 0.5574,
      "step": 1590
    },
    {
      "epoch": 0.5870482480278848,
      "grad_norm": 0.8421168327331543,
      "learning_rate": 4.862364520736317e-05,
      "loss": 0.5805,
      "step": 1600
    },
    {
      "epoch": 0.5907172995780591,
      "grad_norm": 0.8925551772117615,
      "learning_rate": 4.858851116738419e-05,
      "loss": 0.5944,
      "step": 1610
    },
    {
      "epoch": 0.5943863511282333,
      "grad_norm": 0.8234690427780151,
      "learning_rate": 4.855294734959597e-05,
      "loss": 0.5491,
      "step": 1620
    },
    {
      "epoch": 0.5980554026784076,
      "grad_norm": 1.1261595487594604,
      "learning_rate": 4.851695440196394e-05,
      "loss": 0.568,
      "step": 1630
    },
    {
      "epoch": 0.6017244542285819,
      "grad_norm": 0.7588224411010742,
      "learning_rate": 4.8480532980272184e-05,
      "loss": 0.5545,
      "step": 1640
    },
    {
      "epoch": 0.6053935057787562,
      "grad_norm": 0.8019400238990784,
      "learning_rate": 4.844368374811149e-05,
      "loss": 0.5615,
      "step": 1650
    },
    {
      "epoch": 0.6090625573289304,
      "grad_norm": 0.9038190245628357,
      "learning_rate": 4.840640737686727e-05,
      "loss": 0.5828,
      "step": 1660
    },
    {
      "epoch": 0.6127316088791047,
      "grad_norm": 0.7243975400924683,
      "learning_rate": 4.836870454570731e-05,
      "loss": 0.5662,
      "step": 1670
    },
    {
      "epoch": 0.616400660429279,
      "grad_norm": 0.9103299975395203,
      "learning_rate": 4.833057594156944e-05,
      "loss": 0.5528,
      "step": 1680
    },
    {
      "epoch": 0.6200697119794533,
      "grad_norm": 1.1013984680175781,
      "learning_rate": 4.829202225914895e-05,
      "loss": 0.5556,
      "step": 1690
    },
    {
      "epoch": 0.6237387635296275,
      "grad_norm": 0.7952206134796143,
      "learning_rate": 4.825304420088599e-05,
      "loss": 0.5452,
      "step": 1700
    },
    {
      "epoch": 0.6274078150798019,
      "grad_norm": 0.8104619383811951,
      "learning_rate": 4.821364247695274e-05,
      "loss": 0.5591,
      "step": 1710
    },
    {
      "epoch": 0.6310768666299762,
      "grad_norm": 0.7545372247695923,
      "learning_rate": 4.8173817805240487e-05,
      "loss": 0.5738,
      "step": 1720
    },
    {
      "epoch": 0.6347459181801505,
      "grad_norm": 0.9334061145782471,
      "learning_rate": 4.813357091134654e-05,
      "loss": 0.5709,
      "step": 1730
    },
    {
      "epoch": 0.6384149697303247,
      "grad_norm": 0.6794409155845642,
      "learning_rate": 4.8092902528561e-05,
      "loss": 0.591,
      "step": 1740
    },
    {
      "epoch": 0.642084021280499,
      "grad_norm": 1.0061829090118408,
      "learning_rate": 4.805181339785342e-05,
      "loss": 0.5723,
      "step": 1750
    },
    {
      "epoch": 0.6457530728306733,
      "grad_norm": 1.2289650440216064,
      "learning_rate": 4.801030426785928e-05,
      "loss": 0.5788,
      "step": 1760
    },
    {
      "epoch": 0.6494221243808476,
      "grad_norm": 1.067782998085022,
      "learning_rate": 4.796837589486639e-05,
      "loss": 0.5468,
      "step": 1770
    },
    {
      "epoch": 0.6530911759310218,
      "grad_norm": 0.8999747037887573,
      "learning_rate": 4.792602904280104e-05,
      "loss": 0.5634,
      "step": 1780
    },
    {
      "epoch": 0.6567602274811961,
      "grad_norm": 0.8649622797966003,
      "learning_rate": 4.788326448321415e-05,
      "loss": 0.5892,
      "step": 1790
    },
    {
      "epoch": 0.6604292790313704,
      "grad_norm": 0.863810122013092,
      "learning_rate": 4.784008299526716e-05,
      "loss": 0.5562,
      "step": 1800
    },
    {
      "epoch": 0.6640983305815447,
      "grad_norm": 0.8143636584281921,
      "learning_rate": 4.779648536571791e-05,
      "loss": 0.5553,
      "step": 1810
    },
    {
      "epoch": 0.6677673821317189,
      "grad_norm": 0.9549927115440369,
      "learning_rate": 4.775247238890619e-05,
      "loss": 0.5448,
      "step": 1820
    },
    {
      "epoch": 0.6714364336818932,
      "grad_norm": 1.003637671470642,
      "learning_rate": 4.770804486673938e-05,
      "loss": 0.5678,
      "step": 1830
    },
    {
      "epoch": 0.6751054852320675,
      "grad_norm": 0.825347363948822,
      "learning_rate": 4.766320360867775e-05,
      "loss": 0.5374,
      "step": 1840
    },
    {
      "epoch": 0.6787745367822418,
      "grad_norm": 1.002130150794983,
      "learning_rate": 4.76179494317198e-05,
      "loss": 0.5441,
      "step": 1850
    },
    {
      "epoch": 0.682443588332416,
      "grad_norm": 0.9000377655029297,
      "learning_rate": 4.757228316038729e-05,
      "loss": 0.5404,
      "step": 1860
    },
    {
      "epoch": 0.6861126398825903,
      "grad_norm": 0.7789478302001953,
      "learning_rate": 4.752620562671027e-05,
      "loss": 0.5275,
      "step": 1870
    },
    {
      "epoch": 0.6897816914327646,
      "grad_norm": 0.7302083969116211,
      "learning_rate": 4.7479717670211904e-05,
      "loss": 0.5562,
      "step": 1880
    },
    {
      "epoch": 0.693450742982939,
      "grad_norm": 0.8888310194015503,
      "learning_rate": 4.743282013789316e-05,
      "loss": 0.5606,
      "step": 1890
    },
    {
      "epoch": 0.6971197945331132,
      "grad_norm": 0.8932925462722778,
      "learning_rate": 4.738551388421743e-05,
      "loss": 0.5819,
      "step": 1900
    },
    {
      "epoch": 0.7007888460832875,
      "grad_norm": 0.8947935700416565,
      "learning_rate": 4.733779977109487e-05,
      "loss": 0.5537,
      "step": 1910
    },
    {
      "epoch": 0.7044578976334618,
      "grad_norm": 0.8630931973457336,
      "learning_rate": 4.728967866786681e-05,
      "loss": 0.5539,
      "step": 1920
    },
    {
      "epoch": 0.7081269491836361,
      "grad_norm": 0.8323912024497986,
      "learning_rate": 4.7241151451289813e-05,
      "loss": 0.5714,
      "step": 1930
    },
    {
      "epoch": 0.7117960007338103,
      "grad_norm": 0.8414443731307983,
      "learning_rate": 4.719221900551976e-05,
      "loss": 0.5625,
      "step": 1940
    },
    {
      "epoch": 0.7154650522839846,
      "grad_norm": 0.8163629174232483,
      "learning_rate": 4.714288222209573e-05,
      "loss": 0.5594,
      "step": 1950
    },
    {
      "epoch": 0.7191341038341589,
      "grad_norm": 0.9008724689483643,
      "learning_rate": 4.7093141999923726e-05,
      "loss": 0.5762,
      "step": 1960
    },
    {
      "epoch": 0.7228031553843332,
      "grad_norm": 0.8228312730789185,
      "learning_rate": 4.7042999245260356e-05,
      "loss": 0.5703,
      "step": 1970
    },
    {
      "epoch": 0.7264722069345074,
      "grad_norm": 1.0673984289169312,
      "learning_rate": 4.6992454871696265e-05,
      "loss": 0.57,
      "step": 1980
    },
    {
      "epoch": 0.7301412584846817,
      "grad_norm": 0.7121770977973938,
      "learning_rate": 4.694150980013952e-05,
      "loss": 0.5426,
      "step": 1990
    },
    {
      "epoch": 0.733810310034856,
      "grad_norm": 0.7347238063812256,
      "learning_rate": 4.68901649587988e-05,
      "loss": 0.5766,
      "step": 2000
    },
    {
      "epoch": 0.733810310034856,
      "eval_loss": 0.552966833114624,
      "eval_runtime": 240.4235,
      "eval_samples_per_second": 2.521,
      "eval_steps_per_second": 2.521,
      "step": 2000
    },
    {
      "epoch": 0.7374793615850302,
      "grad_norm": 0.8168190121650696,
      "learning_rate": 4.683842128316655e-05,
      "loss": 0.568,
      "step": 2010
    },
    {
      "epoch": 0.7411484131352045,
      "grad_norm": 0.9358319044113159,
      "learning_rate": 4.6786279716001855e-05,
      "loss": 0.5794,
      "step": 2020
    },
    {
      "epoch": 0.7448174646853788,
      "grad_norm": 0.8422871828079224,
      "learning_rate": 4.673374120731333e-05,
      "loss": 0.5553,
      "step": 2030
    },
    {
      "epoch": 0.7484865162355531,
      "grad_norm": 0.9374701976776123,
      "learning_rate": 4.6680806714341765e-05,
      "loss": 0.5456,
      "step": 2040
    },
    {
      "epoch": 0.7521555677857273,
      "grad_norm": 0.9011454582214355,
      "learning_rate": 4.662747720154269e-05,
      "loss": 0.5508,
      "step": 2050
    },
    {
      "epoch": 0.7558246193359016,
      "grad_norm": 1.0650379657745361,
      "learning_rate": 4.657375364056885e-05,
      "loss": 0.5661,
      "step": 2060
    },
    {
      "epoch": 0.759493670886076,
      "grad_norm": 0.9504855275154114,
      "learning_rate": 4.651963701025244e-05,
      "loss": 0.5852,
      "step": 2070
    },
    {
      "epoch": 0.7631627224362503,
      "grad_norm": 0.7971680760383606,
      "learning_rate": 4.646512829658731e-05,
      "loss": 0.5335,
      "step": 2080
    },
    {
      "epoch": 0.7668317739864245,
      "grad_norm": 0.7174059748649597,
      "learning_rate": 4.641022849271097e-05,
      "loss": 0.5579,
      "step": 2090
    },
    {
      "epoch": 0.7705008255365988,
      "grad_norm": 0.8644967675209045,
      "learning_rate": 4.6354938598886544e-05,
      "loss": 0.5464,
      "step": 2100
    },
    {
      "epoch": 0.7741698770867731,
      "grad_norm": 0.6945546269416809,
      "learning_rate": 4.6299259622484486e-05,
      "loss": 0.5209,
      "step": 2110
    },
    {
      "epoch": 0.7778389286369474,
      "grad_norm": 0.7372620105743408,
      "learning_rate": 4.624319257796426e-05,
      "loss": 0.539,
      "step": 2120
    },
    {
      "epoch": 0.7815079801871216,
      "grad_norm": 0.9778143167495728,
      "learning_rate": 4.618673848685586e-05,
      "loss": 0.5722,
      "step": 2130
    },
    {
      "epoch": 0.7851770317372959,
      "grad_norm": 0.6679160594940186,
      "learning_rate": 4.612989837774119e-05,
      "loss": 0.5572,
      "step": 2140
    },
    {
      "epoch": 0.7888460832874702,
      "grad_norm": 0.7771591544151306,
      "learning_rate": 4.607267328623531e-05,
      "loss": 0.5798,
      "step": 2150
    },
    {
      "epoch": 0.7925151348376445,
      "grad_norm": 0.8083762526512146,
      "learning_rate": 4.601506425496759e-05,
      "loss": 0.558,
      "step": 2160
    },
    {
      "epoch": 0.7961841863878187,
      "grad_norm": 0.9205446243286133,
      "learning_rate": 4.59570723335627e-05,
      "loss": 0.5284,
      "step": 2170
    },
    {
      "epoch": 0.799853237937993,
      "grad_norm": 0.784064531326294,
      "learning_rate": 4.589869857862148e-05,
      "loss": 0.5276,
      "step": 2180
    },
    {
      "epoch": 0.8035222894881673,
      "grad_norm": 0.7402964234352112,
      "learning_rate": 4.583994405370172e-05,
      "loss": 0.5354,
      "step": 2190
    },
    {
      "epoch": 0.8071913410383416,
      "grad_norm": 1.0059432983398438,
      "learning_rate": 4.5780809829298746e-05,
      "loss": 0.5488,
      "step": 2200
    },
    {
      "epoch": 0.8108603925885158,
      "grad_norm": 0.6676888465881348,
      "learning_rate": 4.572129698282592e-05,
      "loss": 0.553,
      "step": 2210
    },
    {
      "epoch": 0.8145294441386901,
      "grad_norm": 0.8007650375366211,
      "learning_rate": 4.566140659859505e-05,
      "loss": 0.5743,
      "step": 2220
    },
    {
      "epoch": 0.8181984956888644,
      "grad_norm": 0.9345247745513916,
      "learning_rate": 4.5601139767796586e-05,
      "loss": 0.5545,
      "step": 2230
    },
    {
      "epoch": 0.8218675472390387,
      "grad_norm": 0.7873967289924622,
      "learning_rate": 4.5540497588479746e-05,
      "loss": 0.5255,
      "step": 2240
    },
    {
      "epoch": 0.825536598789213,
      "grad_norm": 0.867009162902832,
      "learning_rate": 4.547948116553253e-05,
      "loss": 0.5429,
      "step": 2250
    },
    {
      "epoch": 0.8292056503393873,
      "grad_norm": 0.9745082259178162,
      "learning_rate": 4.541809161066159e-05,
      "loss": 0.5529,
      "step": 2260
    },
    {
      "epoch": 0.8328747018895616,
      "grad_norm": 1.0054662227630615,
      "learning_rate": 4.535633004237196e-05,
      "loss": 0.5541,
      "step": 2270
    },
    {
      "epoch": 0.8365437534397359,
      "grad_norm": 1.0356608629226685,
      "learning_rate": 4.529419758594667e-05,
      "loss": 0.5627,
      "step": 2280
    },
    {
      "epoch": 0.8402128049899101,
      "grad_norm": 0.7988411784172058,
      "learning_rate": 4.5231695373426275e-05,
      "loss": 0.5528,
      "step": 2290
    },
    {
      "epoch": 0.8438818565400844,
      "grad_norm": 0.8256310224533081,
      "learning_rate": 4.5168824543588184e-05,
      "loss": 0.5406,
      "step": 2300
    },
    {
      "epoch": 0.8475509080902587,
      "grad_norm": 0.9598526954650879,
      "learning_rate": 4.510558624192596e-05,
      "loss": 0.5512,
      "step": 2310
    },
    {
      "epoch": 0.851219959640433,
      "grad_norm": 0.7551243901252747,
      "learning_rate": 4.5041981620628414e-05,
      "loss": 0.5419,
      "step": 2320
    },
    {
      "epoch": 0.8548890111906072,
      "grad_norm": 0.8776786923408508,
      "learning_rate": 4.497801183855864e-05,
      "loss": 0.5443,
      "step": 2330
    },
    {
      "epoch": 0.8585580627407815,
      "grad_norm": 0.8410866856575012,
      "learning_rate": 4.491367806123286e-05,
      "loss": 0.5456,
      "step": 2340
    },
    {
      "epoch": 0.8622271142909558,
      "grad_norm": 0.988510012626648,
      "learning_rate": 4.4848981460799244e-05,
      "loss": 0.543,
      "step": 2350
    },
    {
      "epoch": 0.86589616584113,
      "grad_norm": 0.8719709515571594,
      "learning_rate": 4.478392321601651e-05,
      "loss": 0.542,
      "step": 2360
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 1.034745454788208,
      "learning_rate": 4.471850451223245e-05,
      "loss": 0.528,
      "step": 2370
    },
    {
      "epoch": 0.8732342689414786,
      "grad_norm": 0.8525258302688599,
      "learning_rate": 4.465272654136237e-05,
      "loss": 0.5534,
      "step": 2380
    },
    {
      "epoch": 0.8769033204916529,
      "grad_norm": 1.0630966424942017,
      "learning_rate": 4.458659050186733e-05,
      "loss": 0.5378,
      "step": 2390
    },
    {
      "epoch": 0.8805723720418271,
      "grad_norm": 1.0998499393463135,
      "learning_rate": 4.452009759873233e-05,
      "loss": 0.5527,
      "step": 2400
    },
    {
      "epoch": 0.8842414235920014,
      "grad_norm": 0.688452422618866,
      "learning_rate": 4.4453249043444364e-05,
      "loss": 0.5407,
      "step": 2410
    },
    {
      "epoch": 0.8879104751421757,
      "grad_norm": 0.8851842284202576,
      "learning_rate": 4.438604605397031e-05,
      "loss": 0.5335,
      "step": 2420
    },
    {
      "epoch": 0.8915795266923501,
      "grad_norm": 0.9860828518867493,
      "learning_rate": 4.4318489854734776e-05,
      "loss": 0.5513,
      "step": 2430
    },
    {
      "epoch": 0.8952485782425244,
      "grad_norm": 0.9076856374740601,
      "learning_rate": 4.42505816765978e-05,
      "loss": 0.5733,
      "step": 2440
    },
    {
      "epoch": 0.8989176297926986,
      "grad_norm": 0.7030923962593079,
      "learning_rate": 4.4182322756832374e-05,
      "loss": 0.5686,
      "step": 2450
    },
    {
      "epoch": 0.9025866813428729,
      "grad_norm": 1.1286635398864746,
      "learning_rate": 4.411371433910193e-05,
      "loss": 0.5851,
      "step": 2460
    },
    {
      "epoch": 0.9062557328930472,
      "grad_norm": 0.9608522057533264,
      "learning_rate": 4.404475767343772e-05,
      "loss": 0.5353,
      "step": 2470
    },
    {
      "epoch": 0.9099247844432214,
      "grad_norm": 1.1069785356521606,
      "learning_rate": 4.397545401621593e-05,
      "loss": 0.5311,
      "step": 2480
    },
    {
      "epoch": 0.9135938359933957,
      "grad_norm": 0.8005871772766113,
      "learning_rate": 4.390580463013494e-05,
      "loss": 0.5616,
      "step": 2490
    },
    {
      "epoch": 0.91726288754357,
      "grad_norm": 1.1311414241790771,
      "learning_rate": 4.383581078419219e-05,
      "loss": 0.525,
      "step": 2500
    },
    {
      "epoch": 0.91726288754357,
      "eval_loss": 0.5432298183441162,
      "eval_runtime": 241.2137,
      "eval_samples_per_second": 2.512,
      "eval_steps_per_second": 2.512,
      "step": 2500
    },
    {
      "epoch": 0.9209319390937443,
      "grad_norm": 0.9654207229614258,
      "learning_rate": 4.376547375366111e-05,
      "loss": 0.5387,
      "step": 2510
    },
    {
      "epoch": 0.9246009906439185,
      "grad_norm": 0.7038743495941162,
      "learning_rate": 4.369479482006791e-05,
      "loss": 0.5372,
      "step": 2520
    },
    {
      "epoch": 0.9282700421940928,
      "grad_norm": 0.8052876591682434,
      "learning_rate": 4.3623775271168164e-05,
      "loss": 0.5486,
      "step": 2530
    },
    {
      "epoch": 0.9319390937442671,
      "grad_norm": 0.8348866105079651,
      "learning_rate": 4.3552416400923425e-05,
      "loss": 0.5299,
      "step": 2540
    },
    {
      "epoch": 0.9356081452944414,
      "grad_norm": 0.7724452614784241,
      "learning_rate": 4.348071950947759e-05,
      "loss": 0.5268,
      "step": 2550
    },
    {
      "epoch": 0.9392771968446156,
      "grad_norm": 1.0534683465957642,
      "learning_rate": 4.340868590313324e-05,
      "loss": 0.5523,
      "step": 2560
    },
    {
      "epoch": 0.9429462483947899,
      "grad_norm": 1.1290223598480225,
      "learning_rate": 4.333631689432781e-05,
      "loss": 0.5329,
      "step": 2570
    },
    {
      "epoch": 0.9466152999449642,
      "grad_norm": 0.862647533416748,
      "learning_rate": 4.3263613801609734e-05,
      "loss": 0.541,
      "step": 2580
    },
    {
      "epoch": 0.9502843514951385,
      "grad_norm": 0.9960070252418518,
      "learning_rate": 4.319057794961437e-05,
      "loss": 0.5519,
      "step": 2590
    },
    {
      "epoch": 0.9539534030453128,
      "grad_norm": 0.9242678284645081,
      "learning_rate": 4.311721066903988e-05,
      "loss": 0.5542,
      "step": 2600
    },
    {
      "epoch": 0.9576224545954871,
      "grad_norm": 0.9528604745864868,
      "learning_rate": 4.3043513296622974e-05,
      "loss": 0.5713,
      "step": 2610
    },
    {
      "epoch": 0.9612915061456614,
      "grad_norm": 0.9879667162895203,
      "learning_rate": 4.296948717511459e-05,
      "loss": 0.5486,
      "step": 2620
    },
    {
      "epoch": 0.9649605576958357,
      "grad_norm": 0.6862794756889343,
      "learning_rate": 4.2895133653255396e-05,
      "loss": 0.4993,
      "step": 2630
    },
    {
      "epoch": 0.9686296092460099,
      "grad_norm": 0.9930823445320129,
      "learning_rate": 4.2820454085751225e-05,
      "loss": 0.5165,
      "step": 2640
    },
    {
      "epoch": 0.9722986607961842,
      "grad_norm": 0.8407339453697205,
      "learning_rate": 4.274544983324841e-05,
      "loss": 0.5392,
      "step": 2650
    },
    {
      "epoch": 0.9759677123463585,
      "grad_norm": 0.9661375880241394,
      "learning_rate": 4.267012226230894e-05,
      "loss": 0.5544,
      "step": 2660
    },
    {
      "epoch": 0.9796367638965328,
      "grad_norm": 0.7821788787841797,
      "learning_rate": 4.259447274538565e-05,
      "loss": 0.5233,
      "step": 2670
    },
    {
      "epoch": 0.983305815446707,
      "grad_norm": 0.850843608379364,
      "learning_rate": 4.251850266079712e-05,
      "loss": 0.5274,
      "step": 2680
    },
    {
      "epoch": 0.9869748669968813,
      "grad_norm": 0.9794067144393921,
      "learning_rate": 4.2442213392702635e-05,
      "loss": 0.5513,
      "step": 2690
    },
    {
      "epoch": 0.9906439185470556,
      "grad_norm": 0.8385506868362427,
      "learning_rate": 4.2365606331076925e-05,
      "loss": 0.5775,
      "step": 2700
    },
    {
      "epoch": 0.9943129700972299,
      "grad_norm": 0.9123114347457886,
      "learning_rate": 4.2288682871684857e-05,
      "loss": 0.5587,
      "step": 2710
    },
    {
      "epoch": 0.9979820216474041,
      "grad_norm": 0.7605298161506653,
      "learning_rate": 4.2211444416056e-05,
      "loss": 0.5513,
      "step": 2720
    },
    {
      "epoch": 1.0014676206200697,
      "grad_norm": 0.7635568380355835,
      "learning_rate": 4.2133892371459074e-05,
      "loss": 0.5474,
      "step": 2730
    },
    {
      "epoch": 1.005136672170244,
      "grad_norm": 0.7955774664878845,
      "learning_rate": 4.2056028150876356e-05,
      "loss": 0.5035,
      "step": 2740
    },
    {
      "epoch": 1.0088057237204182,
      "grad_norm": 0.9981663823127747,
      "learning_rate": 4.1977853172977885e-05,
      "loss": 0.5216,
      "step": 2750
    },
    {
      "epoch": 1.0124747752705925,
      "grad_norm": 0.9269798398017883,
      "learning_rate": 4.189936886209563e-05,
      "loss": 0.5254,
      "step": 2760
    },
    {
      "epoch": 1.0161438268207668,
      "grad_norm": 0.8262214660644531,
      "learning_rate": 4.182057664819757e-05,
      "loss": 0.4942,
      "step": 2770
    },
    {
      "epoch": 1.019812878370941,
      "grad_norm": 0.922914445400238,
      "learning_rate": 4.174147796686158e-05,
      "loss": 0.5553,
      "step": 2780
    },
    {
      "epoch": 1.0234819299211153,
      "grad_norm": 1.0055451393127441,
      "learning_rate": 4.1662074259249305e-05,
      "loss": 0.5247,
      "step": 2790
    },
    {
      "epoch": 1.0271509814712896,
      "grad_norm": 0.9538084864616394,
      "learning_rate": 4.158236697207996e-05,
      "loss": 0.5204,
      "step": 2800
    },
    {
      "epoch": 1.0308200330214639,
      "grad_norm": 1.0916240215301514,
      "learning_rate": 4.1502357557603856e-05,
      "loss": 0.5386,
      "step": 2810
    },
    {
      "epoch": 1.0344890845716381,
      "grad_norm": 0.9748235940933228,
      "learning_rate": 4.142204747357604e-05,
      "loss": 0.5763,
      "step": 2820
    },
    {
      "epoch": 1.0381581361218126,
      "grad_norm": 0.7713705897331238,
      "learning_rate": 4.134143818322967e-05,
      "loss": 0.5162,
      "step": 2830
    },
    {
      "epoch": 1.041827187671987,
      "grad_norm": 0.8903515338897705,
      "learning_rate": 4.1260531155249397e-05,
      "loss": 0.525,
      "step": 2840
    },
    {
      "epoch": 1.0454962392221612,
      "grad_norm": 0.9214364290237427,
      "learning_rate": 4.117932786374459e-05,
      "loss": 0.5369,
      "step": 2850
    },
    {
      "epoch": 1.0491652907723354,
      "grad_norm": 0.7038514614105225,
      "learning_rate": 4.109782978822248e-05,
      "loss": 0.5196,
      "step": 2860
    },
    {
      "epoch": 1.0528343423225097,
      "grad_norm": 0.8205967545509338,
      "learning_rate": 4.1016038413561186e-05,
      "loss": 0.5065,
      "step": 2870
    },
    {
      "epoch": 1.056503393872684,
      "grad_norm": 0.8811222314834595,
      "learning_rate": 4.093395522998269e-05,
      "loss": 0.5115,
      "step": 2880
    },
    {
      "epoch": 1.0601724454228583,
      "grad_norm": 0.8891407251358032,
      "learning_rate": 4.085158173302568e-05,
      "loss": 0.5174,
      "step": 2890
    },
    {
      "epoch": 1.0638414969730325,
      "grad_norm": 0.887023389339447,
      "learning_rate": 4.076891942351827e-05,
      "loss": 0.5155,
      "step": 2900
    },
    {
      "epoch": 1.0675105485232068,
      "grad_norm": 0.9760738611221313,
      "learning_rate": 4.068596980755071e-05,
      "loss": 0.4976,
      "step": 2910
    },
    {
      "epoch": 1.071179600073381,
      "grad_norm": 1.1278280019760132,
      "learning_rate": 4.060273439644787e-05,
      "loss": 0.5324,
      "step": 2920
    },
    {
      "epoch": 1.0748486516235554,
      "grad_norm": 0.9721632599830627,
      "learning_rate": 4.0519214706741816e-05,
      "loss": 0.4998,
      "step": 2930
    },
    {
      "epoch": 1.0785177031737296,
      "grad_norm": 1.069064974784851,
      "learning_rate": 4.0435412260144034e-05,
      "loss": 0.534,
      "step": 2940
    },
    {
      "epoch": 1.082186754723904,
      "grad_norm": 0.8873580098152161,
      "learning_rate": 4.035132858351785e-05,
      "loss": 0.4854,
      "step": 2950
    },
    {
      "epoch": 1.0858558062740782,
      "grad_norm": 0.9535754919052124,
      "learning_rate": 4.026696520885049e-05,
      "loss": 0.5328,
      "step": 2960
    },
    {
      "epoch": 1.0895248578242525,
      "grad_norm": 0.9886404871940613,
      "learning_rate": 4.0182323673225255e-05,
      "loss": 0.5672,
      "step": 2970
    },
    {
      "epoch": 1.0931939093744267,
      "grad_norm": 0.8983646631240845,
      "learning_rate": 4.009740551879347e-05,
      "loss": 0.4869,
      "step": 2980
    },
    {
      "epoch": 1.096862960924601,
      "grad_norm": 1.092265248298645,
      "learning_rate": 4.00122122927464e-05,
      "loss": 0.5259,
      "step": 2990
    },
    {
      "epoch": 1.1005320124747753,
      "grad_norm": 0.9941574335098267,
      "learning_rate": 3.9926745547287044e-05,
      "loss": 0.5286,
      "step": 3000
    },
    {
      "epoch": 1.1005320124747753,
      "eval_loss": 0.5367289781570435,
      "eval_runtime": 239.7673,
      "eval_samples_per_second": 2.527,
      "eval_steps_per_second": 2.527,
      "step": 3000
    },
    {
      "epoch": 1.1042010640249496,
      "grad_norm": 1.0637037754058838,
      "learning_rate": 3.984100683960189e-05,
      "loss": 0.546,
      "step": 3010
    },
    {
      "epoch": 1.1078701155751238,
      "grad_norm": 0.7903811931610107,
      "learning_rate": 3.97549977318325e-05,
      "loss": 0.5193,
      "step": 3020
    },
    {
      "epoch": 1.111539167125298,
      "grad_norm": 1.04246985912323,
      "learning_rate": 3.9668719791047106e-05,
      "loss": 0.4993,
      "step": 3030
    },
    {
      "epoch": 1.1152082186754724,
      "grad_norm": 1.1459685564041138,
      "learning_rate": 3.958217458921197e-05,
      "loss": 0.5275,
      "step": 3040
    },
    {
      "epoch": 1.1188772702256466,
      "grad_norm": 0.8469519019126892,
      "learning_rate": 3.949536370316285e-05,
      "loss": 0.523,
      "step": 3050
    },
    {
      "epoch": 1.122546321775821,
      "grad_norm": 0.8984081149101257,
      "learning_rate": 3.940828871457616e-05,
      "loss": 0.4932,
      "step": 3060
    },
    {
      "epoch": 1.1262153733259952,
      "grad_norm": 0.8882035613059998,
      "learning_rate": 3.932095120994025e-05,
      "loss": 0.4785,
      "step": 3070
    },
    {
      "epoch": 1.1298844248761695,
      "grad_norm": 1.0641158819198608,
      "learning_rate": 3.9233352780526446e-05,
      "loss": 0.5181,
      "step": 3080
    },
    {
      "epoch": 1.1335534764263437,
      "grad_norm": 1.1235672235488892,
      "learning_rate": 3.914549502236007e-05,
      "loss": 0.5176,
      "step": 3090
    },
    {
      "epoch": 1.137222527976518,
      "grad_norm": 1.1215784549713135,
      "learning_rate": 3.905737953619135e-05,
      "loss": 0.4993,
      "step": 3100
    },
    {
      "epoch": 1.1408915795266923,
      "grad_norm": 0.7564018964767456,
      "learning_rate": 3.8969007927466286e-05,
      "loss": 0.531,
      "step": 3110
    },
    {
      "epoch": 1.1445606310768666,
      "grad_norm": 0.898160457611084,
      "learning_rate": 3.888038180629735e-05,
      "loss": 0.5125,
      "step": 3120
    },
    {
      "epoch": 1.1482296826270408,
      "grad_norm": 1.1156057119369507,
      "learning_rate": 3.87915027874342e-05,
      "loss": 0.5102,
      "step": 3130
    },
    {
      "epoch": 1.1518987341772151,
      "grad_norm": 0.9025706648826599,
      "learning_rate": 3.870237249023424e-05,
      "loss": 0.5284,
      "step": 3140
    },
    {
      "epoch": 1.1555677857273894,
      "grad_norm": 0.9641231298446655,
      "learning_rate": 3.861299253863309e-05,
      "loss": 0.5072,
      "step": 3150
    },
    {
      "epoch": 1.1592368372775637,
      "grad_norm": 1.1992841958999634,
      "learning_rate": 3.852336456111505e-05,
      "loss": 0.5113,
      "step": 3160
    },
    {
      "epoch": 1.162905888827738,
      "grad_norm": 0.9995589256286621,
      "learning_rate": 3.843349019068338e-05,
      "loss": 0.5323,
      "step": 3170
    },
    {
      "epoch": 1.1665749403779122,
      "grad_norm": 1.133537769317627,
      "learning_rate": 3.834337106483059e-05,
      "loss": 0.5342,
      "step": 3180
    },
    {
      "epoch": 1.1702439919280865,
      "grad_norm": 0.9323656558990479,
      "learning_rate": 3.825300882550855e-05,
      "loss": 0.5328,
      "step": 3190
    },
    {
      "epoch": 1.1739130434782608,
      "grad_norm": 0.871662974357605,
      "learning_rate": 3.8162405119098646e-05,
      "loss": 0.5209,
      "step": 3200
    },
    {
      "epoch": 1.177582095028435,
      "grad_norm": 0.9234001040458679,
      "learning_rate": 3.807156159638171e-05,
      "loss": 0.5174,
      "step": 3210
    },
    {
      "epoch": 1.1812511465786095,
      "grad_norm": 1.092403769493103,
      "learning_rate": 3.7980479912507994e-05,
      "loss": 0.5018,
      "step": 3220
    },
    {
      "epoch": 1.1849201981287838,
      "grad_norm": 1.297141194343567,
      "learning_rate": 3.7889161726967006e-05,
      "loss": 0.5119,
      "step": 3230
    },
    {
      "epoch": 1.188589249678958,
      "grad_norm": 0.7372556328773499,
      "learning_rate": 3.779760870355724e-05,
      "loss": 0.5086,
      "step": 3240
    },
    {
      "epoch": 1.1922583012291323,
      "grad_norm": 0.826324999332428,
      "learning_rate": 3.7705822510355925e-05,
      "loss": 0.5023,
      "step": 3250
    },
    {
      "epoch": 1.1959273527793066,
      "grad_norm": 0.9262144565582275,
      "learning_rate": 3.7613804819688555e-05,
      "loss": 0.4995,
      "step": 3260
    },
    {
      "epoch": 1.199596404329481,
      "grad_norm": 0.9617217183113098,
      "learning_rate": 3.752155730809849e-05,
      "loss": 0.4849,
      "step": 3270
    },
    {
      "epoch": 1.2032654558796552,
      "grad_norm": 0.7965459823608398,
      "learning_rate": 3.742908165631636e-05,
      "loss": 0.5156,
      "step": 3280
    },
    {
      "epoch": 1.2069345074298294,
      "grad_norm": 1.0194956064224243,
      "learning_rate": 3.733637954922948e-05,
      "loss": 0.5094,
      "step": 3290
    },
    {
      "epoch": 1.2106035589800037,
      "grad_norm": 0.9794409275054932,
      "learning_rate": 3.724345267585112e-05,
      "loss": 0.4974,
      "step": 3300
    },
    {
      "epoch": 1.214272610530178,
      "grad_norm": 0.9531334042549133,
      "learning_rate": 3.7150302729289744e-05,
      "loss": 0.5362,
      "step": 3310
    },
    {
      "epoch": 1.2179416620803523,
      "grad_norm": 1.0231926441192627,
      "learning_rate": 3.7056931406718176e-05,
      "loss": 0.5352,
      "step": 3320
    },
    {
      "epoch": 1.2216107136305265,
      "grad_norm": 0.9047032594680786,
      "learning_rate": 3.6963340409342666e-05,
      "loss": 0.5065,
      "step": 3330
    },
    {
      "epoch": 1.2252797651807008,
      "grad_norm": 0.8732335567474365,
      "learning_rate": 3.6869531442371876e-05,
      "loss": 0.4992,
      "step": 3340
    },
    {
      "epoch": 1.228948816730875,
      "grad_norm": 1.000060796737671,
      "learning_rate": 3.6775506214985836e-05,
      "loss": 0.5386,
      "step": 3350
    },
    {
      "epoch": 1.2326178682810494,
      "grad_norm": 0.9516342282295227,
      "learning_rate": 3.668126644030482e-05,
      "loss": 0.5169,
      "step": 3360
    },
    {
      "epoch": 1.2362869198312236,
      "grad_norm": 0.9891219139099121,
      "learning_rate": 3.658681383535807e-05,
      "loss": 0.5115,
      "step": 3370
    },
    {
      "epoch": 1.239955971381398,
      "grad_norm": 0.8148437738418579,
      "learning_rate": 3.649215012105258e-05,
      "loss": 0.5023,
      "step": 3380
    },
    {
      "epoch": 1.2436250229315722,
      "grad_norm": 1.100064992904663,
      "learning_rate": 3.6397277022141694e-05,
      "loss": 0.5289,
      "step": 3390
    },
    {
      "epoch": 1.2472940744817465,
      "grad_norm": 0.722948431968689,
      "learning_rate": 3.6302196267193726e-05,
      "loss": 0.4907,
      "step": 3400
    },
    {
      "epoch": 1.2509631260319207,
      "grad_norm": 1.1131923198699951,
      "learning_rate": 3.620690958856042e-05,
      "loss": 0.5241,
      "step": 3410
    },
    {
      "epoch": 1.254632177582095,
      "grad_norm": 0.9331019520759583,
      "learning_rate": 3.61114187223454e-05,
      "loss": 0.5172,
      "step": 3420
    },
    {
      "epoch": 1.2583012291322693,
      "grad_norm": 0.8633185029029846,
      "learning_rate": 3.6015725408372565e-05,
      "loss": 0.5238,
      "step": 3430
    },
    {
      "epoch": 1.2619702806824435,
      "grad_norm": 0.8492324352264404,
      "learning_rate": 3.591983139015436e-05,
      "loss": 0.4956,
      "step": 3440
    },
    {
      "epoch": 1.2656393322326178,
      "grad_norm": 0.9706494808197021,
      "learning_rate": 3.5823738414860025e-05,
      "loss": 0.5126,
      "step": 3450
    },
    {
      "epoch": 1.269308383782792,
      "grad_norm": 1.0284154415130615,
      "learning_rate": 3.572744823328376e-05,
      "loss": 0.5023,
      "step": 3460
    },
    {
      "epoch": 1.2729774353329664,
      "grad_norm": 1.0125406980514526,
      "learning_rate": 3.56309625998128e-05,
      "loss": 0.5085,
      "step": 3470
    },
    {
      "epoch": 1.2766464868831406,
      "grad_norm": 0.9410109519958496,
      "learning_rate": 3.553428327239551e-05,
      "loss": 0.5166,
      "step": 3480
    },
    {
      "epoch": 1.280315538433315,
      "grad_norm": 0.8887771964073181,
      "learning_rate": 3.543741201250929e-05,
      "loss": 0.5128,
      "step": 3490
    },
    {
      "epoch": 1.2839845899834892,
      "grad_norm": 1.0279946327209473,
      "learning_rate": 3.534035058512851e-05,
      "loss": 0.5439,
      "step": 3500
    },
    {
      "epoch": 1.2839845899834892,
      "eval_loss": 0.5326447486877441,
      "eval_runtime": 231.1877,
      "eval_samples_per_second": 2.621,
      "eval_steps_per_second": 2.621,
      "step": 3500
    },
    {
      "epoch": 1.2876536415336637,
      "grad_norm": 0.8505242466926575,
      "learning_rate": 3.5243100758692386e-05,
      "loss": 0.4946,
      "step": 3510
    },
    {
      "epoch": 1.291322693083838,
      "grad_norm": 0.8635669946670532,
      "learning_rate": 3.514566430507268e-05,
      "loss": 0.4952,
      "step": 3520
    },
    {
      "epoch": 1.2949917446340122,
      "grad_norm": 1.0726934671401978,
      "learning_rate": 3.504804299954149e-05,
      "loss": 0.5287,
      "step": 3530
    },
    {
      "epoch": 1.2986607961841865,
      "grad_norm": 0.9249968528747559,
      "learning_rate": 3.495023862073887e-05,
      "loss": 0.5158,
      "step": 3540
    },
    {
      "epoch": 1.3023298477343608,
      "grad_norm": 1.1182197332382202,
      "learning_rate": 3.485225295064044e-05,
      "loss": 0.5082,
      "step": 3550
    },
    {
      "epoch": 1.305998899284535,
      "grad_norm": 1.0571675300598145,
      "learning_rate": 3.4754087774524905e-05,
      "loss": 0.5325,
      "step": 3560
    },
    {
      "epoch": 1.3096679508347093,
      "grad_norm": 1.2827324867248535,
      "learning_rate": 3.465574488094152e-05,
      "loss": 0.5439,
      "step": 3570
    },
    {
      "epoch": 1.3133370023848836,
      "grad_norm": 0.8562873005867004,
      "learning_rate": 3.455722606167754e-05,
      "loss": 0.4925,
      "step": 3580
    },
    {
      "epoch": 1.3170060539350579,
      "grad_norm": 1.012946367263794,
      "learning_rate": 3.4458533111725515e-05,
      "loss": 0.5304,
      "step": 3590
    },
    {
      "epoch": 1.3206751054852321,
      "grad_norm": 0.8904183506965637,
      "learning_rate": 3.435966782925066e-05,
      "loss": 0.5034,
      "step": 3600
    },
    {
      "epoch": 1.3243441570354064,
      "grad_norm": 1.0000728368759155,
      "learning_rate": 3.4260632015558047e-05,
      "loss": 0.4989,
      "step": 3610
    },
    {
      "epoch": 1.3280132085855807,
      "grad_norm": 0.8009348511695862,
      "learning_rate": 3.4161427475059745e-05,
      "loss": 0.5217,
      "step": 3620
    },
    {
      "epoch": 1.331682260135755,
      "grad_norm": 1.1289713382720947,
      "learning_rate": 3.406205601524205e-05,
      "loss": 0.5382,
      "step": 3630
    },
    {
      "epoch": 1.3353513116859292,
      "grad_norm": 0.9382407665252686,
      "learning_rate": 3.3962519446632454e-05,
      "loss": 0.5194,
      "step": 3640
    },
    {
      "epoch": 1.3390203632361035,
      "grad_norm": 1.0790501832962036,
      "learning_rate": 3.3862819582766714e-05,
      "loss": 0.5341,
      "step": 3650
    },
    {
      "epoch": 1.3426894147862778,
      "grad_norm": 0.9315184950828552,
      "learning_rate": 3.376295824015581e-05,
      "loss": 0.4932,
      "step": 3660
    },
    {
      "epoch": 1.346358466336452,
      "grad_norm": 0.8551687598228455,
      "learning_rate": 3.366293723825278e-05,
      "loss": 0.5172,
      "step": 3670
    },
    {
      "epoch": 1.3500275178866263,
      "grad_norm": 0.8260353803634644,
      "learning_rate": 3.356275839941967e-05,
      "loss": 0.5142,
      "step": 3680
    },
    {
      "epoch": 1.3536965694368006,
      "grad_norm": 1.059957504272461,
      "learning_rate": 3.346242354889427e-05,
      "loss": 0.4911,
      "step": 3690
    },
    {
      "epoch": 1.3573656209869749,
      "grad_norm": 0.8368703126907349,
      "learning_rate": 3.336193451475685e-05,
      "loss": 0.5271,
      "step": 3700
    },
    {
      "epoch": 1.3610346725371492,
      "grad_norm": 0.8385125994682312,
      "learning_rate": 3.326129312789692e-05,
      "loss": 0.5201,
      "step": 3710
    },
    {
      "epoch": 1.3647037240873234,
      "grad_norm": 0.8766797780990601,
      "learning_rate": 3.316050122197977e-05,
      "loss": 0.5174,
      "step": 3720
    },
    {
      "epoch": 1.3683727756374977,
      "grad_norm": 0.8743470907211304,
      "learning_rate": 3.305956063341314e-05,
      "loss": 0.5369,
      "step": 3730
    },
    {
      "epoch": 1.372041827187672,
      "grad_norm": 0.9249287247657776,
      "learning_rate": 3.2958473201313744e-05,
      "loss": 0.5125,
      "step": 3740
    },
    {
      "epoch": 1.3757108787378463,
      "grad_norm": 0.8530007004737854,
      "learning_rate": 3.285724076747375e-05,
      "loss": 0.4865,
      "step": 3750
    },
    {
      "epoch": 1.3793799302880205,
      "grad_norm": 1.0500656366348267,
      "learning_rate": 3.275586517632724e-05,
      "loss": 0.5127,
      "step": 3760
    },
    {
      "epoch": 1.3830489818381948,
      "grad_norm": 0.9515796899795532,
      "learning_rate": 3.2654348274916566e-05,
      "loss": 0.4799,
      "step": 3770
    },
    {
      "epoch": 1.386718033388369,
      "grad_norm": 0.7839356064796448,
      "learning_rate": 3.255269191285874e-05,
      "loss": 0.5155,
      "step": 3780
    },
    {
      "epoch": 1.3903870849385433,
      "grad_norm": 1.1705440282821655,
      "learning_rate": 3.245089794231171e-05,
      "loss": 0.533,
      "step": 3790
    },
    {
      "epoch": 1.3940561364887176,
      "grad_norm": 0.935599684715271,
      "learning_rate": 3.2348968217940626e-05,
      "loss": 0.5146,
      "step": 3800
    },
    {
      "epoch": 1.397725188038892,
      "grad_norm": 1.0857276916503906,
      "learning_rate": 3.224690459688406e-05,
      "loss": 0.5061,
      "step": 3810
    },
    {
      "epoch": 1.4013942395890662,
      "grad_norm": 0.9415270686149597,
      "learning_rate": 3.214470893872015e-05,
      "loss": 0.5311,
      "step": 3820
    },
    {
      "epoch": 1.4050632911392404,
      "grad_norm": 0.9964818954467773,
      "learning_rate": 3.2042383105432695e-05,
      "loss": 0.4809,
      "step": 3830
    },
    {
      "epoch": 1.4087323426894147,
      "grad_norm": 0.92458176612854,
      "learning_rate": 3.193992896137728e-05,
      "loss": 0.4953,
      "step": 3840
    },
    {
      "epoch": 1.412401394239589,
      "grad_norm": 0.947990357875824,
      "learning_rate": 3.183734837324727e-05,
      "loss": 0.5165,
      "step": 3850
    },
    {
      "epoch": 1.4160704457897633,
      "grad_norm": 0.9327725172042847,
      "learning_rate": 3.1734643210039855e-05,
      "loss": 0.5266,
      "step": 3860
    },
    {
      "epoch": 1.4197394973399375,
      "grad_norm": 1.0861709117889404,
      "learning_rate": 3.163181534302192e-05,
      "loss": 0.5147,
      "step": 3870
    },
    {
      "epoch": 1.4234085488901118,
      "grad_norm": 1.0089092254638672,
      "learning_rate": 3.152886664569598e-05,
      "loss": 0.5113,
      "step": 3880
    },
    {
      "epoch": 1.427077600440286,
      "grad_norm": 0.9725763201713562,
      "learning_rate": 3.142579899376609e-05,
      "loss": 0.5156,
      "step": 3890
    },
    {
      "epoch": 1.4307466519904604,
      "grad_norm": 0.9345846772193909,
      "learning_rate": 3.132261426510361e-05,
      "loss": 0.5251,
      "step": 3900
    },
    {
      "epoch": 1.4344157035406346,
      "grad_norm": 0.9671109318733215,
      "learning_rate": 3.121931433971302e-05,
      "loss": 0.5233,
      "step": 3910
    },
    {
      "epoch": 1.438084755090809,
      "grad_norm": 0.8192123770713806,
      "learning_rate": 3.1115901099697656e-05,
      "loss": 0.4956,
      "step": 3920
    },
    {
      "epoch": 1.4417538066409832,
      "grad_norm": 0.8485032320022583,
      "learning_rate": 3.1012376429225424e-05,
      "loss": 0.5077,
      "step": 3930
    },
    {
      "epoch": 1.4454228581911575,
      "grad_norm": 0.9765728116035461,
      "learning_rate": 3.090874221449448e-05,
      "loss": 0.5118,
      "step": 3940
    },
    {
      "epoch": 1.4490919097413317,
      "grad_norm": 0.8579782247543335,
      "learning_rate": 3.080500034369883e-05,
      "loss": 0.5258,
      "step": 3950
    },
    {
      "epoch": 1.4527609612915062,
      "grad_norm": 0.8543968200683594,
      "learning_rate": 3.0701152706993985e-05,
      "loss": 0.506,
      "step": 3960
    },
    {
      "epoch": 1.4564300128416805,
      "grad_norm": 0.908636212348938,
      "learning_rate": 3.0597201196462463e-05,
      "loss": 0.5093,
      "step": 3970
    },
    {
      "epoch": 1.4600990643918548,
      "grad_norm": 1.1897763013839722,
      "learning_rate": 3.049314770607935e-05,
      "loss": 0.5117,
      "step": 3980
    },
    {
      "epoch": 1.463768115942029,
      "grad_norm": 0.8877365589141846,
      "learning_rate": 3.0388994131677784e-05,
      "loss": 0.5355,
      "step": 3990
    },
    {
      "epoch": 1.4674371674922033,
      "grad_norm": 1.057456135749817,
      "learning_rate": 3.0284742370914403e-05,
      "loss": 0.5437,
      "step": 4000
    },
    {
      "epoch": 1.4674371674922033,
      "eval_loss": 0.527490496635437,
      "eval_runtime": 232.7571,
      "eval_samples_per_second": 2.604,
      "eval_steps_per_second": 2.604,
      "step": 4000
    },
    {
      "epoch": 1.4711062190423776,
      "grad_norm": 0.9717181324958801,
      "learning_rate": 3.0180394323234813e-05,
      "loss": 0.5174,
      "step": 4010
    },
    {
      "epoch": 1.4747752705925519,
      "grad_norm": 0.9128007292747498,
      "learning_rate": 3.0075951889838917e-05,
      "loss": 0.5422,
      "step": 4020
    },
    {
      "epoch": 1.4784443221427261,
      "grad_norm": 0.9310988783836365,
      "learning_rate": 2.9971416973646293e-05,
      "loss": 0.5082,
      "step": 4030
    },
    {
      "epoch": 1.4821133736929004,
      "grad_norm": 0.9611682295799255,
      "learning_rate": 2.9866791479261584e-05,
      "loss": 0.5054,
      "step": 4040
    },
    {
      "epoch": 1.4857824252430747,
      "grad_norm": 1.0387334823608398,
      "learning_rate": 2.976207731293971e-05,
      "loss": 0.5022,
      "step": 4050
    },
    {
      "epoch": 1.489451476793249,
      "grad_norm": 1.3275202512741089,
      "learning_rate": 2.9657276382551185e-05,
      "loss": 0.5064,
      "step": 4060
    },
    {
      "epoch": 1.4931205283434232,
      "grad_norm": 0.9811340570449829,
      "learning_rate": 2.955239059754737e-05,
      "loss": 0.4846,
      "step": 4070
    },
    {
      "epoch": 1.4967895798935975,
      "grad_norm": 0.9878092408180237,
      "learning_rate": 2.944742186892561e-05,
      "loss": 0.4749,
      "step": 4080
    },
    {
      "epoch": 1.5004586314437718,
      "grad_norm": 0.8789183497428894,
      "learning_rate": 2.9342372109194516e-05,
      "loss": 0.5037,
      "step": 4090
    },
    {
      "epoch": 1.504127682993946,
      "grad_norm": 0.9945605397224426,
      "learning_rate": 2.923724323233904e-05,
      "loss": 0.5306,
      "step": 4100
    },
    {
      "epoch": 1.5077967345441203,
      "grad_norm": 1.070317029953003,
      "learning_rate": 2.9132037153785634e-05,
      "loss": 0.5195,
      "step": 4110
    },
    {
      "epoch": 1.5114657860942946,
      "grad_norm": 1.0403907299041748,
      "learning_rate": 2.9026755790367376e-05,
      "loss": 0.5076,
      "step": 4120
    },
    {
      "epoch": 1.5151348376444689,
      "grad_norm": 0.9972668886184692,
      "learning_rate": 2.8921401060288966e-05,
      "loss": 0.4863,
      "step": 4130
    },
    {
      "epoch": 1.5188038891946432,
      "grad_norm": 0.9783010482788086,
      "learning_rate": 2.8815974883091884e-05,
      "loss": 0.5068,
      "step": 4140
    },
    {
      "epoch": 1.5224729407448174,
      "grad_norm": 1.2028930187225342,
      "learning_rate": 2.871047917961933e-05,
      "loss": 0.5217,
      "step": 4150
    },
    {
      "epoch": 1.5261419922949917,
      "grad_norm": 1.1120834350585938,
      "learning_rate": 2.8604915871981265e-05,
      "loss": 0.5138,
      "step": 4160
    },
    {
      "epoch": 1.529811043845166,
      "grad_norm": 1.0339429378509521,
      "learning_rate": 2.8499286883519398e-05,
      "loss": 0.5128,
      "step": 4170
    },
    {
      "epoch": 1.5334800953953405,
      "grad_norm": 1.006658911705017,
      "learning_rate": 2.83935941387721e-05,
      "loss": 0.497,
      "step": 4180
    },
    {
      "epoch": 1.5371491469455147,
      "grad_norm": 0.9148851037025452,
      "learning_rate": 2.8287839563439395e-05,
      "loss": 0.4922,
      "step": 4190
    },
    {
      "epoch": 1.540818198495689,
      "grad_norm": 0.854830265045166,
      "learning_rate": 2.8182025084347836e-05,
      "loss": 0.5055,
      "step": 4200
    },
    {
      "epoch": 1.5444872500458633,
      "grad_norm": 1.1474218368530273,
      "learning_rate": 2.8076152629415403e-05,
      "loss": 0.5061,
      "step": 4210
    },
    {
      "epoch": 1.5481563015960376,
      "grad_norm": 1.024875521659851,
      "learning_rate": 2.797022412761641e-05,
      "loss": 0.5323,
      "step": 4220
    },
    {
      "epoch": 1.5518253531462118,
      "grad_norm": 0.9536452293395996,
      "learning_rate": 2.7864241508946305e-05,
      "loss": 0.5162,
      "step": 4230
    },
    {
      "epoch": 1.5554944046963861,
      "grad_norm": 0.8775179386138916,
      "learning_rate": 2.7758206704386545e-05,
      "loss": 0.4977,
      "step": 4240
    },
    {
      "epoch": 1.5591634562465604,
      "grad_norm": 0.9244831204414368,
      "learning_rate": 2.7652121645869412e-05,
      "loss": 0.5094,
      "step": 4250
    },
    {
      "epoch": 1.5628325077967347,
      "grad_norm": 0.9842005372047424,
      "learning_rate": 2.7545988266242785e-05,
      "loss": 0.5158,
      "step": 4260
    },
    {
      "epoch": 1.566501559346909,
      "grad_norm": 1.0604709386825562,
      "learning_rate": 2.7439808499234957e-05,
      "loss": 0.5062,
      "step": 4270
    },
    {
      "epoch": 1.5701706108970832,
      "grad_norm": 1.0026077032089233,
      "learning_rate": 2.73335842794194e-05,
      "loss": 0.5217,
      "step": 4280
    },
    {
      "epoch": 1.5738396624472575,
      "grad_norm": 0.9699780344963074,
      "learning_rate": 2.7227317542179477e-05,
      "loss": 0.5211,
      "step": 4290
    },
    {
      "epoch": 1.5775087139974318,
      "grad_norm": 1.0255078077316284,
      "learning_rate": 2.7121010223673237e-05,
      "loss": 0.528,
      "step": 4300
    },
    {
      "epoch": 1.581177765547606,
      "grad_norm": 0.9601745009422302,
      "learning_rate": 2.7014664260798096e-05,
      "loss": 0.5243,
      "step": 4310
    },
    {
      "epoch": 1.5848468170977803,
      "grad_norm": 1.0979671478271484,
      "learning_rate": 2.6908281591155572e-05,
      "loss": 0.522,
      "step": 4320
    },
    {
      "epoch": 1.5885158686479546,
      "grad_norm": 1.161711573600769,
      "learning_rate": 2.6801864153015977e-05,
      "loss": 0.5091,
      "step": 4330
    },
    {
      "epoch": 1.5921849201981289,
      "grad_norm": 1.0911256074905396,
      "learning_rate": 2.6695413885283065e-05,
      "loss": 0.4858,
      "step": 4340
    },
    {
      "epoch": 1.5958539717483031,
      "grad_norm": 0.8395224213600159,
      "learning_rate": 2.6588932727458786e-05,
      "loss": 0.5005,
      "step": 4350
    },
    {
      "epoch": 1.5995230232984774,
      "grad_norm": 1.23264741897583,
      "learning_rate": 2.648242261960786e-05,
      "loss": 0.4969,
      "step": 4360
    },
    {
      "epoch": 1.6031920748486517,
      "grad_norm": 0.9221340417861938,
      "learning_rate": 2.6375885502322506e-05,
      "loss": 0.5152,
      "step": 4370
    },
    {
      "epoch": 1.606861126398826,
      "grad_norm": 0.83207768201828,
      "learning_rate": 2.6269323316687027e-05,
      "loss": 0.4855,
      "step": 4380
    },
    {
      "epoch": 1.6105301779490002,
      "grad_norm": 1.1201894283294678,
      "learning_rate": 2.616273800424246e-05,
      "loss": 0.5117,
      "step": 4390
    },
    {
      "epoch": 1.6141992294991745,
      "grad_norm": 1.1243469715118408,
      "learning_rate": 2.6056131506951232e-05,
      "loss": 0.4911,
      "step": 4400
    },
    {
      "epoch": 1.6178682810493488,
      "grad_norm": 0.9399608969688416,
      "learning_rate": 2.5949505767161725e-05,
      "loss": 0.5151,
      "step": 4410
    },
    {
      "epoch": 1.621537332599523,
      "grad_norm": 1.1602848768234253,
      "learning_rate": 2.584286272757295e-05,
      "loss": 0.5065,
      "step": 4420
    },
    {
      "epoch": 1.6252063841496973,
      "grad_norm": 1.1268662214279175,
      "learning_rate": 2.5736204331199088e-05,
      "loss": 0.4974,
      "step": 4430
    },
    {
      "epoch": 1.6288754356998716,
      "grad_norm": 0.9943903088569641,
      "learning_rate": 2.5629532521334115e-05,
      "loss": 0.5169,
      "step": 4440
    },
    {
      "epoch": 1.6325444872500459,
      "grad_norm": 0.9009532928466797,
      "learning_rate": 2.552284924151642e-05,
      "loss": 0.5044,
      "step": 4450
    },
    {
      "epoch": 1.6362135388002201,
      "grad_norm": 1.0662145614624023,
      "learning_rate": 2.5416156435493366e-05,
      "loss": 0.5007,
      "step": 4460
    },
    {
      "epoch": 1.6398825903503944,
      "grad_norm": 1.0880720615386963,
      "learning_rate": 2.5309456047185876e-05,
      "loss": 0.5265,
      "step": 4470
    },
    {
      "epoch": 1.6435516419005687,
      "grad_norm": 0.9624683856964111,
      "learning_rate": 2.5202750020653027e-05,
      "loss": 0.5174,
      "step": 4480
    },
    {
      "epoch": 1.647220693450743,
      "grad_norm": 0.817380964756012,
      "learning_rate": 2.50960403000566e-05,
      "loss": 0.4912,
      "step": 4490
    },
    {
      "epoch": 1.6508897450009172,
      "grad_norm": 1.1110498905181885,
      "learning_rate": 2.4989328829625713e-05,
      "loss": 0.5092,
      "step": 4500
    },
    {
      "epoch": 1.6508897450009172,
      "eval_loss": 0.5229318737983704,
      "eval_runtime": 231.3578,
      "eval_samples_per_second": 2.619,
      "eval_steps_per_second": 2.619,
      "step": 4500
    },
    {
      "epoch": 1.6545587965510915,
      "grad_norm": 0.9209726452827454,
      "learning_rate": 2.4882617553621345e-05,
      "loss": 0.4859,
      "step": 4510
    },
    {
      "epoch": 1.6582278481012658,
      "grad_norm": 0.9479291439056396,
      "learning_rate": 2.477590841630096e-05,
      "loss": 0.4889,
      "step": 4520
    },
    {
      "epoch": 1.66189689965144,
      "grad_norm": 0.9414562582969666,
      "learning_rate": 2.4669203361883008e-05,
      "loss": 0.5044,
      "step": 4530
    },
    {
      "epoch": 1.6655659512016143,
      "grad_norm": 1.116664171218872,
      "learning_rate": 2.4562504334511585e-05,
      "loss": 0.5127,
      "step": 4540
    },
    {
      "epoch": 1.6692350027517886,
      "grad_norm": 1.0085790157318115,
      "learning_rate": 2.445581327822097e-05,
      "loss": 0.5385,
      "step": 4550
    },
    {
      "epoch": 1.6729040543019629,
      "grad_norm": 1.1363215446472168,
      "learning_rate": 2.434913213690022e-05,
      "loss": 0.5221,
      "step": 4560
    },
    {
      "epoch": 1.6765731058521371,
      "grad_norm": 0.9904065132141113,
      "learning_rate": 2.4242462854257708e-05,
      "loss": 0.5327,
      "step": 4570
    },
    {
      "epoch": 1.6802421574023114,
      "grad_norm": 1.098220705986023,
      "learning_rate": 2.4135807373785786e-05,
      "loss": 0.5126,
      "step": 4580
    },
    {
      "epoch": 1.6839112089524857,
      "grad_norm": 0.8977326154708862,
      "learning_rate": 2.402916763872531e-05,
      "loss": 0.5114,
      "step": 4590
    },
    {
      "epoch": 1.68758026050266,
      "grad_norm": 0.8845460414886475,
      "learning_rate": 2.3922545592030246e-05,
      "loss": 0.4798,
      "step": 4600
    },
    {
      "epoch": 1.6912493120528342,
      "grad_norm": 0.9646274447441101,
      "learning_rate": 2.3815943176332315e-05,
      "loss": 0.5151,
      "step": 4610
    },
    {
      "epoch": 1.6949183636030085,
      "grad_norm": 0.9207940101623535,
      "learning_rate": 2.3709362333905554e-05,
      "loss": 0.5467,
      "step": 4620
    },
    {
      "epoch": 1.6985874151531828,
      "grad_norm": 0.830416202545166,
      "learning_rate": 2.3602805006630917e-05,
      "loss": 0.5183,
      "step": 4630
    },
    {
      "epoch": 1.702256466703357,
      "grad_norm": 1.0778138637542725,
      "learning_rate": 2.3496273135960938e-05,
      "loss": 0.5229,
      "step": 4640
    },
    {
      "epoch": 1.7059255182535313,
      "grad_norm": 1.0077544450759888,
      "learning_rate": 2.3389768662884336e-05,
      "loss": 0.5326,
      "step": 4650
    },
    {
      "epoch": 1.7095945698037056,
      "grad_norm": 0.7735280990600586,
      "learning_rate": 2.328329352789066e-05,
      "loss": 0.4865,
      "step": 4660
    },
    {
      "epoch": 1.7132636213538799,
      "grad_norm": 0.9580767154693604,
      "learning_rate": 2.3176849670934888e-05,
      "loss": 0.5152,
      "step": 4670
    },
    {
      "epoch": 1.7169326729040542,
      "grad_norm": 0.8074700236320496,
      "learning_rate": 2.3070439031402163e-05,
      "loss": 0.4697,
      "step": 4680
    },
    {
      "epoch": 1.7206017244542284,
      "grad_norm": 1.101008653640747,
      "learning_rate": 2.296406354807239e-05,
      "loss": 0.5114,
      "step": 4690
    },
    {
      "epoch": 1.7242707760044027,
      "grad_norm": 1.0476558208465576,
      "learning_rate": 2.2857725159084932e-05,
      "loss": 0.5034,
      "step": 4700
    },
    {
      "epoch": 1.727939827554577,
      "grad_norm": 0.8786264657974243,
      "learning_rate": 2.2751425801903305e-05,
      "loss": 0.5237,
      "step": 4710
    },
    {
      "epoch": 1.7316088791047515,
      "grad_norm": 1.1969928741455078,
      "learning_rate": 2.2645167413279902e-05,
      "loss": 0.4942,
      "step": 4720
    },
    {
      "epoch": 1.7352779306549257,
      "grad_norm": 0.929524838924408,
      "learning_rate": 2.253895192922062e-05,
      "loss": 0.514,
      "step": 4730
    },
    {
      "epoch": 1.7389469822051,
      "grad_norm": 0.8829103708267212,
      "learning_rate": 2.24327812849497e-05,
      "loss": 0.4995,
      "step": 4740
    },
    {
      "epoch": 1.7426160337552743,
      "grad_norm": 0.9233318567276001,
      "learning_rate": 2.232665741487438e-05,
      "loss": 0.5091,
      "step": 4750
    },
    {
      "epoch": 1.7462850853054486,
      "grad_norm": 1.0752466917037964,
      "learning_rate": 2.2220582252549676e-05,
      "loss": 0.5176,
      "step": 4760
    },
    {
      "epoch": 1.7499541368556228,
      "grad_norm": 1.0742378234863281,
      "learning_rate": 2.2114557730643182e-05,
      "loss": 0.509,
      "step": 4770
    },
    {
      "epoch": 1.7536231884057971,
      "grad_norm": 0.988858699798584,
      "learning_rate": 2.200858578089983e-05,
      "loss": 0.5205,
      "step": 4780
    },
    {
      "epoch": 1.7572922399559714,
      "grad_norm": 1.0490611791610718,
      "learning_rate": 2.1902668334106686e-05,
      "loss": 0.4965,
      "step": 4790
    },
    {
      "epoch": 1.7609612915061457,
      "grad_norm": 1.3148648738861084,
      "learning_rate": 2.1796807320057783e-05,
      "loss": 0.5013,
      "step": 4800
    },
    {
      "epoch": 1.76463034305632,
      "grad_norm": 0.8072360754013062,
      "learning_rate": 2.1691004667518968e-05,
      "loss": 0.5374,
      "step": 4810
    },
    {
      "epoch": 1.7682993946064942,
      "grad_norm": 1.0918337106704712,
      "learning_rate": 2.158526230419277e-05,
      "loss": 0.4825,
      "step": 4820
    },
    {
      "epoch": 1.7719684461566685,
      "grad_norm": 1.0746703147888184,
      "learning_rate": 2.147958215668322e-05,
      "loss": 0.506,
      "step": 4830
    },
    {
      "epoch": 1.7756374977068428,
      "grad_norm": 1.195997714996338,
      "learning_rate": 2.1373966150460827e-05,
      "loss": 0.5256,
      "step": 4840
    },
    {
      "epoch": 1.779306549257017,
      "grad_norm": 0.9266668558120728,
      "learning_rate": 2.126841620982745e-05,
      "loss": 0.5127,
      "step": 4850
    },
    {
      "epoch": 1.7829756008071913,
      "grad_norm": 1.285637617111206,
      "learning_rate": 2.1162934257881224e-05,
      "loss": 0.5268,
      "step": 4860
    },
    {
      "epoch": 1.7866446523573656,
      "grad_norm": 1.1704673767089844,
      "learning_rate": 2.1057522216481563e-05,
      "loss": 0.5279,
      "step": 4870
    },
    {
      "epoch": 1.7903137039075399,
      "grad_norm": 1.0365042686462402,
      "learning_rate": 2.0952182006214145e-05,
      "loss": 0.4876,
      "step": 4880
    },
    {
      "epoch": 1.7939827554577141,
      "grad_norm": 0.9031667709350586,
      "learning_rate": 2.0846915546355868e-05,
      "loss": 0.5007,
      "step": 4890
    },
    {
      "epoch": 1.7976518070078886,
      "grad_norm": 1.1357613801956177,
      "learning_rate": 2.0741724754839913e-05,
      "loss": 0.5094,
      "step": 4900
    },
    {
      "epoch": 1.801320858558063,
      "grad_norm": 1.2161802053451538,
      "learning_rate": 2.063661154822082e-05,
      "loss": 0.5375,
      "step": 4910
    },
    {
      "epoch": 1.8049899101082372,
      "grad_norm": 0.9568532109260559,
      "learning_rate": 2.053157784163954e-05,
      "loss": 0.4956,
      "step": 4920
    },
    {
      "epoch": 1.8086589616584114,
      "grad_norm": 1.0702060461044312,
      "learning_rate": 2.042662554878854e-05,
      "loss": 0.5073,
      "step": 4930
    },
    {
      "epoch": 1.8123280132085857,
      "grad_norm": 1.1124117374420166,
      "learning_rate": 2.032175658187696e-05,
      "loss": 0.4989,
      "step": 4940
    },
    {
      "epoch": 1.81599706475876,
      "grad_norm": 1.2252739667892456,
      "learning_rate": 2.0216972851595754e-05,
      "loss": 0.5132,
      "step": 4950
    },
    {
      "epoch": 1.8196661163089343,
      "grad_norm": 1.1239897012710571,
      "learning_rate": 2.0112276267082866e-05,
      "loss": 0.5178,
      "step": 4960
    },
    {
      "epoch": 1.8233351678591085,
      "grad_norm": 1.1821050643920898,
      "learning_rate": 2.0007668735888486e-05,
      "loss": 0.4859,
      "step": 4970
    },
    {
      "epoch": 1.8270042194092828,
      "grad_norm": 0.9448051452636719,
      "learning_rate": 1.990315216394027e-05,
      "loss": 0.4889,
      "step": 4980
    },
    {
      "epoch": 1.830673270959457,
      "grad_norm": 0.8695102334022522,
      "learning_rate": 1.979872845550859e-05,
      "loss": 0.5019,
      "step": 4990
    },
    {
      "epoch": 1.8343423225096314,
      "grad_norm": 1.1209285259246826,
      "learning_rate": 1.9694399513171882e-05,
      "loss": 0.5094,
      "step": 5000
    },
    {
      "epoch": 1.8343423225096314,
      "eval_loss": 0.518907904624939,
      "eval_runtime": 234.2279,
      "eval_samples_per_second": 2.587,
      "eval_steps_per_second": 2.587,
      "step": 5000
    },
    {
      "epoch": 1.8380113740598056,
      "grad_norm": 0.833130955696106,
      "learning_rate": 1.959016723778197e-05,
      "loss": 0.4935,
      "step": 5010
    },
    {
      "epoch": 1.84168042560998,
      "grad_norm": 1.1186310052871704,
      "learning_rate": 1.9486033528429422e-05,
      "loss": 0.4956,
      "step": 5020
    },
    {
      "epoch": 1.8453494771601542,
      "grad_norm": 0.965471088886261,
      "learning_rate": 1.9382000282408928e-05,
      "loss": 0.4998,
      "step": 5030
    },
    {
      "epoch": 1.8490185287103285,
      "grad_norm": 0.823370635509491,
      "learning_rate": 1.92780693951848e-05,
      "loss": 0.5076,
      "step": 5040
    },
    {
      "epoch": 1.8526875802605027,
      "grad_norm": 1.0525524616241455,
      "learning_rate": 1.917424276035637e-05,
      "loss": 0.5137,
      "step": 5050
    },
    {
      "epoch": 1.856356631810677,
      "grad_norm": 1.0302828550338745,
      "learning_rate": 1.9070522269623492e-05,
      "loss": 0.5192,
      "step": 5060
    },
    {
      "epoch": 1.8600256833608513,
      "grad_norm": 0.9364860653877258,
      "learning_rate": 1.8966909812752132e-05,
      "loss": 0.4785,
      "step": 5070
    },
    {
      "epoch": 1.8636947349110256,
      "grad_norm": 1.0344969034194946,
      "learning_rate": 1.8863407277539902e-05,
      "loss": 0.4912,
      "step": 5080
    },
    {
      "epoch": 1.8673637864611998,
      "grad_norm": 1.0051286220550537,
      "learning_rate": 1.8760016549781632e-05,
      "loss": 0.4862,
      "step": 5090
    },
    {
      "epoch": 1.871032838011374,
      "grad_norm": 0.9901503920555115,
      "learning_rate": 1.865673951323506e-05,
      "loss": 0.5109,
      "step": 5100
    },
    {
      "epoch": 1.8747018895615484,
      "grad_norm": 0.9759026765823364,
      "learning_rate": 1.8553578049586506e-05,
      "loss": 0.514,
      "step": 5110
    },
    {
      "epoch": 1.8783709411117226,
      "grad_norm": 0.8850026726722717,
      "learning_rate": 1.8450534038416568e-05,
      "loss": 0.4979,
      "step": 5120
    },
    {
      "epoch": 1.882039992661897,
      "grad_norm": 1.0924288034439087,
      "learning_rate": 1.8347609357165864e-05,
      "loss": 0.5176,
      "step": 5130
    },
    {
      "epoch": 1.8857090442120712,
      "grad_norm": 0.9653976559638977,
      "learning_rate": 1.8244805881100872e-05,
      "loss": 0.4889,
      "step": 5140
    },
    {
      "epoch": 1.8893780957622455,
      "grad_norm": 1.166527271270752,
      "learning_rate": 1.8142125483279732e-05,
      "loss": 0.5088,
      "step": 5150
    },
    {
      "epoch": 1.8930471473124197,
      "grad_norm": 0.8980358839035034,
      "learning_rate": 1.8039570034518104e-05,
      "loss": 0.5151,
      "step": 5160
    },
    {
      "epoch": 1.896716198862594,
      "grad_norm": 0.9328470230102539,
      "learning_rate": 1.7937141403355125e-05,
      "loss": 0.5017,
      "step": 5170
    },
    {
      "epoch": 1.9003852504127683,
      "grad_norm": 1.1543471813201904,
      "learning_rate": 1.783484145601934e-05,
      "loss": 0.5107,
      "step": 5180
    },
    {
      "epoch": 1.9040543019629426,
      "grad_norm": 0.8993279933929443,
      "learning_rate": 1.773267205639468e-05,
      "loss": 0.5228,
      "step": 5190
    },
    {
      "epoch": 1.9077233535131168,
      "grad_norm": 0.7625851631164551,
      "learning_rate": 1.7630635065986543e-05,
      "loss": 0.5106,
      "step": 5200
    },
    {
      "epoch": 1.9113924050632911,
      "grad_norm": 0.9024369120597839,
      "learning_rate": 1.752873234388786e-05,
      "loss": 0.5104,
      "step": 5210
    },
    {
      "epoch": 1.9150614566134654,
      "grad_norm": 1.2209627628326416,
      "learning_rate": 1.74269657467452e-05,
      "loss": 0.4797,
      "step": 5220
    },
    {
      "epoch": 1.9187305081636397,
      "grad_norm": 0.9488281011581421,
      "learning_rate": 1.7325337128724982e-05,
      "loss": 0.5134,
      "step": 5230
    },
    {
      "epoch": 1.922399559713814,
      "grad_norm": 0.8081420660018921,
      "learning_rate": 1.722384834147968e-05,
      "loss": 0.5025,
      "step": 5240
    },
    {
      "epoch": 1.9260686112639882,
      "grad_norm": 1.0759528875350952,
      "learning_rate": 1.712250123411407e-05,
      "loss": 0.5168,
      "step": 5250
    },
    {
      "epoch": 1.9297376628141625,
      "grad_norm": 1.0780614614486694,
      "learning_rate": 1.7021297653151528e-05,
      "loss": 0.5217,
      "step": 5260
    },
    {
      "epoch": 1.9334067143643368,
      "grad_norm": 1.1243650913238525,
      "learning_rate": 1.6920239442500445e-05,
      "loss": 0.4998,
      "step": 5270
    },
    {
      "epoch": 1.937075765914511,
      "grad_norm": 0.8195152878761292,
      "learning_rate": 1.6819328443420586e-05,
      "loss": 0.4828,
      "step": 5280
    },
    {
      "epoch": 1.9407448174646853,
      "grad_norm": 0.9800430536270142,
      "learning_rate": 1.6718566494489523e-05,
      "loss": 0.4983,
      "step": 5290
    },
    {
      "epoch": 1.9444138690148596,
      "grad_norm": 1.1039866209030151,
      "learning_rate": 1.6617955431569212e-05,
      "loss": 0.5036,
      "step": 5300
    },
    {
      "epoch": 1.9480829205650338,
      "grad_norm": 1.14901602268219,
      "learning_rate": 1.6517497087772465e-05,
      "loss": 0.5004,
      "step": 5310
    },
    {
      "epoch": 1.9517519721152081,
      "grad_norm": 0.7710126638412476,
      "learning_rate": 1.6417193293429577e-05,
      "loss": 0.4726,
      "step": 5320
    },
    {
      "epoch": 1.9554210236653824,
      "grad_norm": 0.9620373249053955,
      "learning_rate": 1.6317045876055006e-05,
      "loss": 0.5178,
      "step": 5330
    },
    {
      "epoch": 1.9590900752155567,
      "grad_norm": 1.059621810913086,
      "learning_rate": 1.6217056660314052e-05,
      "loss": 0.4969,
      "step": 5340
    },
    {
      "epoch": 1.962759126765731,
      "grad_norm": 1.223995566368103,
      "learning_rate": 1.6117227467989602e-05,
      "loss": 0.5452,
      "step": 5350
    },
    {
      "epoch": 1.9664281783159052,
      "grad_norm": 1.155535340309143,
      "learning_rate": 1.6017560117948946e-05,
      "loss": 0.526,
      "step": 5360
    },
    {
      "epoch": 1.9700972298660795,
      "grad_norm": 1.1572538614273071,
      "learning_rate": 1.5918056426110657e-05,
      "loss": 0.5101,
      "step": 5370
    },
    {
      "epoch": 1.9737662814162538,
      "grad_norm": 0.9044736623764038,
      "learning_rate": 1.5818718205411487e-05,
      "loss": 0.5106,
      "step": 5380
    },
    {
      "epoch": 1.977435332966428,
      "grad_norm": 0.9077745079994202,
      "learning_rate": 1.5719547265773317e-05,
      "loss": 0.492,
      "step": 5390
    },
    {
      "epoch": 1.9811043845166023,
      "grad_norm": 0.9804140329360962,
      "learning_rate": 1.562054541407023e-05,
      "loss": 0.4848,
      "step": 5400
    },
    {
      "epoch": 1.9847734360667766,
      "grad_norm": 1.1803187131881714,
      "learning_rate": 1.552171445409555e-05,
      "loss": 0.5137,
      "step": 5410
    },
    {
      "epoch": 1.9884424876169509,
      "grad_norm": 0.8508923649787903,
      "learning_rate": 1.5423056186528972e-05,
      "loss": 0.5065,
      "step": 5420
    },
    {
      "epoch": 1.9921115391671251,
      "grad_norm": 0.9768891930580139,
      "learning_rate": 1.53245724089038e-05,
      "loss": 0.4844,
      "step": 5430
    },
    {
      "epoch": 1.9957805907172996,
      "grad_norm": 1.0143649578094482,
      "learning_rate": 1.5226264915574157e-05,
      "loss": 0.4796,
      "step": 5440
    },
    {
      "epoch": 1.999449642267474,
      "grad_norm": 0.9577715396881104,
      "learning_rate": 1.5128135497682288e-05,
      "loss": 0.4911,
      "step": 5450
    },
    {
      "epoch": 2.0029352412401393,
      "grad_norm": 1.2007781267166138,
      "learning_rate": 1.5030185943125951e-05,
      "loss": 0.4682,
      "step": 5460
    },
    {
      "epoch": 2.0066042927903136,
      "grad_norm": 0.9090074300765991,
      "learning_rate": 1.4932418036525842e-05,
      "loss": 0.5096,
      "step": 5470
    },
    {
      "epoch": 2.010273344340488,
      "grad_norm": 0.9512068033218384,
      "learning_rate": 1.4834833559193057e-05,
      "loss": 0.4791,
      "step": 5480
    },
    {
      "epoch": 2.013942395890662,
      "grad_norm": 1.0587823390960693,
      "learning_rate": 1.4737434289096638e-05,
      "loss": 0.49,
      "step": 5490
    },
    {
      "epoch": 2.0176114474408364,
      "grad_norm": 0.9494228959083557,
      "learning_rate": 1.4640222000831217e-05,
      "loss": 0.4738,
      "step": 5500
    },
    {
      "epoch": 2.0176114474408364,
      "eval_loss": 0.5169897675514221,
      "eval_runtime": 238.0753,
      "eval_samples_per_second": 2.545,
      "eval_steps_per_second": 2.545,
      "step": 5500
    },
    {
      "epoch": 2.0212804989910107,
      "grad_norm": 1.403185248374939,
      "learning_rate": 1.4543198465584629e-05,
      "loss": 0.4819,
      "step": 5510
    },
    {
      "epoch": 2.024949550541185,
      "grad_norm": 0.8618935346603394,
      "learning_rate": 1.444636545110568e-05,
      "loss": 0.4761,
      "step": 5520
    },
    {
      "epoch": 2.0286186020913592,
      "grad_norm": 1.646319031715393,
      "learning_rate": 1.4349724721671937e-05,
      "loss": 0.4719,
      "step": 5530
    },
    {
      "epoch": 2.0322876536415335,
      "grad_norm": 1.088055968284607,
      "learning_rate": 1.4253278038057552e-05,
      "loss": 0.5123,
      "step": 5540
    },
    {
      "epoch": 2.035956705191708,
      "grad_norm": 1.3201335668563843,
      "learning_rate": 1.4157027157501202e-05,
      "loss": 0.4962,
      "step": 5550
    },
    {
      "epoch": 2.039625756741882,
      "grad_norm": 1.3275820016860962,
      "learning_rate": 1.4060973833674097e-05,
      "loss": 0.5046,
      "step": 5560
    },
    {
      "epoch": 2.0432948082920563,
      "grad_norm": 0.8678469061851501,
      "learning_rate": 1.3965119816647981e-05,
      "loss": 0.4679,
      "step": 5570
    },
    {
      "epoch": 2.0469638598422306,
      "grad_norm": 1.168977975845337,
      "learning_rate": 1.38694668528633e-05,
      "loss": 0.463,
      "step": 5580
    },
    {
      "epoch": 2.050632911392405,
      "grad_norm": 1.0617173910140991,
      "learning_rate": 1.3774016685097296e-05,
      "loss": 0.4833,
      "step": 5590
    },
    {
      "epoch": 2.054301962942579,
      "grad_norm": 0.9967471957206726,
      "learning_rate": 1.3678771052432365e-05,
      "loss": 0.4726,
      "step": 5600
    },
    {
      "epoch": 2.0579710144927534,
      "grad_norm": 1.030588150024414,
      "learning_rate": 1.3583731690224294e-05,
      "loss": 0.4785,
      "step": 5610
    },
    {
      "epoch": 2.0616400660429277,
      "grad_norm": 1.012284755706787,
      "learning_rate": 1.3488900330070647e-05,
      "loss": 0.4776,
      "step": 5620
    },
    {
      "epoch": 2.065309117593102,
      "grad_norm": 1.1276881694793701,
      "learning_rate": 1.3394278699779276e-05,
      "loss": 0.4759,
      "step": 5630
    },
    {
      "epoch": 2.0689781691432763,
      "grad_norm": 1.1409449577331543,
      "learning_rate": 1.3299868523336756e-05,
      "loss": 0.4404,
      "step": 5640
    },
    {
      "epoch": 2.0726472206934505,
      "grad_norm": 0.8799906969070435,
      "learning_rate": 1.3205671520877024e-05,
      "loss": 0.4897,
      "step": 5650
    },
    {
      "epoch": 2.0763162722436252,
      "grad_norm": 1.0355695486068726,
      "learning_rate": 1.3111689408650054e-05,
      "loss": 0.4774,
      "step": 5660
    },
    {
      "epoch": 2.0799853237937995,
      "grad_norm": 1.0800646543502808,
      "learning_rate": 1.3017923898990559e-05,
      "loss": 0.4818,
      "step": 5670
    },
    {
      "epoch": 2.083654375343974,
      "grad_norm": 0.9720245599746704,
      "learning_rate": 1.2924376700286766e-05,
      "loss": 0.4902,
      "step": 5680
    },
    {
      "epoch": 2.087323426894148,
      "grad_norm": 1.2290140390396118,
      "learning_rate": 1.2831049516949361e-05,
      "loss": 0.4735,
      "step": 5690
    },
    {
      "epoch": 2.0909924784443223,
      "grad_norm": 1.1229207515716553,
      "learning_rate": 1.2737944049380373e-05,
      "loss": 0.4794,
      "step": 5700
    },
    {
      "epoch": 2.0946615299944966,
      "grad_norm": 0.8709964752197266,
      "learning_rate": 1.2645061993942239e-05,
      "loss": 0.4561,
      "step": 5710
    },
    {
      "epoch": 2.098330581544671,
      "grad_norm": 0.9970029592514038,
      "learning_rate": 1.2552405042926829e-05,
      "loss": 0.4987,
      "step": 5720
    },
    {
      "epoch": 2.101999633094845,
      "grad_norm": 1.0758767127990723,
      "learning_rate": 1.2459974884524706e-05,
      "loss": 0.4776,
      "step": 5730
    },
    {
      "epoch": 2.1056686846450194,
      "grad_norm": 0.9215141534805298,
      "learning_rate": 1.2367773202794287e-05,
      "loss": 0.4917,
      "step": 5740
    },
    {
      "epoch": 2.1093377361951937,
      "grad_norm": 0.9819067120552063,
      "learning_rate": 1.2275801677631187e-05,
      "loss": 0.5093,
      "step": 5750
    },
    {
      "epoch": 2.113006787745368,
      "grad_norm": 1.0229853391647339,
      "learning_rate": 1.2184061984737644e-05,
      "loss": 0.4966,
      "step": 5760
    },
    {
      "epoch": 2.1166758392955423,
      "grad_norm": 1.0494178533554077,
      "learning_rate": 1.2092555795591947e-05,
      "loss": 0.4573,
      "step": 5770
    },
    {
      "epoch": 2.1203448908457165,
      "grad_norm": 0.9931570887565613,
      "learning_rate": 1.2001284777417982e-05,
      "loss": 0.4866,
      "step": 5780
    },
    {
      "epoch": 2.124013942395891,
      "grad_norm": 1.0582044124603271,
      "learning_rate": 1.191025059315488e-05,
      "loss": 0.4917,
      "step": 5790
    },
    {
      "epoch": 2.127682993946065,
      "grad_norm": 1.0779615640640259,
      "learning_rate": 1.1819454901426713e-05,
      "loss": 0.4703,
      "step": 5800
    },
    {
      "epoch": 2.1313520454962394,
      "grad_norm": 1.1260806322097778,
      "learning_rate": 1.1728899356512265e-05,
      "loss": 0.4689,
      "step": 5810
    },
    {
      "epoch": 2.1350210970464136,
      "grad_norm": 1.3518306016921997,
      "learning_rate": 1.1638585608314874e-05,
      "loss": 0.4512,
      "step": 5820
    },
    {
      "epoch": 2.138690148596588,
      "grad_norm": 1.183992862701416,
      "learning_rate": 1.154851530233243e-05,
      "loss": 0.5066,
      "step": 5830
    },
    {
      "epoch": 2.142359200146762,
      "grad_norm": 1.0033563375473022,
      "learning_rate": 1.1458690079627325e-05,
      "loss": 0.4783,
      "step": 5840
    },
    {
      "epoch": 2.1460282516969365,
      "grad_norm": 0.9800117015838623,
      "learning_rate": 1.1369111576796577e-05,
      "loss": 0.4404,
      "step": 5850
    },
    {
      "epoch": 2.1496973032471107,
      "grad_norm": 1.0856506824493408,
      "learning_rate": 1.1279781425942052e-05,
      "loss": 0.4524,
      "step": 5860
    },
    {
      "epoch": 2.153366354797285,
      "grad_norm": 0.9916655421257019,
      "learning_rate": 1.1190701254640685e-05,
      "loss": 0.4624,
      "step": 5870
    },
    {
      "epoch": 2.1570354063474593,
      "grad_norm": 1.060982346534729,
      "learning_rate": 1.1101872685914807e-05,
      "loss": 0.4765,
      "step": 5880
    },
    {
      "epoch": 2.1607044578976335,
      "grad_norm": 1.3350634574890137,
      "learning_rate": 1.1013297338202638e-05,
      "loss": 0.4821,
      "step": 5890
    },
    {
      "epoch": 2.164373509447808,
      "grad_norm": 1.11875319480896,
      "learning_rate": 1.092497682532875e-05,
      "loss": 0.4757,
      "step": 5900
    },
    {
      "epoch": 2.168042560997982,
      "grad_norm": 1.0386865139007568,
      "learning_rate": 1.083691275647466e-05,
      "loss": 0.4616,
      "step": 5910
    },
    {
      "epoch": 2.1717116125481564,
      "grad_norm": 1.0126460790634155,
      "learning_rate": 1.074910673614955e-05,
      "loss": 0.4836,
      "step": 5920
    },
    {
      "epoch": 2.1753806640983306,
      "grad_norm": 0.7838504314422607,
      "learning_rate": 1.0661560364161016e-05,
      "loss": 0.4632,
      "step": 5930
    },
    {
      "epoch": 2.179049715648505,
      "grad_norm": 0.8986156582832336,
      "learning_rate": 1.0574275235585893e-05,
      "loss": 0.4561,
      "step": 5940
    },
    {
      "epoch": 2.182718767198679,
      "grad_norm": 1.0742733478546143,
      "learning_rate": 1.0487252940741213e-05,
      "loss": 0.4675,
      "step": 5950
    },
    {
      "epoch": 2.1863878187488535,
      "grad_norm": 1.0086737871170044,
      "learning_rate": 1.0400495065155253e-05,
      "loss": 0.4985,
      "step": 5960
    },
    {
      "epoch": 2.1900568702990277,
      "grad_norm": 0.8636407852172852,
      "learning_rate": 1.0314003189538624e-05,
      "loss": 0.4771,
      "step": 5970
    },
    {
      "epoch": 2.193725921849202,
      "grad_norm": 1.1657392978668213,
      "learning_rate": 1.0227778889755446e-05,
      "loss": 0.4791,
      "step": 5980
    },
    {
      "epoch": 2.1973949733993763,
      "grad_norm": 1.0650666952133179,
      "learning_rate": 1.0141823736794692e-05,
      "loss": 0.4634,
      "step": 5990
    },
    {
      "epoch": 2.2010640249495506,
      "grad_norm": 1.0366514921188354,
      "learning_rate": 1.0056139296741529e-05,
      "loss": 0.4744,
      "step": 6000
    },
    {
      "epoch": 2.2010640249495506,
      "eval_loss": 0.5145697593688965,
      "eval_runtime": 241.4077,
      "eval_samples_per_second": 2.51,
      "eval_steps_per_second": 2.51,
      "step": 6000
    },
    {
      "epoch": 2.204733076499725,
      "grad_norm": 0.9758366942405701,
      "learning_rate": 9.970727130748771e-06,
      "loss": 0.449,
      "step": 6010
    },
    {
      "epoch": 2.208402128049899,
      "grad_norm": 1.0104902982711792,
      "learning_rate": 9.88558879500848e-06,
      "loss": 0.4561,
      "step": 6020
    },
    {
      "epoch": 2.2120711796000734,
      "grad_norm": 1.1962568759918213,
      "learning_rate": 9.800725840723583e-06,
      "loss": 0.4844,
      "step": 6030
    },
    {
      "epoch": 2.2157402311502477,
      "grad_norm": 1.2715821266174316,
      "learning_rate": 9.716139814079595e-06,
      "loss": 0.4955,
      "step": 6040
    },
    {
      "epoch": 2.219409282700422,
      "grad_norm": 1.1079530715942383,
      "learning_rate": 9.631832256216474e-06,
      "loss": 0.4845,
      "step": 6050
    },
    {
      "epoch": 2.223078334250596,
      "grad_norm": 0.9749194979667664,
      "learning_rate": 9.54780470320055e-06,
      "loss": 0.4845,
      "step": 6060
    },
    {
      "epoch": 2.2267473858007705,
      "grad_norm": 0.891008734703064,
      "learning_rate": 9.464058685996515e-06,
      "loss": 0.4638,
      "step": 6070
    },
    {
      "epoch": 2.2304164373509447,
      "grad_norm": 1.14248526096344,
      "learning_rate": 9.38059573043952e-06,
      "loss": 0.4913,
      "step": 6080
    },
    {
      "epoch": 2.234085488901119,
      "grad_norm": 1.0857394933700562,
      "learning_rate": 9.29741735720741e-06,
      "loss": 0.4549,
      "step": 6090
    },
    {
      "epoch": 2.2377545404512933,
      "grad_norm": 0.8906619548797607,
      "learning_rate": 9.214525081793004e-06,
      "loss": 0.4558,
      "step": 6100
    },
    {
      "epoch": 2.2414235920014676,
      "grad_norm": 1.0803526639938354,
      "learning_rate": 9.131920414476446e-06,
      "loss": 0.485,
      "step": 6110
    },
    {
      "epoch": 2.245092643551642,
      "grad_norm": 0.8794256448745728,
      "learning_rate": 9.049604860297752e-06,
      "loss": 0.4862,
      "step": 6120
    },
    {
      "epoch": 2.248761695101816,
      "grad_norm": 1.0943444967269897,
      "learning_rate": 8.967579919029351e-06,
      "loss": 0.4785,
      "step": 6130
    },
    {
      "epoch": 2.2524307466519904,
      "grad_norm": 1.1884266138076782,
      "learning_rate": 8.885847085148755e-06,
      "loss": 0.4616,
      "step": 6140
    },
    {
      "epoch": 2.2560997982021647,
      "grad_norm": 1.0885648727416992,
      "learning_rate": 8.804407847811327e-06,
      "loss": 0.5223,
      "step": 6150
    },
    {
      "epoch": 2.259768849752339,
      "grad_norm": 0.8932308554649353,
      "learning_rate": 8.723263690823191e-06,
      "loss": 0.4701,
      "step": 6160
    },
    {
      "epoch": 2.263437901302513,
      "grad_norm": 1.34469735622406,
      "learning_rate": 8.642416092614162e-06,
      "loss": 0.4694,
      "step": 6170
    },
    {
      "epoch": 2.2671069528526875,
      "grad_norm": 1.054312825202942,
      "learning_rate": 8.561866526210788e-06,
      "loss": 0.4631,
      "step": 6180
    },
    {
      "epoch": 2.2707760044028618,
      "grad_norm": 1.222394585609436,
      "learning_rate": 8.48161645920957e-06,
      "loss": 0.4829,
      "step": 6190
    },
    {
      "epoch": 2.274445055953036,
      "grad_norm": 0.975588858127594,
      "learning_rate": 8.401667353750193e-06,
      "loss": 0.4745,
      "step": 6200
    },
    {
      "epoch": 2.2781141075032103,
      "grad_norm": 1.0941109657287598,
      "learning_rate": 8.322020666488844e-06,
      "loss": 0.4746,
      "step": 6210
    },
    {
      "epoch": 2.2817831590533846,
      "grad_norm": 1.1205480098724365,
      "learning_rate": 8.242677848571759e-06,
      "loss": 0.4692,
      "step": 6220
    },
    {
      "epoch": 2.285452210603559,
      "grad_norm": 1.4668667316436768,
      "learning_rate": 8.163640345608723e-06,
      "loss": 0.4847,
      "step": 6230
    },
    {
      "epoch": 2.289121262153733,
      "grad_norm": 1.1100854873657227,
      "learning_rate": 8.084909597646734e-06,
      "loss": 0.5118,
      "step": 6240
    },
    {
      "epoch": 2.2927903137039074,
      "grad_norm": 0.936525821685791,
      "learning_rate": 8.00648703914378e-06,
      "loss": 0.4667,
      "step": 6250
    },
    {
      "epoch": 2.2964593652540817,
      "grad_norm": 1.0628732442855835,
      "learning_rate": 7.928374098942704e-06,
      "loss": 0.4727,
      "step": 6260
    },
    {
      "epoch": 2.300128416804256,
      "grad_norm": 1.198099136352539,
      "learning_rate": 7.850572200245184e-06,
      "loss": 0.4563,
      "step": 6270
    },
    {
      "epoch": 2.3037974683544302,
      "grad_norm": 1.041306495666504,
      "learning_rate": 7.773082760585757e-06,
      "loss": 0.4462,
      "step": 6280
    },
    {
      "epoch": 2.3074665199046045,
      "grad_norm": 1.1630598306655884,
      "learning_rate": 7.695907191806035e-06,
      "loss": 0.4882,
      "step": 6290
    },
    {
      "epoch": 2.3111355714547788,
      "grad_norm": 1.1418871879577637,
      "learning_rate": 7.619046900028981e-06,
      "loss": 0.4815,
      "step": 6300
    },
    {
      "epoch": 2.314804623004953,
      "grad_norm": 1.056389570236206,
      "learning_rate": 7.54250328563324e-06,
      "loss": 0.5128,
      "step": 6310
    },
    {
      "epoch": 2.3184736745551273,
      "grad_norm": 0.950781524181366,
      "learning_rate": 7.466277743227695e-06,
      "loss": 0.462,
      "step": 6320
    },
    {
      "epoch": 2.3221427261053016,
      "grad_norm": 0.9278048872947693,
      "learning_rate": 7.390371661626017e-06,
      "loss": 0.482,
      "step": 6330
    },
    {
      "epoch": 2.325811777655476,
      "grad_norm": 1.1997020244598389,
      "learning_rate": 7.31478642382134e-06,
      "loss": 0.444,
      "step": 6340
    },
    {
      "epoch": 2.32948082920565,
      "grad_norm": 0.9762285351753235,
      "learning_rate": 7.239523406961132e-06,
      "loss": 0.4692,
      "step": 6350
    },
    {
      "epoch": 2.3331498807558244,
      "grad_norm": 1.2622642517089844,
      "learning_rate": 7.164583982322029e-06,
      "loss": 0.471,
      "step": 6360
    },
    {
      "epoch": 2.3368189323059987,
      "grad_norm": 0.9129505753517151,
      "learning_rate": 7.089969515284886e-06,
      "loss": 0.4623,
      "step": 6370
    },
    {
      "epoch": 2.340487983856173,
      "grad_norm": 0.8323271870613098,
      "learning_rate": 7.015681365309915e-06,
      "loss": 0.5061,
      "step": 6380
    },
    {
      "epoch": 2.3441570354063472,
      "grad_norm": 1.0094308853149414,
      "learning_rate": 6.94172088591189e-06,
      "loss": 0.4982,
      "step": 6390
    },
    {
      "epoch": 2.3478260869565215,
      "grad_norm": 1.0211843252182007,
      "learning_rate": 6.868089424635502e-06,
      "loss": 0.4844,
      "step": 6400
    },
    {
      "epoch": 2.351495138506696,
      "grad_norm": 0.9575326442718506,
      "learning_rate": 6.794788323030776e-06,
      "loss": 0.4807,
      "step": 6410
    },
    {
      "epoch": 2.35516419005687,
      "grad_norm": 1.2869937419891357,
      "learning_rate": 6.721818916628672e-06,
      "loss": 0.4779,
      "step": 6420
    },
    {
      "epoch": 2.3588332416070448,
      "grad_norm": 1.3438565731048584,
      "learning_rate": 6.649182534916742e-06,
      "loss": 0.4717,
      "step": 6430
    },
    {
      "epoch": 2.362502293157219,
      "grad_norm": 1.1024246215820312,
      "learning_rate": 6.576880501314861e-06,
      "loss": 0.4796,
      "step": 6440
    },
    {
      "epoch": 2.3661713447073933,
      "grad_norm": 1.1888881921768188,
      "learning_rate": 6.504914133151188e-06,
      "loss": 0.4624,
      "step": 6450
    },
    {
      "epoch": 2.3698403962575676,
      "grad_norm": 1.065861701965332,
      "learning_rate": 6.433284741638107e-06,
      "loss": 0.5047,
      "step": 6460
    },
    {
      "epoch": 2.373509447807742,
      "grad_norm": 1.1294344663619995,
      "learning_rate": 6.361993631848348e-06,
      "loss": 0.4511,
      "step": 6470
    },
    {
      "epoch": 2.377178499357916,
      "grad_norm": 1.4639546871185303,
      "learning_rate": 6.291042102691242e-06,
      "loss": 0.4782,
      "step": 6480
    },
    {
      "epoch": 2.3808475509080904,
      "grad_norm": 1.047289490699768,
      "learning_rate": 6.220431446889016e-06,
      "loss": 0.4885,
      "step": 6490
    },
    {
      "epoch": 2.3845166024582647,
      "grad_norm": 1.0149236917495728,
      "learning_rate": 6.150162950953264e-06,
      "loss": 0.4818,
      "step": 6500
    },
    {
      "epoch": 2.3845166024582647,
      "eval_loss": 0.5127094984054565,
      "eval_runtime": 240.2832,
      "eval_samples_per_second": 2.522,
      "eval_steps_per_second": 2.522,
      "step": 6500
    },
    {
      "epoch": 2.388185654008439,
      "grad_norm": 1.0614635944366455,
      "learning_rate": 6.080237895161483e-06,
      "loss": 0.4788,
      "step": 6510
    },
    {
      "epoch": 2.3918547055586132,
      "grad_norm": 0.9502063393592834,
      "learning_rate": 6.010657553533774e-06,
      "loss": 0.4753,
      "step": 6520
    },
    {
      "epoch": 2.3955237571087875,
      "grad_norm": 1.0552899837493896,
      "learning_rate": 5.94142319380962e-06,
      "loss": 0.4816,
      "step": 6530
    },
    {
      "epoch": 2.399192808658962,
      "grad_norm": 0.8859190344810486,
      "learning_rate": 5.8725360774247646e-06,
      "loss": 0.4991,
      "step": 6540
    },
    {
      "epoch": 2.402861860209136,
      "grad_norm": 1.149677038192749,
      "learning_rate": 5.803997459488275e-06,
      "loss": 0.4824,
      "step": 6550
    },
    {
      "epoch": 2.4065309117593103,
      "grad_norm": 1.0091294050216675,
      "learning_rate": 5.735808588759633e-06,
      "loss": 0.5087,
      "step": 6560
    },
    {
      "epoch": 2.4101999633094846,
      "grad_norm": 1.0026583671569824,
      "learning_rate": 5.6679707076259916e-06,
      "loss": 0.4675,
      "step": 6570
    },
    {
      "epoch": 2.413869014859659,
      "grad_norm": 1.2009302377700806,
      "learning_rate": 5.600485052079568e-06,
      "loss": 0.4894,
      "step": 6580
    },
    {
      "epoch": 2.417538066409833,
      "grad_norm": 0.9573816657066345,
      "learning_rate": 5.533352851695093e-06,
      "loss": 0.4935,
      "step": 6590
    },
    {
      "epoch": 2.4212071179600074,
      "grad_norm": 1.3438702821731567,
      "learning_rate": 5.466575329607398e-06,
      "loss": 0.4931,
      "step": 6600
    },
    {
      "epoch": 2.4248761695101817,
      "grad_norm": 0.9460842609405518,
      "learning_rate": 5.400153702489177e-06,
      "loss": 0.4813,
      "step": 6610
    },
    {
      "epoch": 2.428545221060356,
      "grad_norm": 1.2758539915084839,
      "learning_rate": 5.334089180528776e-06,
      "loss": 0.502,
      "step": 6620
    },
    {
      "epoch": 2.4322142726105302,
      "grad_norm": 1.0640389919281006,
      "learning_rate": 5.2683829674081724e-06,
      "loss": 0.5137,
      "step": 6630
    },
    {
      "epoch": 2.4358833241607045,
      "grad_norm": 1.1171743869781494,
      "learning_rate": 5.203036260281002e-06,
      "loss": 0.451,
      "step": 6640
    },
    {
      "epoch": 2.439552375710879,
      "grad_norm": 0.9534650444984436,
      "learning_rate": 5.1380502497508086e-06,
      "loss": 0.4885,
      "step": 6650
    },
    {
      "epoch": 2.443221427261053,
      "grad_norm": 0.9417087435722351,
      "learning_rate": 5.073426119849295e-06,
      "loss": 0.4918,
      "step": 6660
    },
    {
      "epoch": 2.4468904788112273,
      "grad_norm": 1.1875280141830444,
      "learning_rate": 5.00916504801478e-06,
      "loss": 0.4794,
      "step": 6670
    },
    {
      "epoch": 2.4505595303614016,
      "grad_norm": 1.3566325902938843,
      "learning_rate": 4.945268205070741e-06,
      "loss": 0.5001,
      "step": 6680
    },
    {
      "epoch": 2.454228581911576,
      "grad_norm": 1.3453025817871094,
      "learning_rate": 4.881736755204491e-06,
      "loss": 0.4959,
      "step": 6690
    },
    {
      "epoch": 2.45789763346175,
      "grad_norm": 1.1745924949645996,
      "learning_rate": 4.818571855945933e-06,
      "loss": 0.4768,
      "step": 6700
    },
    {
      "epoch": 2.4615666850119244,
      "grad_norm": 1.1026362180709839,
      "learning_rate": 4.755774658146508e-06,
      "loss": 0.4808,
      "step": 6710
    },
    {
      "epoch": 2.4652357365620987,
      "grad_norm": 1.094588279724121,
      "learning_rate": 4.693346305958218e-06,
      "loss": 0.4892,
      "step": 6720
    },
    {
      "epoch": 2.468904788112273,
      "grad_norm": 0.9171593189239502,
      "learning_rate": 4.631287936812764e-06,
      "loss": 0.4662,
      "step": 6730
    },
    {
      "epoch": 2.4725738396624473,
      "grad_norm": 0.9275270700454712,
      "learning_rate": 4.569600681400829e-06,
      "loss": 0.4882,
      "step": 6740
    },
    {
      "epoch": 2.4762428912126215,
      "grad_norm": 1.2338370084762573,
      "learning_rate": 4.508285663651496e-06,
      "loss": 0.458,
      "step": 6750
    },
    {
      "epoch": 2.479911942762796,
      "grad_norm": 1.7698208093643188,
      "learning_rate": 4.4473440007117365e-06,
      "loss": 0.5021,
      "step": 6760
    },
    {
      "epoch": 2.48358099431297,
      "grad_norm": 1.0442287921905518,
      "learning_rate": 4.386776802926079e-06,
      "loss": 0.4542,
      "step": 6770
    },
    {
      "epoch": 2.4872500458631444,
      "grad_norm": 0.8600567579269409,
      "learning_rate": 4.32658517381638e-06,
      "loss": 0.4734,
      "step": 6780
    },
    {
      "epoch": 2.4909190974133186,
      "grad_norm": 1.4507365226745605,
      "learning_rate": 4.266770210061721e-06,
      "loss": 0.4743,
      "step": 6790
    },
    {
      "epoch": 2.494588148963493,
      "grad_norm": 1.0647755861282349,
      "learning_rate": 4.207333001478392e-06,
      "loss": 0.4641,
      "step": 6800
    },
    {
      "epoch": 2.498257200513667,
      "grad_norm": 1.1833049058914185,
      "learning_rate": 4.148274631000082e-06,
      "loss": 0.4666,
      "step": 6810
    },
    {
      "epoch": 2.5019262520638414,
      "grad_norm": 1.2540826797485352,
      "learning_rate": 4.089596174658128e-06,
      "loss": 0.4744,
      "step": 6820
    },
    {
      "epoch": 2.5055953036140157,
      "grad_norm": 1.0765169858932495,
      "learning_rate": 4.031298701561895e-06,
      "loss": 0.4656,
      "step": 6830
    },
    {
      "epoch": 2.50926435516419,
      "grad_norm": 1.1263598203659058,
      "learning_rate": 3.9733832738793275e-06,
      "loss": 0.4675,
      "step": 6840
    },
    {
      "epoch": 2.5129334067143643,
      "grad_norm": 1.304402232170105,
      "learning_rate": 3.915850946817579e-06,
      "loss": 0.4857,
      "step": 6850
    },
    {
      "epoch": 2.5166024582645385,
      "grad_norm": 1.0923244953155518,
      "learning_rate": 3.858702768603778e-06,
      "loss": 0.482,
      "step": 6860
    },
    {
      "epoch": 2.520271509814713,
      "grad_norm": 1.046303153038025,
      "learning_rate": 3.8019397804659434e-06,
      "loss": 0.487,
      "step": 6870
    },
    {
      "epoch": 2.523940561364887,
      "grad_norm": 1.029362440109253,
      "learning_rate": 3.745563016614018e-06,
      "loss": 0.4743,
      "step": 6880
    },
    {
      "epoch": 2.5276096129150614,
      "grad_norm": 1.2557183504104614,
      "learning_rate": 3.6895735042210195e-06,
      "loss": 0.4876,
      "step": 6890
    },
    {
      "epoch": 2.5312786644652356,
      "grad_norm": 1.0523215532302856,
      "learning_rate": 3.633972263404309e-06,
      "loss": 0.4555,
      "step": 6900
    },
    {
      "epoch": 2.53494771601541,
      "grad_norm": 0.9394640922546387,
      "learning_rate": 3.5787603072070297e-06,
      "loss": 0.4745,
      "step": 6910
    },
    {
      "epoch": 2.538616767565584,
      "grad_norm": 1.4020226001739502,
      "learning_rate": 3.5239386415796494e-06,
      "loss": 0.5143,
      "step": 6920
    },
    {
      "epoch": 2.5422858191157585,
      "grad_norm": 1.1758431196212769,
      "learning_rate": 3.4695082653615956e-06,
      "loss": 0.4804,
      "step": 6930
    },
    {
      "epoch": 2.5459548706659327,
      "grad_norm": 1.1330039501190186,
      "learning_rate": 3.4154701702631047e-06,
      "loss": 0.4877,
      "step": 6940
    },
    {
      "epoch": 2.549623922216107,
      "grad_norm": 1.5724884271621704,
      "learning_rate": 3.3618253408471326e-06,
      "loss": 0.485,
      "step": 6950
    },
    {
      "epoch": 2.5532929737662813,
      "grad_norm": 0.9390740394592285,
      "learning_rate": 3.308574754511404e-06,
      "loss": 0.4836,
      "step": 6960
    },
    {
      "epoch": 2.5569620253164556,
      "grad_norm": 1.1356174945831299,
      "learning_rate": 3.255719381470615e-06,
      "loss": 0.4667,
      "step": 6970
    },
    {
      "epoch": 2.56063107686663,
      "grad_norm": 1.1045786142349243,
      "learning_rate": 3.2032601847387685e-06,
      "loss": 0.4788,
      "step": 6980
    },
    {
      "epoch": 2.564300128416804,
      "grad_norm": 1.0325651168823242,
      "learning_rate": 3.1511981201116177e-06,
      "loss": 0.4745,
      "step": 6990
    },
    {
      "epoch": 2.5679691799669784,
      "grad_norm": 1.0939797163009644,
      "learning_rate": 3.099534136149232e-06,
      "loss": 0.4882,
      "step": 7000
    },
    {
      "epoch": 2.5679691799669784,
      "eval_loss": 0.5115830898284912,
      "eval_runtime": 242.5929,
      "eval_samples_per_second": 2.498,
      "eval_steps_per_second": 2.498,
      "step": 7000
    },
    {
      "epoch": 2.5716382315171527,
      "grad_norm": 1.2998616695404053,
      "learning_rate": 3.0482691741587495e-06,
      "loss": 0.483,
      "step": 7010
    },
    {
      "epoch": 2.5753072830673274,
      "grad_norm": 1.0874706506729126,
      "learning_rate": 2.9974041681772147e-06,
      "loss": 0.475,
      "step": 7020
    },
    {
      "epoch": 2.5789763346175016,
      "grad_norm": 1.2338545322418213,
      "learning_rate": 2.9469400449545355e-06,
      "loss": 0.482,
      "step": 7030
    },
    {
      "epoch": 2.582645386167676,
      "grad_norm": 1.1319416761398315,
      "learning_rate": 2.8968777239366363e-06,
      "loss": 0.4755,
      "step": 7040
    },
    {
      "epoch": 2.58631443771785,
      "grad_norm": 1.0439883470535278,
      "learning_rate": 2.847218117248687e-06,
      "loss": 0.4752,
      "step": 7050
    },
    {
      "epoch": 2.5899834892680245,
      "grad_norm": 1.142724871635437,
      "learning_rate": 2.7979621296784775e-06,
      "loss": 0.4768,
      "step": 7060
    },
    {
      "epoch": 2.5936525408181987,
      "grad_norm": 1.205451250076294,
      "learning_rate": 2.749110658659937e-06,
      "loss": 0.4522,
      "step": 7070
    },
    {
      "epoch": 2.597321592368373,
      "grad_norm": 1.025147795677185,
      "learning_rate": 2.700664594256802e-06,
      "loss": 0.4706,
      "step": 7080
    },
    {
      "epoch": 2.6009906439185473,
      "grad_norm": 1.0426020622253418,
      "learning_rate": 2.6526248191463763e-06,
      "loss": 0.477,
      "step": 7090
    },
    {
      "epoch": 2.6046596954687216,
      "grad_norm": 1.083366870880127,
      "learning_rate": 2.604992208603452e-06,
      "loss": 0.4667,
      "step": 7100
    },
    {
      "epoch": 2.608328747018896,
      "grad_norm": 1.1282833814620972,
      "learning_rate": 2.5577676304843673e-06,
      "loss": 0.4777,
      "step": 7110
    },
    {
      "epoch": 2.61199779856907,
      "grad_norm": 1.1477068662643433,
      "learning_rate": 2.5109519452112096e-06,
      "loss": 0.4789,
      "step": 7120
    },
    {
      "epoch": 2.6156668501192444,
      "grad_norm": 1.0347554683685303,
      "learning_rate": 2.464546005756099e-06,
      "loss": 0.4713,
      "step": 7130
    },
    {
      "epoch": 2.6193359016694187,
      "grad_norm": 1.1003060340881348,
      "learning_rate": 2.4185506576256872e-06,
      "loss": 0.4909,
      "step": 7140
    },
    {
      "epoch": 2.623004953219593,
      "grad_norm": 0.9722782969474792,
      "learning_rate": 2.372966738845736e-06,
      "loss": 0.4632,
      "step": 7150
    },
    {
      "epoch": 2.626674004769767,
      "grad_norm": 0.9919159412384033,
      "learning_rate": 2.327795079945841e-06,
      "loss": 0.4926,
      "step": 7160
    },
    {
      "epoch": 2.6303430563199415,
      "grad_norm": 1.214325189590454,
      "learning_rate": 2.283036503944311e-06,
      "loss": 0.4678,
      "step": 7170
    },
    {
      "epoch": 2.6340121078701157,
      "grad_norm": 1.0036134719848633,
      "learning_rate": 2.2386918263331724e-06,
      "loss": 0.4807,
      "step": 7180
    },
    {
      "epoch": 2.63768115942029,
      "grad_norm": 1.2839936017990112,
      "learning_rate": 2.1947618550633097e-06,
      "loss": 0.4948,
      "step": 7190
    },
    {
      "epoch": 2.6413502109704643,
      "grad_norm": 1.212727665901184,
      "learning_rate": 2.151247390529737e-06,
      "loss": 0.4871,
      "step": 7200
    },
    {
      "epoch": 2.6450192625206386,
      "grad_norm": 0.9670155048370361,
      "learning_rate": 2.1081492255570266e-06,
      "loss": 0.4606,
      "step": 7210
    },
    {
      "epoch": 2.648688314070813,
      "grad_norm": 1.1250370740890503,
      "learning_rate": 2.0654681453848608e-06,
      "loss": 0.462,
      "step": 7220
    },
    {
      "epoch": 2.652357365620987,
      "grad_norm": 1.3460599184036255,
      "learning_rate": 2.02320492765371e-06,
      "loss": 0.4586,
      "step": 7230
    },
    {
      "epoch": 2.6560264171711614,
      "grad_norm": 1.263229250907898,
      "learning_rate": 1.9813603423906924e-06,
      "loss": 0.4885,
      "step": 7240
    },
    {
      "epoch": 2.6596954687213357,
      "grad_norm": 1.1084803342819214,
      "learning_rate": 1.9399351519955254e-06,
      "loss": 0.478,
      "step": 7250
    },
    {
      "epoch": 2.66336452027151,
      "grad_norm": 1.3232501745224,
      "learning_rate": 1.8989301112266266e-06,
      "loss": 0.4801,
      "step": 7260
    },
    {
      "epoch": 2.667033571821684,
      "grad_norm": 1.0144097805023193,
      "learning_rate": 1.8583459671873942e-06,
      "loss": 0.452,
      "step": 7270
    },
    {
      "epoch": 2.6707026233718585,
      "grad_norm": 1.144231915473938,
      "learning_rate": 1.8181834593125558e-06,
      "loss": 0.4941,
      "step": 7280
    },
    {
      "epoch": 2.6743716749220328,
      "grad_norm": 1.0687694549560547,
      "learning_rate": 1.7784433193547223e-06,
      "loss": 0.4642,
      "step": 7290
    },
    {
      "epoch": 2.678040726472207,
      "grad_norm": 1.071439266204834,
      "learning_rate": 1.7391262713710499e-06,
      "loss": 0.5098,
      "step": 7300
    },
    {
      "epoch": 2.6817097780223813,
      "grad_norm": 0.9933722615242004,
      "learning_rate": 1.7002330317100469e-06,
      "loss": 0.4749,
      "step": 7310
    },
    {
      "epoch": 2.6853788295725556,
      "grad_norm": 1.3896921873092651,
      "learning_rate": 1.6617643089985257e-06,
      "loss": 0.4664,
      "step": 7320
    },
    {
      "epoch": 2.68904788112273,
      "grad_norm": 0.8435997366905212,
      "learning_rate": 1.6237208041286672e-06,
      "loss": 0.4934,
      "step": 7330
    },
    {
      "epoch": 2.692716932672904,
      "grad_norm": 1.3586794137954712,
      "learning_rate": 1.586103210245296e-06,
      "loss": 0.4879,
      "step": 7340
    },
    {
      "epoch": 2.6963859842230784,
      "grad_norm": 1.3717219829559326,
      "learning_rate": 1.548912212733214e-06,
      "loss": 0.4711,
      "step": 7350
    },
    {
      "epoch": 2.7000550357732527,
      "grad_norm": 1.030213475227356,
      "learning_rate": 1.5121484892047233e-06,
      "loss": 0.5015,
      "step": 7360
    },
    {
      "epoch": 2.703724087323427,
      "grad_norm": 1.0124726295471191,
      "learning_rate": 1.4758127094872898e-06,
      "loss": 0.4983,
      "step": 7370
    },
    {
      "epoch": 2.7073931388736012,
      "grad_norm": 1.2298890352249146,
      "learning_rate": 1.4399055356113272e-06,
      "loss": 0.4668,
      "step": 7380
    },
    {
      "epoch": 2.7110621904237755,
      "grad_norm": 1.0433547496795654,
      "learning_rate": 1.4044276217981295e-06,
      "loss": 0.484,
      "step": 7390
    },
    {
      "epoch": 2.7147312419739498,
      "grad_norm": 1.1889890432357788,
      "learning_rate": 1.369379614447977e-06,
      "loss": 0.4772,
      "step": 7400
    },
    {
      "epoch": 2.718400293524124,
      "grad_norm": 0.9900437593460083,
      "learning_rate": 1.3347621521283382e-06,
      "loss": 0.4667,
      "step": 7410
    },
    {
      "epoch": 2.7220693450742983,
      "grad_norm": 0.945975124835968,
      "learning_rate": 1.3005758655622424e-06,
      "loss": 0.4914,
      "step": 7420
    },
    {
      "epoch": 2.7257383966244726,
      "grad_norm": 1.3591928482055664,
      "learning_rate": 1.266821377616767e-06,
      "loss": 0.4724,
      "step": 7430
    },
    {
      "epoch": 2.729407448174647,
      "grad_norm": 0.9050936698913574,
      "learning_rate": 1.2334993032917324e-06,
      "loss": 0.4574,
      "step": 7440
    },
    {
      "epoch": 2.733076499724821,
      "grad_norm": 0.9637750387191772,
      "learning_rate": 1.2006102497084643e-06,
      "loss": 0.47,
      "step": 7450
    },
    {
      "epoch": 2.7367455512749954,
      "grad_norm": 1.039812445640564,
      "learning_rate": 1.1681548160987267e-06,
      "loss": 0.4634,
      "step": 7460
    },
    {
      "epoch": 2.7404146028251697,
      "grad_norm": 1.1204975843429565,
      "learning_rate": 1.1361335937938338e-06,
      "loss": 0.4685,
      "step": 7470
    },
    {
      "epoch": 2.744083654375344,
      "grad_norm": 1.3006625175476074,
      "learning_rate": 1.104547166213854e-06,
      "loss": 0.4735,
      "step": 7480
    },
    {
      "epoch": 2.7477527059255182,
      "grad_norm": 1.0787922143936157,
      "learning_rate": 1.073396108856975e-06,
      "loss": 0.4803,
      "step": 7490
    },
    {
      "epoch": 2.7514217574756925,
      "grad_norm": 1.0945625305175781,
      "learning_rate": 1.0426809892890466e-06,
      "loss": 0.4843,
      "step": 7500
    },
    {
      "epoch": 2.7514217574756925,
      "eval_loss": 0.5108335614204407,
      "eval_runtime": 243.2897,
      "eval_samples_per_second": 2.491,
      "eval_steps_per_second": 2.491,
      "step": 7500
    },
    {
      "epoch": 2.755090809025867,
      "grad_norm": 0.9795251488685608,
      "learning_rate": 1.0124023671332167e-06,
      "loss": 0.4882,
      "step": 7510
    },
    {
      "epoch": 2.758759860576041,
      "grad_norm": 1.1547175645828247,
      "learning_rate": 9.825607940597254e-07,
      "loss": 0.4875,
      "step": 7520
    },
    {
      "epoch": 2.7624289121262153,
      "grad_norm": 0.9601801633834839,
      "learning_rate": 9.531568137758906e-07,
      "loss": 0.4733,
      "step": 7530
    },
    {
      "epoch": 2.7660979636763896,
      "grad_norm": 1.1617836952209473,
      "learning_rate": 9.241909620161637e-07,
      "loss": 0.469,
      "step": 7540
    },
    {
      "epoch": 2.769767015226564,
      "grad_norm": 1.116990327835083,
      "learning_rate": 8.95663766532398e-07,
      "loss": 0.4751,
      "step": 7550
    },
    {
      "epoch": 2.773436066776738,
      "grad_norm": 1.097736120223999,
      "learning_rate": 8.675757470842038e-07,
      "loss": 0.4656,
      "step": 7560
    },
    {
      "epoch": 2.7771051183269124,
      "grad_norm": 0.8601435422897339,
      "learning_rate": 8.399274154295089e-07,
      "loss": 0.4621,
      "step": 7570
    },
    {
      "epoch": 2.7807741698770867,
      "grad_norm": 1.084355115890503,
      "learning_rate": 8.127192753152129e-07,
      "loss": 0.4622,
      "step": 7580
    },
    {
      "epoch": 2.784443221427261,
      "grad_norm": 0.9287521839141846,
      "learning_rate": 7.859518224680174e-07,
      "loss": 0.4804,
      "step": 7590
    },
    {
      "epoch": 2.7881122729774352,
      "grad_norm": 1.0060977935791016,
      "learning_rate": 7.596255445853934e-07,
      "loss": 0.4709,
      "step": 7600
    },
    {
      "epoch": 2.7917813245276095,
      "grad_norm": 1.0688620805740356,
      "learning_rate": 7.337409213266977e-07,
      "loss": 0.478,
      "step": 7610
    },
    {
      "epoch": 2.795450376077784,
      "grad_norm": 1.0311342477798462,
      "learning_rate": 7.082984243044238e-07,
      "loss": 0.4846,
      "step": 7620
    },
    {
      "epoch": 2.799119427627958,
      "grad_norm": 0.950131356716156,
      "learning_rate": 6.832985170756256e-07,
      "loss": 0.4869,
      "step": 7630
    },
    {
      "epoch": 2.8027884791781323,
      "grad_norm": 1.0103631019592285,
      "learning_rate": 6.587416551334546e-07,
      "loss": 0.4817,
      "step": 7640
    },
    {
      "epoch": 2.8064575307283066,
      "grad_norm": 1.1399298906326294,
      "learning_rate": 6.34628285898875e-07,
      "loss": 0.4636,
      "step": 7650
    },
    {
      "epoch": 2.810126582278481,
      "grad_norm": 1.0882922410964966,
      "learning_rate": 6.109588487124978e-07,
      "loss": 0.4752,
      "step": 7660
    },
    {
      "epoch": 2.813795633828655,
      "grad_norm": 1.2773634195327759,
      "learning_rate": 5.877337748265905e-07,
      "loss": 0.4955,
      "step": 7670
    },
    {
      "epoch": 2.8174646853788294,
      "grad_norm": 1.0079293251037598,
      "learning_rate": 5.649534873972073e-07,
      "loss": 0.4641,
      "step": 7680
    },
    {
      "epoch": 2.8211337369290037,
      "grad_norm": 1.0470513105392456,
      "learning_rate": 5.426184014764885e-07,
      "loss": 0.4857,
      "step": 7690
    },
    {
      "epoch": 2.824802788479178,
      "grad_norm": 1.1643450260162354,
      "learning_rate": 5.207289240050927e-07,
      "loss": 0.4837,
      "step": 7700
    },
    {
      "epoch": 2.8284718400293523,
      "grad_norm": 1.2491276264190674,
      "learning_rate": 4.992854538047931e-07,
      "loss": 0.4883,
      "step": 7710
    },
    {
      "epoch": 2.8321408915795265,
      "grad_norm": 1.167676329612732,
      "learning_rate": 4.78288381571182e-07,
      "loss": 0.4798,
      "step": 7720
    },
    {
      "epoch": 2.835809943129701,
      "grad_norm": 1.330261468887329,
      "learning_rate": 4.5773808986659673e-07,
      "loss": 0.4588,
      "step": 7730
    },
    {
      "epoch": 2.839478994679875,
      "grad_norm": 1.3763492107391357,
      "learning_rate": 4.3763495311310855e-07,
      "loss": 0.5043,
      "step": 7740
    },
    {
      "epoch": 2.8431480462300494,
      "grad_norm": 0.9072518944740295,
      "learning_rate": 4.1797933758572494e-07,
      "loss": 0.4595,
      "step": 7750
    },
    {
      "epoch": 2.8468170977802236,
      "grad_norm": 0.985634982585907,
      "learning_rate": 3.9877160140570914e-07,
      "loss": 0.4568,
      "step": 7760
    },
    {
      "epoch": 2.850486149330398,
      "grad_norm": 1.1514387130737305,
      "learning_rate": 3.8001209453405184e-07,
      "loss": 0.4642,
      "step": 7770
    },
    {
      "epoch": 2.854155200880572,
      "grad_norm": 1.00948965549469,
      "learning_rate": 3.6170115876510144e-07,
      "loss": 0.4547,
      "step": 7780
    },
    {
      "epoch": 2.8578242524307464,
      "grad_norm": 1.2566930055618286,
      "learning_rate": 3.4383912772032735e-07,
      "loss": 0.4776,
      "step": 7790
    },
    {
      "epoch": 2.8614933039809207,
      "grad_norm": 0.9360045790672302,
      "learning_rate": 3.264263268422579e-07,
      "loss": 0.4589,
      "step": 7800
    },
    {
      "epoch": 2.865162355531095,
      "grad_norm": 1.103943109512329,
      "learning_rate": 3.094630733885301e-07,
      "loss": 0.4744,
      "step": 7810
    },
    {
      "epoch": 2.8688314070812693,
      "grad_norm": 1.1529326438903809,
      "learning_rate": 2.929496764261269e-07,
      "loss": 0.5059,
      "step": 7820
    },
    {
      "epoch": 2.8725004586314435,
      "grad_norm": 1.183394193649292,
      "learning_rate": 2.768864368257323e-07,
      "loss": 0.487,
      "step": 7830
    },
    {
      "epoch": 2.876169510181618,
      "grad_norm": 1.1575208902359009,
      "learning_rate": 2.6127364725626045e-07,
      "loss": 0.4749,
      "step": 7840
    },
    {
      "epoch": 2.879838561731792,
      "grad_norm": 1.2331948280334473,
      "learning_rate": 2.4611159217952093e-07,
      "loss": 0.4888,
      "step": 7850
    },
    {
      "epoch": 2.8835076132819664,
      "grad_norm": 1.0552432537078857,
      "learning_rate": 2.3140054784502595e-07,
      "loss": 0.4819,
      "step": 7860
    },
    {
      "epoch": 2.8871766648321406,
      "grad_norm": 1.1691441535949707,
      "learning_rate": 2.171407822849747e-07,
      "loss": 0.4913,
      "step": 7870
    },
    {
      "epoch": 2.890845716382315,
      "grad_norm": 1.3298386335372925,
      "learning_rate": 2.0333255530934902e-07,
      "loss": 0.4865,
      "step": 7880
    },
    {
      "epoch": 2.894514767932489,
      "grad_norm": 1.3839668035507202,
      "learning_rate": 1.8997611850120333e-07,
      "loss": 0.4747,
      "step": 7890
    },
    {
      "epoch": 2.8981838194826635,
      "grad_norm": 1.3309091329574585,
      "learning_rate": 1.7707171521205712e-07,
      "loss": 0.4709,
      "step": 7900
    },
    {
      "epoch": 2.901852871032838,
      "grad_norm": 1.1871602535247803,
      "learning_rate": 1.6461958055747906e-07,
      "loss": 0.465,
      "step": 7910
    },
    {
      "epoch": 2.9055219225830125,
      "grad_norm": 1.3193415403366089,
      "learning_rate": 1.52619941412796e-07,
      "loss": 0.4752,
      "step": 7920
    },
    {
      "epoch": 2.9091909741331867,
      "grad_norm": 1.3378053903579712,
      "learning_rate": 1.4107301640895464e-07,
      "loss": 0.4731,
      "step": 7930
    },
    {
      "epoch": 2.912860025683361,
      "grad_norm": 1.3738112449645996,
      "learning_rate": 1.2997901592855521e-07,
      "loss": 0.4697,
      "step": 7940
    },
    {
      "epoch": 2.9165290772335353,
      "grad_norm": 1.0603090524673462,
      "learning_rate": 1.1933814210199067e-07,
      "loss": 0.4838,
      "step": 7950
    },
    {
      "epoch": 2.9201981287837095,
      "grad_norm": 0.987289547920227,
      "learning_rate": 1.0915058880379137e-07,
      "loss": 0.4955,
      "step": 7960
    },
    {
      "epoch": 2.923867180333884,
      "grad_norm": 1.208422303199768,
      "learning_rate": 9.941654164907776e-08,
      "loss": 0.4769,
      "step": 7970
    },
    {
      "epoch": 2.927536231884058,
      "grad_norm": 1.025102972984314,
      "learning_rate": 9.013617799018271e-08,
      "loss": 0.467,
      "step": 7980
    },
    {
      "epoch": 2.9312052834342324,
      "grad_norm": 1.0641257762908936,
      "learning_rate": 8.130966691341502e-08,
      "loss": 0.5209,
      "step": 7990
    },
    {
      "epoch": 2.9348743349844066,
      "grad_norm": 0.958498477935791,
      "learning_rate": 7.293716923598704e-08,
      "loss": 0.4853,
      "step": 8000
    },
    {
      "epoch": 2.9348743349844066,
      "eval_loss": 0.5103743672370911,
      "eval_runtime": 239.5682,
      "eval_samples_per_second": 2.53,
      "eval_steps_per_second": 2.53,
      "step": 8000
    },
    {
      "epoch": 2.938543386534581,
      "grad_norm": 1.1159329414367676,
      "learning_rate": 6.501883750308357e-08,
      "loss": 0.4667,
      "step": 8010
    },
    {
      "epoch": 2.942212438084755,
      "grad_norm": 1.4681369066238403,
      "learning_rate": 5.755481598507528e-08,
      "loss": 0.4817,
      "step": 8020
    },
    {
      "epoch": 2.9458814896349295,
      "grad_norm": 0.987959086894989,
      "learning_rate": 5.0545240674890194e-08,
      "loss": 0.4783,
      "step": 8030
    },
    {
      "epoch": 2.9495505411851037,
      "grad_norm": 0.9514848589897156,
      "learning_rate": 4.399023928554902e-08,
      "loss": 0.4765,
      "step": 8040
    },
    {
      "epoch": 2.953219592735278,
      "grad_norm": 1.1681430339813232,
      "learning_rate": 3.788993124782536e-08,
      "loss": 0.4775,
      "step": 8050
    },
    {
      "epoch": 2.9568886442854523,
      "grad_norm": 0.8645135164260864,
      "learning_rate": 3.2244427708072455e-08,
      "loss": 0.4757,
      "step": 8060
    },
    {
      "epoch": 2.9605576958356266,
      "grad_norm": 0.8488491773605347,
      "learning_rate": 2.705383152619978e-08,
      "loss": 0.4825,
      "step": 8070
    },
    {
      "epoch": 2.964226747385801,
      "grad_norm": 1.3520457744598389,
      "learning_rate": 2.2318237273802333e-08,
      "loss": 0.4951,
      "step": 8080
    },
    {
      "epoch": 2.967895798935975,
      "grad_norm": 1.0949887037277222,
      "learning_rate": 1.803773123242869e-08,
      "loss": 0.4453,
      "step": 8090
    },
    {
      "epoch": 2.9715648504861494,
      "grad_norm": 1.2356436252593994,
      "learning_rate": 1.4212391392015579e-08,
      "loss": 0.4993,
      "step": 8100
    },
    {
      "epoch": 2.9752339020363237,
      "grad_norm": 0.8899649381637573,
      "learning_rate": 1.0842287449469579e-08,
      "loss": 0.461,
      "step": 8110
    },
    {
      "epoch": 2.978902953586498,
      "grad_norm": 1.0446999073028564,
      "learning_rate": 7.927480807384814e-09,
      "loss": 0.4705,
      "step": 8120
    },
    {
      "epoch": 2.982572005136672,
      "grad_norm": 0.963333249092102,
      "learning_rate": 5.468024572941044e-09,
      "loss": 0.4786,
      "step": 8130
    },
    {
      "epoch": 2.9862410566868465,
      "grad_norm": 1.0340508222579956,
      "learning_rate": 3.4639635569211347e-09,
      "loss": 0.487,
      "step": 8140
    },
    {
      "epoch": 2.9899101082370207,
      "grad_norm": 1.396687626838684,
      "learning_rate": 1.915334272906133e-09,
      "loss": 0.4437,
      "step": 8150
    },
    {
      "epoch": 2.993579159787195,
      "grad_norm": 1.1523339748382568,
      "learning_rate": 8.22164936600811e-10,
      "loss": 0.4838,
      "step": 8160
    },
    {
      "epoch": 2.9972482113373693,
      "grad_norm": 1.0486055612564087,
      "learning_rate": 1.8447546532296412e-10,
      "loss": 0.4861,
      "step": 8170
    }
  ],
  "logging_steps": 10,
  "max_steps": 8178,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3573267692957204e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
