{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.366905155017428,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00366905155017428,
      "grad_norm": 0.3877936601638794,
      "learning_rate": 5.501222493887531e-07,
      "loss": 1.3825,
      "step": 10
    },
    {
      "epoch": 0.00733810310034856,
      "grad_norm": 0.3388456106185913,
      "learning_rate": 1.1613691931540342e-06,
      "loss": 1.3519,
      "step": 20
    },
    {
      "epoch": 0.01100715465052284,
      "grad_norm": 0.34713810682296753,
      "learning_rate": 1.7726161369193154e-06,
      "loss": 1.3608,
      "step": 30
    },
    {
      "epoch": 0.01467620620069712,
      "grad_norm": 0.4064188003540039,
      "learning_rate": 2.3838630806845967e-06,
      "loss": 1.3713,
      "step": 40
    },
    {
      "epoch": 0.0183452577508714,
      "grad_norm": 0.45421141386032104,
      "learning_rate": 2.9951100244498777e-06,
      "loss": 1.3726,
      "step": 50
    },
    {
      "epoch": 0.02201430930104568,
      "grad_norm": 0.4744616746902466,
      "learning_rate": 3.606356968215159e-06,
      "loss": 1.3487,
      "step": 60
    },
    {
      "epoch": 0.025683360851219958,
      "grad_norm": 0.6290422677993774,
      "learning_rate": 4.21760391198044e-06,
      "loss": 1.3523,
      "step": 70
    },
    {
      "epoch": 0.02935241240139424,
      "grad_norm": 0.5566685795783997,
      "learning_rate": 4.828850855745722e-06,
      "loss": 1.3289,
      "step": 80
    },
    {
      "epoch": 0.03302146395156852,
      "grad_norm": 0.46856987476348877,
      "learning_rate": 5.440097799511003e-06,
      "loss": 1.3306,
      "step": 90
    },
    {
      "epoch": 0.0366905155017428,
      "grad_norm": 0.35358479619026184,
      "learning_rate": 6.051344743276284e-06,
      "loss": 1.247,
      "step": 100
    },
    {
      "epoch": 0.04035956705191708,
      "grad_norm": 0.4844614565372467,
      "learning_rate": 6.662591687041565e-06,
      "loss": 1.2218,
      "step": 110
    },
    {
      "epoch": 0.04402861860209136,
      "grad_norm": 0.5792201161384583,
      "learning_rate": 7.273838630806847e-06,
      "loss": 1.2077,
      "step": 120
    },
    {
      "epoch": 0.04769767015226564,
      "grad_norm": 0.38933107256889343,
      "learning_rate": 7.885085574572127e-06,
      "loss": 1.1452,
      "step": 130
    },
    {
      "epoch": 0.051366721702439916,
      "grad_norm": 0.364145427942276,
      "learning_rate": 8.496332518337409e-06,
      "loss": 1.0986,
      "step": 140
    },
    {
      "epoch": 0.0550357732526142,
      "grad_norm": 0.4445214569568634,
      "learning_rate": 9.10757946210269e-06,
      "loss": 1.0758,
      "step": 150
    },
    {
      "epoch": 0.05870482480278848,
      "grad_norm": 0.48486754298210144,
      "learning_rate": 9.718826405867972e-06,
      "loss": 1.0014,
      "step": 160
    },
    {
      "epoch": 0.06237387635296276,
      "grad_norm": 0.33367639780044556,
      "learning_rate": 1.0330073349633253e-05,
      "loss": 0.9749,
      "step": 170
    },
    {
      "epoch": 0.06604292790313704,
      "grad_norm": 0.4073357880115509,
      "learning_rate": 1.0941320293398534e-05,
      "loss": 0.9964,
      "step": 180
    },
    {
      "epoch": 0.06971197945331131,
      "grad_norm": 0.489095002412796,
      "learning_rate": 1.1552567237163816e-05,
      "loss": 0.9409,
      "step": 190
    },
    {
      "epoch": 0.0733810310034856,
      "grad_norm": 0.3971366882324219,
      "learning_rate": 1.2163814180929096e-05,
      "loss": 0.9283,
      "step": 200
    },
    {
      "epoch": 0.07705008255365987,
      "grad_norm": 0.44291526079177856,
      "learning_rate": 1.2775061124694377e-05,
      "loss": 0.8758,
      "step": 210
    },
    {
      "epoch": 0.08071913410383416,
      "grad_norm": 0.6228989362716675,
      "learning_rate": 1.3386308068459657e-05,
      "loss": 0.9017,
      "step": 220
    },
    {
      "epoch": 0.08438818565400844,
      "grad_norm": 0.41784918308258057,
      "learning_rate": 1.3997555012224938e-05,
      "loss": 0.8486,
      "step": 230
    },
    {
      "epoch": 0.08805723720418272,
      "grad_norm": 0.49626976251602173,
      "learning_rate": 1.460880195599022e-05,
      "loss": 0.8642,
      "step": 240
    },
    {
      "epoch": 0.091726288754357,
      "grad_norm": 0.5728238224983215,
      "learning_rate": 1.5220048899755501e-05,
      "loss": 0.8622,
      "step": 250
    },
    {
      "epoch": 0.09539534030453128,
      "grad_norm": 0.468300998210907,
      "learning_rate": 1.583129584352078e-05,
      "loss": 0.8142,
      "step": 260
    },
    {
      "epoch": 0.09906439185470556,
      "grad_norm": 0.6429207921028137,
      "learning_rate": 1.6442542787286064e-05,
      "loss": 0.8135,
      "step": 270
    },
    {
      "epoch": 0.10273344340487983,
      "grad_norm": 0.4333305358886719,
      "learning_rate": 1.7053789731051344e-05,
      "loss": 0.7781,
      "step": 280
    },
    {
      "epoch": 0.10640249495505412,
      "grad_norm": 0.7538961172103882,
      "learning_rate": 1.7665036674816627e-05,
      "loss": 0.7782,
      "step": 290
    },
    {
      "epoch": 0.1100715465052284,
      "grad_norm": 0.5683786869049072,
      "learning_rate": 1.8276283618581907e-05,
      "loss": 0.7574,
      "step": 300
    },
    {
      "epoch": 0.11374059805540268,
      "grad_norm": 0.5173904895782471,
      "learning_rate": 1.888753056234719e-05,
      "loss": 0.7558,
      "step": 310
    },
    {
      "epoch": 0.11740964960557695,
      "grad_norm": 0.6803333163261414,
      "learning_rate": 1.949877750611247e-05,
      "loss": 0.7621,
      "step": 320
    },
    {
      "epoch": 0.12107870115575124,
      "grad_norm": 0.7055644989013672,
      "learning_rate": 2.0110024449877753e-05,
      "loss": 0.7509,
      "step": 330
    },
    {
      "epoch": 0.12474775270592552,
      "grad_norm": 0.6526551842689514,
      "learning_rate": 2.0721271393643033e-05,
      "loss": 0.7612,
      "step": 340
    },
    {
      "epoch": 0.1284168042560998,
      "grad_norm": 1.0160521268844604,
      "learning_rate": 2.1332518337408312e-05,
      "loss": 0.7526,
      "step": 350
    },
    {
      "epoch": 0.13208585580627408,
      "grad_norm": 0.6214171051979065,
      "learning_rate": 2.1943765281173596e-05,
      "loss": 0.7192,
      "step": 360
    },
    {
      "epoch": 0.13575490735644835,
      "grad_norm": 0.6929377317428589,
      "learning_rate": 2.2555012224938875e-05,
      "loss": 0.7006,
      "step": 370
    },
    {
      "epoch": 0.13942395890662262,
      "grad_norm": 0.7169085144996643,
      "learning_rate": 2.316625916870416e-05,
      "loss": 0.6955,
      "step": 380
    },
    {
      "epoch": 0.14309301045679693,
      "grad_norm": 0.8329369425773621,
      "learning_rate": 2.3777506112469438e-05,
      "loss": 0.7199,
      "step": 390
    },
    {
      "epoch": 0.1467620620069712,
      "grad_norm": 0.6524739265441895,
      "learning_rate": 2.438875305623472e-05,
      "loss": 0.6703,
      "step": 400
    },
    {
      "epoch": 0.15043111355714547,
      "grad_norm": 0.7267888784408569,
      "learning_rate": 2.5e-05,
      "loss": 0.6875,
      "step": 410
    },
    {
      "epoch": 0.15410016510731975,
      "grad_norm": 0.6155242323875427,
      "learning_rate": 2.561124694376528e-05,
      "loss": 0.7156,
      "step": 420
    },
    {
      "epoch": 0.15776921665749405,
      "grad_norm": 0.7568008303642273,
      "learning_rate": 2.6222493887530564e-05,
      "loss": 0.6965,
      "step": 430
    },
    {
      "epoch": 0.16143826820766832,
      "grad_norm": 0.6655860543251038,
      "learning_rate": 2.6833740831295844e-05,
      "loss": 0.6546,
      "step": 440
    },
    {
      "epoch": 0.1651073197578426,
      "grad_norm": 1.1648468971252441,
      "learning_rate": 2.7444987775061127e-05,
      "loss": 0.6819,
      "step": 450
    },
    {
      "epoch": 0.16877637130801687,
      "grad_norm": 0.68362957239151,
      "learning_rate": 2.8056234718826407e-05,
      "loss": 0.6855,
      "step": 460
    },
    {
      "epoch": 0.17244542285819114,
      "grad_norm": 0.6543752551078796,
      "learning_rate": 2.866748166259169e-05,
      "loss": 0.645,
      "step": 470
    },
    {
      "epoch": 0.17611447440836545,
      "grad_norm": 0.6918438076972961,
      "learning_rate": 2.927872860635697e-05,
      "loss": 0.6267,
      "step": 480
    },
    {
      "epoch": 0.17978352595853972,
      "grad_norm": 0.7780126333236694,
      "learning_rate": 2.988997555012225e-05,
      "loss": 0.6547,
      "step": 490
    },
    {
      "epoch": 0.183452577508714,
      "grad_norm": 0.6887812614440918,
      "learning_rate": 3.0501222493887533e-05,
      "loss": 0.6507,
      "step": 500
    },
    {
      "epoch": 0.183452577508714,
      "eval_loss": 0.6555390357971191,
      "eval_runtime": 241.4797,
      "eval_samples_per_second": 2.51,
      "eval_steps_per_second": 2.51,
      "step": 500
    },
    {
      "epoch": 0.18712162905888827,
      "grad_norm": 0.756022572517395,
      "learning_rate": 3.1112469437652816e-05,
      "loss": 0.6563,
      "step": 510
    },
    {
      "epoch": 0.19079068060906257,
      "grad_norm": 0.8010755777359009,
      "learning_rate": 3.1723716381418096e-05,
      "loss": 0.662,
      "step": 520
    },
    {
      "epoch": 0.19445973215923684,
      "grad_norm": 0.7894098162651062,
      "learning_rate": 3.2334963325183375e-05,
      "loss": 0.6657,
      "step": 530
    },
    {
      "epoch": 0.19812878370941112,
      "grad_norm": 1.0443938970565796,
      "learning_rate": 3.2946210268948655e-05,
      "loss": 0.6485,
      "step": 540
    },
    {
      "epoch": 0.2017978352595854,
      "grad_norm": 0.8169821500778198,
      "learning_rate": 3.355745721271394e-05,
      "loss": 0.6534,
      "step": 550
    },
    {
      "epoch": 0.20546688680975966,
      "grad_norm": 0.9781677722930908,
      "learning_rate": 3.416870415647922e-05,
      "loss": 0.6669,
      "step": 560
    },
    {
      "epoch": 0.20913593835993396,
      "grad_norm": 0.9551028609275818,
      "learning_rate": 3.47799511002445e-05,
      "loss": 0.638,
      "step": 570
    },
    {
      "epoch": 0.21280498991010824,
      "grad_norm": 0.7600991725921631,
      "learning_rate": 3.539119804400978e-05,
      "loss": 0.6364,
      "step": 580
    },
    {
      "epoch": 0.2164740414602825,
      "grad_norm": 0.8121793866157532,
      "learning_rate": 3.600244498777506e-05,
      "loss": 0.6195,
      "step": 590
    },
    {
      "epoch": 0.2201430930104568,
      "grad_norm": 0.867216944694519,
      "learning_rate": 3.661369193154035e-05,
      "loss": 0.6555,
      "step": 600
    },
    {
      "epoch": 0.2238121445606311,
      "grad_norm": 0.8910418152809143,
      "learning_rate": 3.722493887530563e-05,
      "loss": 0.6377,
      "step": 610
    },
    {
      "epoch": 0.22748119611080536,
      "grad_norm": 0.9751493334770203,
      "learning_rate": 3.783618581907091e-05,
      "loss": 0.6429,
      "step": 620
    },
    {
      "epoch": 0.23115024766097964,
      "grad_norm": 0.7061278223991394,
      "learning_rate": 3.8447432762836186e-05,
      "loss": 0.6308,
      "step": 630
    },
    {
      "epoch": 0.2348192992111539,
      "grad_norm": 1.1142009496688843,
      "learning_rate": 3.905867970660147e-05,
      "loss": 0.6392,
      "step": 640
    },
    {
      "epoch": 0.2384883507613282,
      "grad_norm": 0.9368607401847839,
      "learning_rate": 3.966992665036675e-05,
      "loss": 0.618,
      "step": 650
    },
    {
      "epoch": 0.24215740231150248,
      "grad_norm": 0.8624376058578491,
      "learning_rate": 4.028117359413203e-05,
      "loss": 0.6153,
      "step": 660
    },
    {
      "epoch": 0.24582645386167676,
      "grad_norm": 0.7143048048019409,
      "learning_rate": 4.089242053789731e-05,
      "loss": 0.593,
      "step": 670
    },
    {
      "epoch": 0.24949550541185103,
      "grad_norm": 0.9557223320007324,
      "learning_rate": 4.150366748166259e-05,
      "loss": 0.6289,
      "step": 680
    },
    {
      "epoch": 0.25316455696202533,
      "grad_norm": 0.6870782375335693,
      "learning_rate": 4.211491442542788e-05,
      "loss": 0.6068,
      "step": 690
    },
    {
      "epoch": 0.2568336085121996,
      "grad_norm": 0.8731458187103271,
      "learning_rate": 4.272616136919316e-05,
      "loss": 0.6428,
      "step": 700
    },
    {
      "epoch": 0.2605026600623739,
      "grad_norm": 1.0079413652420044,
      "learning_rate": 4.333740831295844e-05,
      "loss": 0.6517,
      "step": 710
    },
    {
      "epoch": 0.26417171161254815,
      "grad_norm": 0.8572641015052795,
      "learning_rate": 4.394865525672372e-05,
      "loss": 0.5917,
      "step": 720
    },
    {
      "epoch": 0.26784076316272243,
      "grad_norm": 0.8210773468017578,
      "learning_rate": 4.4559902200489e-05,
      "loss": 0.5923,
      "step": 730
    },
    {
      "epoch": 0.2715098147128967,
      "grad_norm": 1.3339871168136597,
      "learning_rate": 4.5171149144254284e-05,
      "loss": 0.6521,
      "step": 740
    },
    {
      "epoch": 0.275178866263071,
      "grad_norm": 0.8313754200935364,
      "learning_rate": 4.5782396088019564e-05,
      "loss": 0.6547,
      "step": 750
    },
    {
      "epoch": 0.27884791781324525,
      "grad_norm": 0.8662818670272827,
      "learning_rate": 4.6393643031784844e-05,
      "loss": 0.639,
      "step": 760
    },
    {
      "epoch": 0.2825169693634196,
      "grad_norm": 0.821679949760437,
      "learning_rate": 4.7004889975550123e-05,
      "loss": 0.6073,
      "step": 770
    },
    {
      "epoch": 0.28618602091359385,
      "grad_norm": 0.9807654619216919,
      "learning_rate": 4.761613691931541e-05,
      "loss": 0.5926,
      "step": 780
    },
    {
      "epoch": 0.2898550724637681,
      "grad_norm": 1.052196741104126,
      "learning_rate": 4.822738386308069e-05,
      "loss": 0.6106,
      "step": 790
    },
    {
      "epoch": 0.2935241240139424,
      "grad_norm": 0.9126512408256531,
      "learning_rate": 4.883863080684597e-05,
      "loss": 0.608,
      "step": 800
    },
    {
      "epoch": 0.2971931755641167,
      "grad_norm": 0.7981895208358765,
      "learning_rate": 4.944987775061125e-05,
      "loss": 0.5572,
      "step": 810
    },
    {
      "epoch": 0.30086222711429095,
      "grad_norm": 1.0812228918075562,
      "learning_rate": 4.999999772252235e-05,
      "loss": 0.5998,
      "step": 820
    },
    {
      "epoch": 0.3045312786644652,
      "grad_norm": 1.0476435422897339,
      "learning_rate": 4.999972442570682e-05,
      "loss": 0.6393,
      "step": 830
    },
    {
      "epoch": 0.3082003302146395,
      "grad_norm": 0.8512653708457947,
      "learning_rate": 4.9998995639067493e-05,
      "loss": 0.6259,
      "step": 840
    },
    {
      "epoch": 0.31186938176481377,
      "grad_norm": 0.8550739288330078,
      "learning_rate": 4.99978113758827e-05,
      "loss": 0.5873,
      "step": 850
    },
    {
      "epoch": 0.3155384333149881,
      "grad_norm": 0.8724313378334045,
      "learning_rate": 4.999617165772949e-05,
      "loss": 0.579,
      "step": 860
    },
    {
      "epoch": 0.31920748486516237,
      "grad_norm": 0.8744262456893921,
      "learning_rate": 4.999407651448318e-05,
      "loss": 0.5672,
      "step": 870
    },
    {
      "epoch": 0.32287653641533665,
      "grad_norm": 0.7632190585136414,
      "learning_rate": 4.999152598431685e-05,
      "loss": 0.6068,
      "step": 880
    },
    {
      "epoch": 0.3265455879655109,
      "grad_norm": 0.8382863998413086,
      "learning_rate": 4.9988520113700626e-05,
      "loss": 0.5769,
      "step": 890
    },
    {
      "epoch": 0.3302146395156852,
      "grad_norm": 0.862323522567749,
      "learning_rate": 4.998505895740087e-05,
      "loss": 0.5912,
      "step": 900
    },
    {
      "epoch": 0.33388369106585947,
      "grad_norm": 1.0637726783752441,
      "learning_rate": 4.9981142578479115e-05,
      "loss": 0.6381,
      "step": 910
    },
    {
      "epoch": 0.33755274261603374,
      "grad_norm": 1.0006047487258911,
      "learning_rate": 4.997677104829098e-05,
      "loss": 0.5963,
      "step": 920
    },
    {
      "epoch": 0.341221794166208,
      "grad_norm": 0.7697986960411072,
      "learning_rate": 4.9971944446484865e-05,
      "loss": 0.6031,
      "step": 930
    },
    {
      "epoch": 0.3448908457163823,
      "grad_norm": 0.9483711123466492,
      "learning_rate": 4.996666286100043e-05,
      "loss": 0.5832,
      "step": 940
    },
    {
      "epoch": 0.3485598972665566,
      "grad_norm": 0.8196538090705872,
      "learning_rate": 4.99609263880671e-05,
      "loss": 0.582,
      "step": 950
    },
    {
      "epoch": 0.3522289488167309,
      "grad_norm": 0.9448139071464539,
      "learning_rate": 4.995473513220221e-05,
      "loss": 0.597,
      "step": 960
    },
    {
      "epoch": 0.35589800036690517,
      "grad_norm": 0.9995883107185364,
      "learning_rate": 4.994808920620918e-05,
      "loss": 0.5681,
      "step": 970
    },
    {
      "epoch": 0.35956705191707944,
      "grad_norm": 0.7747149467468262,
      "learning_rate": 4.99409887311754e-05,
      "loss": 0.6065,
      "step": 980
    },
    {
      "epoch": 0.3632361034672537,
      "grad_norm": 0.8338237404823303,
      "learning_rate": 4.9933433836470056e-05,
      "loss": 0.5884,
      "step": 990
    },
    {
      "epoch": 0.366905155017428,
      "grad_norm": 1.0708411931991577,
      "learning_rate": 4.992542465974178e-05,
      "loss": 0.5889,
      "step": 1000
    },
    {
      "epoch": 0.366905155017428,
      "eval_loss": 0.5883203744888306,
      "eval_runtime": 237.62,
      "eval_samples_per_second": 2.55,
      "eval_steps_per_second": 2.55,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 8178,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.6617755930473267e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
