{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.6508897450009172,
  "eval_steps": 500,
  "global_step": 4500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00366905155017428,
      "grad_norm": 0.3877936601638794,
      "learning_rate": 5.501222493887531e-07,
      "loss": 1.3825,
      "step": 10
    },
    {
      "epoch": 0.00733810310034856,
      "grad_norm": 0.3388456106185913,
      "learning_rate": 1.1613691931540342e-06,
      "loss": 1.3519,
      "step": 20
    },
    {
      "epoch": 0.01100715465052284,
      "grad_norm": 0.34713810682296753,
      "learning_rate": 1.7726161369193154e-06,
      "loss": 1.3608,
      "step": 30
    },
    {
      "epoch": 0.01467620620069712,
      "grad_norm": 0.4064188003540039,
      "learning_rate": 2.3838630806845967e-06,
      "loss": 1.3713,
      "step": 40
    },
    {
      "epoch": 0.0183452577508714,
      "grad_norm": 0.45421141386032104,
      "learning_rate": 2.9951100244498777e-06,
      "loss": 1.3726,
      "step": 50
    },
    {
      "epoch": 0.02201430930104568,
      "grad_norm": 0.4744616746902466,
      "learning_rate": 3.606356968215159e-06,
      "loss": 1.3487,
      "step": 60
    },
    {
      "epoch": 0.025683360851219958,
      "grad_norm": 0.6290422677993774,
      "learning_rate": 4.21760391198044e-06,
      "loss": 1.3523,
      "step": 70
    },
    {
      "epoch": 0.02935241240139424,
      "grad_norm": 0.5566685795783997,
      "learning_rate": 4.828850855745722e-06,
      "loss": 1.3289,
      "step": 80
    },
    {
      "epoch": 0.03302146395156852,
      "grad_norm": 0.46856987476348877,
      "learning_rate": 5.440097799511003e-06,
      "loss": 1.3306,
      "step": 90
    },
    {
      "epoch": 0.0366905155017428,
      "grad_norm": 0.35358479619026184,
      "learning_rate": 6.051344743276284e-06,
      "loss": 1.247,
      "step": 100
    },
    {
      "epoch": 0.04035956705191708,
      "grad_norm": 0.4844614565372467,
      "learning_rate": 6.662591687041565e-06,
      "loss": 1.2218,
      "step": 110
    },
    {
      "epoch": 0.04402861860209136,
      "grad_norm": 0.5792201161384583,
      "learning_rate": 7.273838630806847e-06,
      "loss": 1.2077,
      "step": 120
    },
    {
      "epoch": 0.04769767015226564,
      "grad_norm": 0.38933107256889343,
      "learning_rate": 7.885085574572127e-06,
      "loss": 1.1452,
      "step": 130
    },
    {
      "epoch": 0.051366721702439916,
      "grad_norm": 0.364145427942276,
      "learning_rate": 8.496332518337409e-06,
      "loss": 1.0986,
      "step": 140
    },
    {
      "epoch": 0.0550357732526142,
      "grad_norm": 0.4445214569568634,
      "learning_rate": 9.10757946210269e-06,
      "loss": 1.0758,
      "step": 150
    },
    {
      "epoch": 0.05870482480278848,
      "grad_norm": 0.48486754298210144,
      "learning_rate": 9.718826405867972e-06,
      "loss": 1.0014,
      "step": 160
    },
    {
      "epoch": 0.06237387635296276,
      "grad_norm": 0.33367639780044556,
      "learning_rate": 1.0330073349633253e-05,
      "loss": 0.9749,
      "step": 170
    },
    {
      "epoch": 0.06604292790313704,
      "grad_norm": 0.4073357880115509,
      "learning_rate": 1.0941320293398534e-05,
      "loss": 0.9964,
      "step": 180
    },
    {
      "epoch": 0.06971197945331131,
      "grad_norm": 0.489095002412796,
      "learning_rate": 1.1552567237163816e-05,
      "loss": 0.9409,
      "step": 190
    },
    {
      "epoch": 0.0733810310034856,
      "grad_norm": 0.3971366882324219,
      "learning_rate": 1.2163814180929096e-05,
      "loss": 0.9283,
      "step": 200
    },
    {
      "epoch": 0.07705008255365987,
      "grad_norm": 0.44291526079177856,
      "learning_rate": 1.2775061124694377e-05,
      "loss": 0.8758,
      "step": 210
    },
    {
      "epoch": 0.08071913410383416,
      "grad_norm": 0.6228989362716675,
      "learning_rate": 1.3386308068459657e-05,
      "loss": 0.9017,
      "step": 220
    },
    {
      "epoch": 0.08438818565400844,
      "grad_norm": 0.41784918308258057,
      "learning_rate": 1.3997555012224938e-05,
      "loss": 0.8486,
      "step": 230
    },
    {
      "epoch": 0.08805723720418272,
      "grad_norm": 0.49626976251602173,
      "learning_rate": 1.460880195599022e-05,
      "loss": 0.8642,
      "step": 240
    },
    {
      "epoch": 0.091726288754357,
      "grad_norm": 0.5728238224983215,
      "learning_rate": 1.5220048899755501e-05,
      "loss": 0.8622,
      "step": 250
    },
    {
      "epoch": 0.09539534030453128,
      "grad_norm": 0.468300998210907,
      "learning_rate": 1.583129584352078e-05,
      "loss": 0.8142,
      "step": 260
    },
    {
      "epoch": 0.09906439185470556,
      "grad_norm": 0.6429207921028137,
      "learning_rate": 1.6442542787286064e-05,
      "loss": 0.8135,
      "step": 270
    },
    {
      "epoch": 0.10273344340487983,
      "grad_norm": 0.4333305358886719,
      "learning_rate": 1.7053789731051344e-05,
      "loss": 0.7781,
      "step": 280
    },
    {
      "epoch": 0.10640249495505412,
      "grad_norm": 0.7538961172103882,
      "learning_rate": 1.7665036674816627e-05,
      "loss": 0.7782,
      "step": 290
    },
    {
      "epoch": 0.1100715465052284,
      "grad_norm": 0.5683786869049072,
      "learning_rate": 1.8276283618581907e-05,
      "loss": 0.7574,
      "step": 300
    },
    {
      "epoch": 0.11374059805540268,
      "grad_norm": 0.5173904895782471,
      "learning_rate": 1.888753056234719e-05,
      "loss": 0.7558,
      "step": 310
    },
    {
      "epoch": 0.11740964960557695,
      "grad_norm": 0.6803333163261414,
      "learning_rate": 1.949877750611247e-05,
      "loss": 0.7621,
      "step": 320
    },
    {
      "epoch": 0.12107870115575124,
      "grad_norm": 0.7055644989013672,
      "learning_rate": 2.0110024449877753e-05,
      "loss": 0.7509,
      "step": 330
    },
    {
      "epoch": 0.12474775270592552,
      "grad_norm": 0.6526551842689514,
      "learning_rate": 2.0721271393643033e-05,
      "loss": 0.7612,
      "step": 340
    },
    {
      "epoch": 0.1284168042560998,
      "grad_norm": 1.0160521268844604,
      "learning_rate": 2.1332518337408312e-05,
      "loss": 0.7526,
      "step": 350
    },
    {
      "epoch": 0.13208585580627408,
      "grad_norm": 0.6214171051979065,
      "learning_rate": 2.1943765281173596e-05,
      "loss": 0.7192,
      "step": 360
    },
    {
      "epoch": 0.13575490735644835,
      "grad_norm": 0.6929377317428589,
      "learning_rate": 2.2555012224938875e-05,
      "loss": 0.7006,
      "step": 370
    },
    {
      "epoch": 0.13942395890662262,
      "grad_norm": 0.7169085144996643,
      "learning_rate": 2.316625916870416e-05,
      "loss": 0.6955,
      "step": 380
    },
    {
      "epoch": 0.14309301045679693,
      "grad_norm": 0.8329369425773621,
      "learning_rate": 2.3777506112469438e-05,
      "loss": 0.7199,
      "step": 390
    },
    {
      "epoch": 0.1467620620069712,
      "grad_norm": 0.6524739265441895,
      "learning_rate": 2.438875305623472e-05,
      "loss": 0.6703,
      "step": 400
    },
    {
      "epoch": 0.15043111355714547,
      "grad_norm": 0.7267888784408569,
      "learning_rate": 2.5e-05,
      "loss": 0.6875,
      "step": 410
    },
    {
      "epoch": 0.15410016510731975,
      "grad_norm": 0.6155242323875427,
      "learning_rate": 2.561124694376528e-05,
      "loss": 0.7156,
      "step": 420
    },
    {
      "epoch": 0.15776921665749405,
      "grad_norm": 0.7568008303642273,
      "learning_rate": 2.6222493887530564e-05,
      "loss": 0.6965,
      "step": 430
    },
    {
      "epoch": 0.16143826820766832,
      "grad_norm": 0.6655860543251038,
      "learning_rate": 2.6833740831295844e-05,
      "loss": 0.6546,
      "step": 440
    },
    {
      "epoch": 0.1651073197578426,
      "grad_norm": 1.1648468971252441,
      "learning_rate": 2.7444987775061127e-05,
      "loss": 0.6819,
      "step": 450
    },
    {
      "epoch": 0.16877637130801687,
      "grad_norm": 0.68362957239151,
      "learning_rate": 2.8056234718826407e-05,
      "loss": 0.6855,
      "step": 460
    },
    {
      "epoch": 0.17244542285819114,
      "grad_norm": 0.6543752551078796,
      "learning_rate": 2.866748166259169e-05,
      "loss": 0.645,
      "step": 470
    },
    {
      "epoch": 0.17611447440836545,
      "grad_norm": 0.6918438076972961,
      "learning_rate": 2.927872860635697e-05,
      "loss": 0.6267,
      "step": 480
    },
    {
      "epoch": 0.17978352595853972,
      "grad_norm": 0.7780126333236694,
      "learning_rate": 2.988997555012225e-05,
      "loss": 0.6547,
      "step": 490
    },
    {
      "epoch": 0.183452577508714,
      "grad_norm": 0.6887812614440918,
      "learning_rate": 3.0501222493887533e-05,
      "loss": 0.6507,
      "step": 500
    },
    {
      "epoch": 0.183452577508714,
      "eval_loss": 0.6555390357971191,
      "eval_runtime": 241.4797,
      "eval_samples_per_second": 2.51,
      "eval_steps_per_second": 2.51,
      "step": 500
    },
    {
      "epoch": 0.18712162905888827,
      "grad_norm": 0.756022572517395,
      "learning_rate": 3.1112469437652816e-05,
      "loss": 0.6563,
      "step": 510
    },
    {
      "epoch": 0.19079068060906257,
      "grad_norm": 0.8010755777359009,
      "learning_rate": 3.1723716381418096e-05,
      "loss": 0.662,
      "step": 520
    },
    {
      "epoch": 0.19445973215923684,
      "grad_norm": 0.7894098162651062,
      "learning_rate": 3.2334963325183375e-05,
      "loss": 0.6657,
      "step": 530
    },
    {
      "epoch": 0.19812878370941112,
      "grad_norm": 1.0443938970565796,
      "learning_rate": 3.2946210268948655e-05,
      "loss": 0.6485,
      "step": 540
    },
    {
      "epoch": 0.2017978352595854,
      "grad_norm": 0.8169821500778198,
      "learning_rate": 3.355745721271394e-05,
      "loss": 0.6534,
      "step": 550
    },
    {
      "epoch": 0.20546688680975966,
      "grad_norm": 0.9781677722930908,
      "learning_rate": 3.416870415647922e-05,
      "loss": 0.6669,
      "step": 560
    },
    {
      "epoch": 0.20913593835993396,
      "grad_norm": 0.9551028609275818,
      "learning_rate": 3.47799511002445e-05,
      "loss": 0.638,
      "step": 570
    },
    {
      "epoch": 0.21280498991010824,
      "grad_norm": 0.7600991725921631,
      "learning_rate": 3.539119804400978e-05,
      "loss": 0.6364,
      "step": 580
    },
    {
      "epoch": 0.2164740414602825,
      "grad_norm": 0.8121793866157532,
      "learning_rate": 3.600244498777506e-05,
      "loss": 0.6195,
      "step": 590
    },
    {
      "epoch": 0.2201430930104568,
      "grad_norm": 0.867216944694519,
      "learning_rate": 3.661369193154035e-05,
      "loss": 0.6555,
      "step": 600
    },
    {
      "epoch": 0.2238121445606311,
      "grad_norm": 0.8910418152809143,
      "learning_rate": 3.722493887530563e-05,
      "loss": 0.6377,
      "step": 610
    },
    {
      "epoch": 0.22748119611080536,
      "grad_norm": 0.9751493334770203,
      "learning_rate": 3.783618581907091e-05,
      "loss": 0.6429,
      "step": 620
    },
    {
      "epoch": 0.23115024766097964,
      "grad_norm": 0.7061278223991394,
      "learning_rate": 3.8447432762836186e-05,
      "loss": 0.6308,
      "step": 630
    },
    {
      "epoch": 0.2348192992111539,
      "grad_norm": 1.1142009496688843,
      "learning_rate": 3.905867970660147e-05,
      "loss": 0.6392,
      "step": 640
    },
    {
      "epoch": 0.2384883507613282,
      "grad_norm": 0.9368607401847839,
      "learning_rate": 3.966992665036675e-05,
      "loss": 0.618,
      "step": 650
    },
    {
      "epoch": 0.24215740231150248,
      "grad_norm": 0.8624376058578491,
      "learning_rate": 4.028117359413203e-05,
      "loss": 0.6153,
      "step": 660
    },
    {
      "epoch": 0.24582645386167676,
      "grad_norm": 0.7143048048019409,
      "learning_rate": 4.089242053789731e-05,
      "loss": 0.593,
      "step": 670
    },
    {
      "epoch": 0.24949550541185103,
      "grad_norm": 0.9557223320007324,
      "learning_rate": 4.150366748166259e-05,
      "loss": 0.6289,
      "step": 680
    },
    {
      "epoch": 0.25316455696202533,
      "grad_norm": 0.6870782375335693,
      "learning_rate": 4.211491442542788e-05,
      "loss": 0.6068,
      "step": 690
    },
    {
      "epoch": 0.2568336085121996,
      "grad_norm": 0.8731458187103271,
      "learning_rate": 4.272616136919316e-05,
      "loss": 0.6428,
      "step": 700
    },
    {
      "epoch": 0.2605026600623739,
      "grad_norm": 1.0079413652420044,
      "learning_rate": 4.333740831295844e-05,
      "loss": 0.6517,
      "step": 710
    },
    {
      "epoch": 0.26417171161254815,
      "grad_norm": 0.8572641015052795,
      "learning_rate": 4.394865525672372e-05,
      "loss": 0.5917,
      "step": 720
    },
    {
      "epoch": 0.26784076316272243,
      "grad_norm": 0.8210773468017578,
      "learning_rate": 4.4559902200489e-05,
      "loss": 0.5923,
      "step": 730
    },
    {
      "epoch": 0.2715098147128967,
      "grad_norm": 1.3339871168136597,
      "learning_rate": 4.5171149144254284e-05,
      "loss": 0.6521,
      "step": 740
    },
    {
      "epoch": 0.275178866263071,
      "grad_norm": 0.8313754200935364,
      "learning_rate": 4.5782396088019564e-05,
      "loss": 0.6547,
      "step": 750
    },
    {
      "epoch": 0.27884791781324525,
      "grad_norm": 0.8662818670272827,
      "learning_rate": 4.6393643031784844e-05,
      "loss": 0.639,
      "step": 760
    },
    {
      "epoch": 0.2825169693634196,
      "grad_norm": 0.821679949760437,
      "learning_rate": 4.7004889975550123e-05,
      "loss": 0.6073,
      "step": 770
    },
    {
      "epoch": 0.28618602091359385,
      "grad_norm": 0.9807654619216919,
      "learning_rate": 4.761613691931541e-05,
      "loss": 0.5926,
      "step": 780
    },
    {
      "epoch": 0.2898550724637681,
      "grad_norm": 1.052196741104126,
      "learning_rate": 4.822738386308069e-05,
      "loss": 0.6106,
      "step": 790
    },
    {
      "epoch": 0.2935241240139424,
      "grad_norm": 0.9126512408256531,
      "learning_rate": 4.883863080684597e-05,
      "loss": 0.608,
      "step": 800
    },
    {
      "epoch": 0.2971931755641167,
      "grad_norm": 0.7981895208358765,
      "learning_rate": 4.944987775061125e-05,
      "loss": 0.5572,
      "step": 810
    },
    {
      "epoch": 0.30086222711429095,
      "grad_norm": 1.0812228918075562,
      "learning_rate": 4.999999772252235e-05,
      "loss": 0.5998,
      "step": 820
    },
    {
      "epoch": 0.3045312786644652,
      "grad_norm": 1.0476435422897339,
      "learning_rate": 4.999972442570682e-05,
      "loss": 0.6393,
      "step": 830
    },
    {
      "epoch": 0.3082003302146395,
      "grad_norm": 0.8512653708457947,
      "learning_rate": 4.9998995639067493e-05,
      "loss": 0.6259,
      "step": 840
    },
    {
      "epoch": 0.31186938176481377,
      "grad_norm": 0.8550739288330078,
      "learning_rate": 4.99978113758827e-05,
      "loss": 0.5873,
      "step": 850
    },
    {
      "epoch": 0.3155384333149881,
      "grad_norm": 0.8724313378334045,
      "learning_rate": 4.999617165772949e-05,
      "loss": 0.579,
      "step": 860
    },
    {
      "epoch": 0.31920748486516237,
      "grad_norm": 0.8744262456893921,
      "learning_rate": 4.999407651448318e-05,
      "loss": 0.5672,
      "step": 870
    },
    {
      "epoch": 0.32287653641533665,
      "grad_norm": 0.7632190585136414,
      "learning_rate": 4.999152598431685e-05,
      "loss": 0.6068,
      "step": 880
    },
    {
      "epoch": 0.3265455879655109,
      "grad_norm": 0.8382863998413086,
      "learning_rate": 4.9988520113700626e-05,
      "loss": 0.5769,
      "step": 890
    },
    {
      "epoch": 0.3302146395156852,
      "grad_norm": 0.862323522567749,
      "learning_rate": 4.998505895740087e-05,
      "loss": 0.5912,
      "step": 900
    },
    {
      "epoch": 0.33388369106585947,
      "grad_norm": 1.0637726783752441,
      "learning_rate": 4.9981142578479115e-05,
      "loss": 0.6381,
      "step": 910
    },
    {
      "epoch": 0.33755274261603374,
      "grad_norm": 1.0006047487258911,
      "learning_rate": 4.997677104829098e-05,
      "loss": 0.5963,
      "step": 920
    },
    {
      "epoch": 0.341221794166208,
      "grad_norm": 0.7697986960411072,
      "learning_rate": 4.9971944446484865e-05,
      "loss": 0.6031,
      "step": 930
    },
    {
      "epoch": 0.3448908457163823,
      "grad_norm": 0.9483711123466492,
      "learning_rate": 4.996666286100043e-05,
      "loss": 0.5832,
      "step": 940
    },
    {
      "epoch": 0.3485598972665566,
      "grad_norm": 0.8196538090705872,
      "learning_rate": 4.99609263880671e-05,
      "loss": 0.582,
      "step": 950
    },
    {
      "epoch": 0.3522289488167309,
      "grad_norm": 0.9448139071464539,
      "learning_rate": 4.995473513220221e-05,
      "loss": 0.597,
      "step": 960
    },
    {
      "epoch": 0.35589800036690517,
      "grad_norm": 0.9995883107185364,
      "learning_rate": 4.994808920620918e-05,
      "loss": 0.5681,
      "step": 970
    },
    {
      "epoch": 0.35956705191707944,
      "grad_norm": 0.7747149467468262,
      "learning_rate": 4.99409887311754e-05,
      "loss": 0.6065,
      "step": 980
    },
    {
      "epoch": 0.3632361034672537,
      "grad_norm": 0.8338237404823303,
      "learning_rate": 4.9933433836470056e-05,
      "loss": 0.5884,
      "step": 990
    },
    {
      "epoch": 0.366905155017428,
      "grad_norm": 1.0708411931991577,
      "learning_rate": 4.992542465974178e-05,
      "loss": 0.5889,
      "step": 1000
    },
    {
      "epoch": 0.366905155017428,
      "eval_loss": 0.5883203744888306,
      "eval_runtime": 237.62,
      "eval_samples_per_second": 2.55,
      "eval_steps_per_second": 2.55,
      "step": 1000
    },
    {
      "epoch": 0.37057420656760226,
      "grad_norm": 0.74204021692276,
      "learning_rate": 4.991696134691613e-05,
      "loss": 0.6142,
      "step": 1010
    },
    {
      "epoch": 0.37424325811777653,
      "grad_norm": 1.1142209768295288,
      "learning_rate": 4.99080440521929e-05,
      "loss": 0.5405,
      "step": 1020
    },
    {
      "epoch": 0.3779123096679508,
      "grad_norm": 0.9425484538078308,
      "learning_rate": 4.9898672938043385e-05,
      "loss": 0.6005,
      "step": 1030
    },
    {
      "epoch": 0.38158136121812514,
      "grad_norm": 0.7661627531051636,
      "learning_rate": 4.988884817520732e-05,
      "loss": 0.5774,
      "step": 1040
    },
    {
      "epoch": 0.3852504127682994,
      "grad_norm": 0.8633294105529785,
      "learning_rate": 4.98785699426899e-05,
      "loss": 0.5964,
      "step": 1050
    },
    {
      "epoch": 0.3889194643184737,
      "grad_norm": 0.8688271641731262,
      "learning_rate": 4.986783842775836e-05,
      "loss": 0.5866,
      "step": 1060
    },
    {
      "epoch": 0.39258851586864796,
      "grad_norm": 0.875762403011322,
      "learning_rate": 4.9856653825938715e-05,
      "loss": 0.5631,
      "step": 1070
    },
    {
      "epoch": 0.39625756741882223,
      "grad_norm": 0.7623623609542847,
      "learning_rate": 4.9845016341012095e-05,
      "loss": 0.5777,
      "step": 1080
    },
    {
      "epoch": 0.3999266189689965,
      "grad_norm": 1.0272465944290161,
      "learning_rate": 4.9832926185011084e-05,
      "loss": 0.5653,
      "step": 1090
    },
    {
      "epoch": 0.4035956705191708,
      "grad_norm": 0.7474942207336426,
      "learning_rate": 4.9820383578215815e-05,
      "loss": 0.5838,
      "step": 1100
    },
    {
      "epoch": 0.40726472206934505,
      "grad_norm": 0.8431952595710754,
      "learning_rate": 4.980738874915001e-05,
      "loss": 0.5779,
      "step": 1110
    },
    {
      "epoch": 0.4109337736195193,
      "grad_norm": 0.7840742468833923,
      "learning_rate": 4.9793941934576774e-05,
      "loss": 0.5956,
      "step": 1120
    },
    {
      "epoch": 0.41460282516969366,
      "grad_norm": 0.7531408667564392,
      "learning_rate": 4.978004337949429e-05,
      "loss": 0.5619,
      "step": 1130
    },
    {
      "epoch": 0.41827187671986793,
      "grad_norm": 0.8034108877182007,
      "learning_rate": 4.976569333713137e-05,
      "loss": 0.5715,
      "step": 1140
    },
    {
      "epoch": 0.4219409282700422,
      "grad_norm": 0.6612378358840942,
      "learning_rate": 4.975089206894283e-05,
      "loss": 0.5776,
      "step": 1150
    },
    {
      "epoch": 0.4256099798202165,
      "grad_norm": 0.741470217704773,
      "learning_rate": 4.9735639844604706e-05,
      "loss": 0.551,
      "step": 1160
    },
    {
      "epoch": 0.42927903137039075,
      "grad_norm": 0.8484413027763367,
      "learning_rate": 4.9719936942009406e-05,
      "loss": 0.5912,
      "step": 1170
    },
    {
      "epoch": 0.432948082920565,
      "grad_norm": 0.9448020458221436,
      "learning_rate": 4.970378364726056e-05,
      "loss": 0.5932,
      "step": 1180
    },
    {
      "epoch": 0.4366171344707393,
      "grad_norm": 0.7909348011016846,
      "learning_rate": 4.968718025466788e-05,
      "loss": 0.584,
      "step": 1190
    },
    {
      "epoch": 0.4402861860209136,
      "grad_norm": 0.7125610709190369,
      "learning_rate": 4.967012706674174e-05,
      "loss": 0.5537,
      "step": 1200
    },
    {
      "epoch": 0.44395523757108785,
      "grad_norm": 0.8675113916397095,
      "learning_rate": 4.965262439418772e-05,
      "loss": 0.5583,
      "step": 1210
    },
    {
      "epoch": 0.4476242891212622,
      "grad_norm": 0.9049820303916931,
      "learning_rate": 4.96346725559009e-05,
      "loss": 0.5909,
      "step": 1220
    },
    {
      "epoch": 0.45129334067143645,
      "grad_norm": 0.9292231202125549,
      "learning_rate": 4.961627187896006e-05,
      "loss": 0.5983,
      "step": 1230
    },
    {
      "epoch": 0.4549623922216107,
      "grad_norm": 0.7964368462562561,
      "learning_rate": 4.9597422698621764e-05,
      "loss": 0.5753,
      "step": 1240
    },
    {
      "epoch": 0.458631443771785,
      "grad_norm": 0.6815668940544128,
      "learning_rate": 4.9578125358314175e-05,
      "loss": 0.5955,
      "step": 1250
    },
    {
      "epoch": 0.46230049532195927,
      "grad_norm": 0.9475581049919128,
      "learning_rate": 4.9558380209630864e-05,
      "loss": 0.5887,
      "step": 1260
    },
    {
      "epoch": 0.46596954687213354,
      "grad_norm": 1.021878719329834,
      "learning_rate": 4.953818761232435e-05,
      "loss": 0.5716,
      "step": 1270
    },
    {
      "epoch": 0.4696385984223078,
      "grad_norm": 0.915371835231781,
      "learning_rate": 4.9517547934299604e-05,
      "loss": 0.5975,
      "step": 1280
    },
    {
      "epoch": 0.4733076499724821,
      "grad_norm": 0.8428240418434143,
      "learning_rate": 4.94964615516073e-05,
      "loss": 0.5626,
      "step": 1290
    },
    {
      "epoch": 0.4769767015226564,
      "grad_norm": 0.8997093439102173,
      "learning_rate": 4.947492884843699e-05,
      "loss": 0.5735,
      "step": 1300
    },
    {
      "epoch": 0.4806457530728307,
      "grad_norm": 1.0769418478012085,
      "learning_rate": 4.945295021711008e-05,
      "loss": 0.6035,
      "step": 1310
    },
    {
      "epoch": 0.48431480462300497,
      "grad_norm": 0.9459863305091858,
      "learning_rate": 4.94305260580727e-05,
      "loss": 0.5842,
      "step": 1320
    },
    {
      "epoch": 0.48798385617317924,
      "grad_norm": 0.8330615758895874,
      "learning_rate": 4.940765677988841e-05,
      "loss": 0.5616,
      "step": 1330
    },
    {
      "epoch": 0.4916529077233535,
      "grad_norm": 0.9455893039703369,
      "learning_rate": 4.938434279923073e-05,
      "loss": 0.616,
      "step": 1340
    },
    {
      "epoch": 0.4953219592735278,
      "grad_norm": 0.8248706459999084,
      "learning_rate": 4.9360584540875585e-05,
      "loss": 0.5723,
      "step": 1350
    },
    {
      "epoch": 0.49899101082370206,
      "grad_norm": 0.7279864549636841,
      "learning_rate": 4.933638243769355e-05,
      "loss": 0.5578,
      "step": 1360
    },
    {
      "epoch": 0.5026600623738764,
      "grad_norm": 0.8937111496925354,
      "learning_rate": 4.931173693064195e-05,
      "loss": 0.5792,
      "step": 1370
    },
    {
      "epoch": 0.5063291139240507,
      "grad_norm": 0.9426361918449402,
      "learning_rate": 4.9286648468756844e-05,
      "loss": 0.5458,
      "step": 1380
    },
    {
      "epoch": 0.5099981654742249,
      "grad_norm": 0.8062474727630615,
      "learning_rate": 4.9261117509144825e-05,
      "loss": 0.5862,
      "step": 1390
    },
    {
      "epoch": 0.5136672170243992,
      "grad_norm": 0.9370191097259521,
      "learning_rate": 4.923514451697472e-05,
      "loss": 0.5358,
      "step": 1400
    },
    {
      "epoch": 0.5173362685745735,
      "grad_norm": 0.8648721575737,
      "learning_rate": 4.9208729965469087e-05,
      "loss": 0.537,
      "step": 1410
    },
    {
      "epoch": 0.5210053201247478,
      "grad_norm": 0.9978837966918945,
      "learning_rate": 4.9181874335895604e-05,
      "loss": 0.5568,
      "step": 1420
    },
    {
      "epoch": 0.524674371674922,
      "grad_norm": 0.8308568596839905,
      "learning_rate": 4.915457811755832e-05,
      "loss": 0.5836,
      "step": 1430
    },
    {
      "epoch": 0.5283434232250963,
      "grad_norm": 0.9117475152015686,
      "learning_rate": 4.912684180778869e-05,
      "loss": 0.5697,
      "step": 1440
    },
    {
      "epoch": 0.5320124747752706,
      "grad_norm": 0.7363874912261963,
      "learning_rate": 4.909866591193656e-05,
      "loss": 0.5637,
      "step": 1450
    },
    {
      "epoch": 0.5356815263254449,
      "grad_norm": 1.0187169313430786,
      "learning_rate": 4.9070050943360935e-05,
      "loss": 0.5644,
      "step": 1460
    },
    {
      "epoch": 0.5393505778756191,
      "grad_norm": 0.9083443284034729,
      "learning_rate": 4.9040997423420656e-05,
      "loss": 0.5591,
      "step": 1470
    },
    {
      "epoch": 0.5430196294257934,
      "grad_norm": 0.793476939201355,
      "learning_rate": 4.901150588146487e-05,
      "loss": 0.5445,
      "step": 1480
    },
    {
      "epoch": 0.5466886809759677,
      "grad_norm": 0.9009830951690674,
      "learning_rate": 4.8981576854823367e-05,
      "loss": 0.551,
      "step": 1490
    },
    {
      "epoch": 0.550357732526142,
      "grad_norm": 0.9271986484527588,
      "learning_rate": 4.895121088879685e-05,
      "loss": 0.5739,
      "step": 1500
    },
    {
      "epoch": 0.550357732526142,
      "eval_loss": 0.5655648708343506,
      "eval_runtime": 240.2058,
      "eval_samples_per_second": 2.523,
      "eval_steps_per_second": 2.523,
      "step": 1500
    },
    {
      "epoch": 0.5540267840763162,
      "grad_norm": 0.8860954642295837,
      "learning_rate": 4.8920408536646975e-05,
      "loss": 0.5868,
      "step": 1510
    },
    {
      "epoch": 0.5576958356264905,
      "grad_norm": 0.8972140550613403,
      "learning_rate": 4.8889170359586226e-05,
      "loss": 0.5674,
      "step": 1520
    },
    {
      "epoch": 0.5613648871766649,
      "grad_norm": 0.8974564075469971,
      "learning_rate": 4.885749692676775e-05,
      "loss": 0.5776,
      "step": 1530
    },
    {
      "epoch": 0.5650339387268392,
      "grad_norm": 0.8998370170593262,
      "learning_rate": 4.882538881527497e-05,
      "loss": 0.5535,
      "step": 1540
    },
    {
      "epoch": 0.5687029902770134,
      "grad_norm": 0.9352656006813049,
      "learning_rate": 4.8792846610111046e-05,
      "loss": 0.5702,
      "step": 1550
    },
    {
      "epoch": 0.5723720418271877,
      "grad_norm": 1.009832739830017,
      "learning_rate": 4.875987090418826e-05,
      "loss": 0.5824,
      "step": 1560
    },
    {
      "epoch": 0.576041093377362,
      "grad_norm": 0.8600253462791443,
      "learning_rate": 4.872646229831716e-05,
      "loss": 0.556,
      "step": 1570
    },
    {
      "epoch": 0.5797101449275363,
      "grad_norm": 0.7715021967887878,
      "learning_rate": 4.869262140119566e-05,
      "loss": 0.5362,
      "step": 1580
    },
    {
      "epoch": 0.5833791964777105,
      "grad_norm": 0.9116750955581665,
      "learning_rate": 4.865834882939794e-05,
      "loss": 0.5574,
      "step": 1590
    },
    {
      "epoch": 0.5870482480278848,
      "grad_norm": 0.8421168327331543,
      "learning_rate": 4.862364520736317e-05,
      "loss": 0.5805,
      "step": 1600
    },
    {
      "epoch": 0.5907172995780591,
      "grad_norm": 0.8925551772117615,
      "learning_rate": 4.858851116738419e-05,
      "loss": 0.5944,
      "step": 1610
    },
    {
      "epoch": 0.5943863511282333,
      "grad_norm": 0.8234690427780151,
      "learning_rate": 4.855294734959597e-05,
      "loss": 0.5491,
      "step": 1620
    },
    {
      "epoch": 0.5980554026784076,
      "grad_norm": 1.1261595487594604,
      "learning_rate": 4.851695440196394e-05,
      "loss": 0.568,
      "step": 1630
    },
    {
      "epoch": 0.6017244542285819,
      "grad_norm": 0.7588224411010742,
      "learning_rate": 4.8480532980272184e-05,
      "loss": 0.5545,
      "step": 1640
    },
    {
      "epoch": 0.6053935057787562,
      "grad_norm": 0.8019400238990784,
      "learning_rate": 4.844368374811149e-05,
      "loss": 0.5615,
      "step": 1650
    },
    {
      "epoch": 0.6090625573289304,
      "grad_norm": 0.9038190245628357,
      "learning_rate": 4.840640737686727e-05,
      "loss": 0.5828,
      "step": 1660
    },
    {
      "epoch": 0.6127316088791047,
      "grad_norm": 0.7243975400924683,
      "learning_rate": 4.836870454570731e-05,
      "loss": 0.5662,
      "step": 1670
    },
    {
      "epoch": 0.616400660429279,
      "grad_norm": 0.9103299975395203,
      "learning_rate": 4.833057594156944e-05,
      "loss": 0.5528,
      "step": 1680
    },
    {
      "epoch": 0.6200697119794533,
      "grad_norm": 1.1013984680175781,
      "learning_rate": 4.829202225914895e-05,
      "loss": 0.5556,
      "step": 1690
    },
    {
      "epoch": 0.6237387635296275,
      "grad_norm": 0.7952206134796143,
      "learning_rate": 4.825304420088599e-05,
      "loss": 0.5452,
      "step": 1700
    },
    {
      "epoch": 0.6274078150798019,
      "grad_norm": 0.8104619383811951,
      "learning_rate": 4.821364247695274e-05,
      "loss": 0.5591,
      "step": 1710
    },
    {
      "epoch": 0.6310768666299762,
      "grad_norm": 0.7545372247695923,
      "learning_rate": 4.8173817805240487e-05,
      "loss": 0.5738,
      "step": 1720
    },
    {
      "epoch": 0.6347459181801505,
      "grad_norm": 0.9334061145782471,
      "learning_rate": 4.813357091134654e-05,
      "loss": 0.5709,
      "step": 1730
    },
    {
      "epoch": 0.6384149697303247,
      "grad_norm": 0.6794409155845642,
      "learning_rate": 4.8092902528561e-05,
      "loss": 0.591,
      "step": 1740
    },
    {
      "epoch": 0.642084021280499,
      "grad_norm": 1.0061829090118408,
      "learning_rate": 4.805181339785342e-05,
      "loss": 0.5723,
      "step": 1750
    },
    {
      "epoch": 0.6457530728306733,
      "grad_norm": 1.2289650440216064,
      "learning_rate": 4.801030426785928e-05,
      "loss": 0.5788,
      "step": 1760
    },
    {
      "epoch": 0.6494221243808476,
      "grad_norm": 1.067782998085022,
      "learning_rate": 4.796837589486639e-05,
      "loss": 0.5468,
      "step": 1770
    },
    {
      "epoch": 0.6530911759310218,
      "grad_norm": 0.8999747037887573,
      "learning_rate": 4.792602904280104e-05,
      "loss": 0.5634,
      "step": 1780
    },
    {
      "epoch": 0.6567602274811961,
      "grad_norm": 0.8649622797966003,
      "learning_rate": 4.788326448321415e-05,
      "loss": 0.5892,
      "step": 1790
    },
    {
      "epoch": 0.6604292790313704,
      "grad_norm": 0.863810122013092,
      "learning_rate": 4.784008299526716e-05,
      "loss": 0.5562,
      "step": 1800
    },
    {
      "epoch": 0.6640983305815447,
      "grad_norm": 0.8143636584281921,
      "learning_rate": 4.779648536571791e-05,
      "loss": 0.5553,
      "step": 1810
    },
    {
      "epoch": 0.6677673821317189,
      "grad_norm": 0.9549927115440369,
      "learning_rate": 4.775247238890619e-05,
      "loss": 0.5448,
      "step": 1820
    },
    {
      "epoch": 0.6714364336818932,
      "grad_norm": 1.003637671470642,
      "learning_rate": 4.770804486673938e-05,
      "loss": 0.5678,
      "step": 1830
    },
    {
      "epoch": 0.6751054852320675,
      "grad_norm": 0.825347363948822,
      "learning_rate": 4.766320360867775e-05,
      "loss": 0.5374,
      "step": 1840
    },
    {
      "epoch": 0.6787745367822418,
      "grad_norm": 1.002130150794983,
      "learning_rate": 4.76179494317198e-05,
      "loss": 0.5441,
      "step": 1850
    },
    {
      "epoch": 0.682443588332416,
      "grad_norm": 0.9000377655029297,
      "learning_rate": 4.757228316038729e-05,
      "loss": 0.5404,
      "step": 1860
    },
    {
      "epoch": 0.6861126398825903,
      "grad_norm": 0.7789478302001953,
      "learning_rate": 4.752620562671027e-05,
      "loss": 0.5275,
      "step": 1870
    },
    {
      "epoch": 0.6897816914327646,
      "grad_norm": 0.7302083969116211,
      "learning_rate": 4.7479717670211904e-05,
      "loss": 0.5562,
      "step": 1880
    },
    {
      "epoch": 0.693450742982939,
      "grad_norm": 0.8888310194015503,
      "learning_rate": 4.743282013789316e-05,
      "loss": 0.5606,
      "step": 1890
    },
    {
      "epoch": 0.6971197945331132,
      "grad_norm": 0.8932925462722778,
      "learning_rate": 4.738551388421743e-05,
      "loss": 0.5819,
      "step": 1900
    },
    {
      "epoch": 0.7007888460832875,
      "grad_norm": 0.8947935700416565,
      "learning_rate": 4.733779977109487e-05,
      "loss": 0.5537,
      "step": 1910
    },
    {
      "epoch": 0.7044578976334618,
      "grad_norm": 0.8630931973457336,
      "learning_rate": 4.728967866786681e-05,
      "loss": 0.5539,
      "step": 1920
    },
    {
      "epoch": 0.7081269491836361,
      "grad_norm": 0.8323912024497986,
      "learning_rate": 4.7241151451289813e-05,
      "loss": 0.5714,
      "step": 1930
    },
    {
      "epoch": 0.7117960007338103,
      "grad_norm": 0.8414443731307983,
      "learning_rate": 4.719221900551976e-05,
      "loss": 0.5625,
      "step": 1940
    },
    {
      "epoch": 0.7154650522839846,
      "grad_norm": 0.8163629174232483,
      "learning_rate": 4.714288222209573e-05,
      "loss": 0.5594,
      "step": 1950
    },
    {
      "epoch": 0.7191341038341589,
      "grad_norm": 0.9008724689483643,
      "learning_rate": 4.7093141999923726e-05,
      "loss": 0.5762,
      "step": 1960
    },
    {
      "epoch": 0.7228031553843332,
      "grad_norm": 0.8228312730789185,
      "learning_rate": 4.7042999245260356e-05,
      "loss": 0.5703,
      "step": 1970
    },
    {
      "epoch": 0.7264722069345074,
      "grad_norm": 1.0673984289169312,
      "learning_rate": 4.6992454871696265e-05,
      "loss": 0.57,
      "step": 1980
    },
    {
      "epoch": 0.7301412584846817,
      "grad_norm": 0.7121770977973938,
      "learning_rate": 4.694150980013952e-05,
      "loss": 0.5426,
      "step": 1990
    },
    {
      "epoch": 0.733810310034856,
      "grad_norm": 0.7347238063812256,
      "learning_rate": 4.68901649587988e-05,
      "loss": 0.5766,
      "step": 2000
    },
    {
      "epoch": 0.733810310034856,
      "eval_loss": 0.552966833114624,
      "eval_runtime": 240.4235,
      "eval_samples_per_second": 2.521,
      "eval_steps_per_second": 2.521,
      "step": 2000
    },
    {
      "epoch": 0.7374793615850302,
      "grad_norm": 0.8168190121650696,
      "learning_rate": 4.683842128316655e-05,
      "loss": 0.568,
      "step": 2010
    },
    {
      "epoch": 0.7411484131352045,
      "grad_norm": 0.9358319044113159,
      "learning_rate": 4.6786279716001855e-05,
      "loss": 0.5794,
      "step": 2020
    },
    {
      "epoch": 0.7448174646853788,
      "grad_norm": 0.8422871828079224,
      "learning_rate": 4.673374120731333e-05,
      "loss": 0.5553,
      "step": 2030
    },
    {
      "epoch": 0.7484865162355531,
      "grad_norm": 0.9374701976776123,
      "learning_rate": 4.6680806714341765e-05,
      "loss": 0.5456,
      "step": 2040
    },
    {
      "epoch": 0.7521555677857273,
      "grad_norm": 0.9011454582214355,
      "learning_rate": 4.662747720154269e-05,
      "loss": 0.5508,
      "step": 2050
    },
    {
      "epoch": 0.7558246193359016,
      "grad_norm": 1.0650379657745361,
      "learning_rate": 4.657375364056885e-05,
      "loss": 0.5661,
      "step": 2060
    },
    {
      "epoch": 0.759493670886076,
      "grad_norm": 0.9504855275154114,
      "learning_rate": 4.651963701025244e-05,
      "loss": 0.5852,
      "step": 2070
    },
    {
      "epoch": 0.7631627224362503,
      "grad_norm": 0.7971680760383606,
      "learning_rate": 4.646512829658731e-05,
      "loss": 0.5335,
      "step": 2080
    },
    {
      "epoch": 0.7668317739864245,
      "grad_norm": 0.7174059748649597,
      "learning_rate": 4.641022849271097e-05,
      "loss": 0.5579,
      "step": 2090
    },
    {
      "epoch": 0.7705008255365988,
      "grad_norm": 0.8644967675209045,
      "learning_rate": 4.6354938598886544e-05,
      "loss": 0.5464,
      "step": 2100
    },
    {
      "epoch": 0.7741698770867731,
      "grad_norm": 0.6945546269416809,
      "learning_rate": 4.6299259622484486e-05,
      "loss": 0.5209,
      "step": 2110
    },
    {
      "epoch": 0.7778389286369474,
      "grad_norm": 0.7372620105743408,
      "learning_rate": 4.624319257796426e-05,
      "loss": 0.539,
      "step": 2120
    },
    {
      "epoch": 0.7815079801871216,
      "grad_norm": 0.9778143167495728,
      "learning_rate": 4.618673848685586e-05,
      "loss": 0.5722,
      "step": 2130
    },
    {
      "epoch": 0.7851770317372959,
      "grad_norm": 0.6679160594940186,
      "learning_rate": 4.612989837774119e-05,
      "loss": 0.5572,
      "step": 2140
    },
    {
      "epoch": 0.7888460832874702,
      "grad_norm": 0.7771591544151306,
      "learning_rate": 4.607267328623531e-05,
      "loss": 0.5798,
      "step": 2150
    },
    {
      "epoch": 0.7925151348376445,
      "grad_norm": 0.8083762526512146,
      "learning_rate": 4.601506425496759e-05,
      "loss": 0.558,
      "step": 2160
    },
    {
      "epoch": 0.7961841863878187,
      "grad_norm": 0.9205446243286133,
      "learning_rate": 4.59570723335627e-05,
      "loss": 0.5284,
      "step": 2170
    },
    {
      "epoch": 0.799853237937993,
      "grad_norm": 0.784064531326294,
      "learning_rate": 4.589869857862148e-05,
      "loss": 0.5276,
      "step": 2180
    },
    {
      "epoch": 0.8035222894881673,
      "grad_norm": 0.7402964234352112,
      "learning_rate": 4.583994405370172e-05,
      "loss": 0.5354,
      "step": 2190
    },
    {
      "epoch": 0.8071913410383416,
      "grad_norm": 1.0059432983398438,
      "learning_rate": 4.5780809829298746e-05,
      "loss": 0.5488,
      "step": 2200
    },
    {
      "epoch": 0.8108603925885158,
      "grad_norm": 0.6676888465881348,
      "learning_rate": 4.572129698282592e-05,
      "loss": 0.553,
      "step": 2210
    },
    {
      "epoch": 0.8145294441386901,
      "grad_norm": 0.8007650375366211,
      "learning_rate": 4.566140659859505e-05,
      "loss": 0.5743,
      "step": 2220
    },
    {
      "epoch": 0.8181984956888644,
      "grad_norm": 0.9345247745513916,
      "learning_rate": 4.5601139767796586e-05,
      "loss": 0.5545,
      "step": 2230
    },
    {
      "epoch": 0.8218675472390387,
      "grad_norm": 0.7873967289924622,
      "learning_rate": 4.5540497588479746e-05,
      "loss": 0.5255,
      "step": 2240
    },
    {
      "epoch": 0.825536598789213,
      "grad_norm": 0.867009162902832,
      "learning_rate": 4.547948116553253e-05,
      "loss": 0.5429,
      "step": 2250
    },
    {
      "epoch": 0.8292056503393873,
      "grad_norm": 0.9745082259178162,
      "learning_rate": 4.541809161066159e-05,
      "loss": 0.5529,
      "step": 2260
    },
    {
      "epoch": 0.8328747018895616,
      "grad_norm": 1.0054662227630615,
      "learning_rate": 4.535633004237196e-05,
      "loss": 0.5541,
      "step": 2270
    },
    {
      "epoch": 0.8365437534397359,
      "grad_norm": 1.0356608629226685,
      "learning_rate": 4.529419758594667e-05,
      "loss": 0.5627,
      "step": 2280
    },
    {
      "epoch": 0.8402128049899101,
      "grad_norm": 0.7988411784172058,
      "learning_rate": 4.5231695373426275e-05,
      "loss": 0.5528,
      "step": 2290
    },
    {
      "epoch": 0.8438818565400844,
      "grad_norm": 0.8256310224533081,
      "learning_rate": 4.5168824543588184e-05,
      "loss": 0.5406,
      "step": 2300
    },
    {
      "epoch": 0.8475509080902587,
      "grad_norm": 0.9598526954650879,
      "learning_rate": 4.510558624192596e-05,
      "loss": 0.5512,
      "step": 2310
    },
    {
      "epoch": 0.851219959640433,
      "grad_norm": 0.7551243901252747,
      "learning_rate": 4.5041981620628414e-05,
      "loss": 0.5419,
      "step": 2320
    },
    {
      "epoch": 0.8548890111906072,
      "grad_norm": 0.8776786923408508,
      "learning_rate": 4.497801183855864e-05,
      "loss": 0.5443,
      "step": 2330
    },
    {
      "epoch": 0.8585580627407815,
      "grad_norm": 0.8410866856575012,
      "learning_rate": 4.491367806123286e-05,
      "loss": 0.5456,
      "step": 2340
    },
    {
      "epoch": 0.8622271142909558,
      "grad_norm": 0.988510012626648,
      "learning_rate": 4.4848981460799244e-05,
      "loss": 0.543,
      "step": 2350
    },
    {
      "epoch": 0.86589616584113,
      "grad_norm": 0.8719709515571594,
      "learning_rate": 4.478392321601651e-05,
      "loss": 0.542,
      "step": 2360
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 1.034745454788208,
      "learning_rate": 4.471850451223245e-05,
      "loss": 0.528,
      "step": 2370
    },
    {
      "epoch": 0.8732342689414786,
      "grad_norm": 0.8525258302688599,
      "learning_rate": 4.465272654136237e-05,
      "loss": 0.5534,
      "step": 2380
    },
    {
      "epoch": 0.8769033204916529,
      "grad_norm": 1.0630966424942017,
      "learning_rate": 4.458659050186733e-05,
      "loss": 0.5378,
      "step": 2390
    },
    {
      "epoch": 0.8805723720418271,
      "grad_norm": 1.0998499393463135,
      "learning_rate": 4.452009759873233e-05,
      "loss": 0.5527,
      "step": 2400
    },
    {
      "epoch": 0.8842414235920014,
      "grad_norm": 0.688452422618866,
      "learning_rate": 4.4453249043444364e-05,
      "loss": 0.5407,
      "step": 2410
    },
    {
      "epoch": 0.8879104751421757,
      "grad_norm": 0.8851842284202576,
      "learning_rate": 4.438604605397031e-05,
      "loss": 0.5335,
      "step": 2420
    },
    {
      "epoch": 0.8915795266923501,
      "grad_norm": 0.9860828518867493,
      "learning_rate": 4.4318489854734776e-05,
      "loss": 0.5513,
      "step": 2430
    },
    {
      "epoch": 0.8952485782425244,
      "grad_norm": 0.9076856374740601,
      "learning_rate": 4.42505816765978e-05,
      "loss": 0.5733,
      "step": 2440
    },
    {
      "epoch": 0.8989176297926986,
      "grad_norm": 0.7030923962593079,
      "learning_rate": 4.4182322756832374e-05,
      "loss": 0.5686,
      "step": 2450
    },
    {
      "epoch": 0.9025866813428729,
      "grad_norm": 1.1286635398864746,
      "learning_rate": 4.411371433910193e-05,
      "loss": 0.5851,
      "step": 2460
    },
    {
      "epoch": 0.9062557328930472,
      "grad_norm": 0.9608522057533264,
      "learning_rate": 4.404475767343772e-05,
      "loss": 0.5353,
      "step": 2470
    },
    {
      "epoch": 0.9099247844432214,
      "grad_norm": 1.1069785356521606,
      "learning_rate": 4.397545401621593e-05,
      "loss": 0.5311,
      "step": 2480
    },
    {
      "epoch": 0.9135938359933957,
      "grad_norm": 0.8005871772766113,
      "learning_rate": 4.390580463013494e-05,
      "loss": 0.5616,
      "step": 2490
    },
    {
      "epoch": 0.91726288754357,
      "grad_norm": 1.1311414241790771,
      "learning_rate": 4.383581078419219e-05,
      "loss": 0.525,
      "step": 2500
    },
    {
      "epoch": 0.91726288754357,
      "eval_loss": 0.5432298183441162,
      "eval_runtime": 241.2137,
      "eval_samples_per_second": 2.512,
      "eval_steps_per_second": 2.512,
      "step": 2500
    },
    {
      "epoch": 0.9209319390937443,
      "grad_norm": 0.9654207229614258,
      "learning_rate": 4.376547375366111e-05,
      "loss": 0.5387,
      "step": 2510
    },
    {
      "epoch": 0.9246009906439185,
      "grad_norm": 0.7038743495941162,
      "learning_rate": 4.369479482006791e-05,
      "loss": 0.5372,
      "step": 2520
    },
    {
      "epoch": 0.9282700421940928,
      "grad_norm": 0.8052876591682434,
      "learning_rate": 4.3623775271168164e-05,
      "loss": 0.5486,
      "step": 2530
    },
    {
      "epoch": 0.9319390937442671,
      "grad_norm": 0.8348866105079651,
      "learning_rate": 4.3552416400923425e-05,
      "loss": 0.5299,
      "step": 2540
    },
    {
      "epoch": 0.9356081452944414,
      "grad_norm": 0.7724452614784241,
      "learning_rate": 4.348071950947759e-05,
      "loss": 0.5268,
      "step": 2550
    },
    {
      "epoch": 0.9392771968446156,
      "grad_norm": 1.0534683465957642,
      "learning_rate": 4.340868590313324e-05,
      "loss": 0.5523,
      "step": 2560
    },
    {
      "epoch": 0.9429462483947899,
      "grad_norm": 1.1290223598480225,
      "learning_rate": 4.333631689432781e-05,
      "loss": 0.5329,
      "step": 2570
    },
    {
      "epoch": 0.9466152999449642,
      "grad_norm": 0.862647533416748,
      "learning_rate": 4.3263613801609734e-05,
      "loss": 0.541,
      "step": 2580
    },
    {
      "epoch": 0.9502843514951385,
      "grad_norm": 0.9960070252418518,
      "learning_rate": 4.319057794961437e-05,
      "loss": 0.5519,
      "step": 2590
    },
    {
      "epoch": 0.9539534030453128,
      "grad_norm": 0.9242678284645081,
      "learning_rate": 4.311721066903988e-05,
      "loss": 0.5542,
      "step": 2600
    },
    {
      "epoch": 0.9576224545954871,
      "grad_norm": 0.9528604745864868,
      "learning_rate": 4.3043513296622974e-05,
      "loss": 0.5713,
      "step": 2610
    },
    {
      "epoch": 0.9612915061456614,
      "grad_norm": 0.9879667162895203,
      "learning_rate": 4.296948717511459e-05,
      "loss": 0.5486,
      "step": 2620
    },
    {
      "epoch": 0.9649605576958357,
      "grad_norm": 0.6862794756889343,
      "learning_rate": 4.2895133653255396e-05,
      "loss": 0.4993,
      "step": 2630
    },
    {
      "epoch": 0.9686296092460099,
      "grad_norm": 0.9930823445320129,
      "learning_rate": 4.2820454085751225e-05,
      "loss": 0.5165,
      "step": 2640
    },
    {
      "epoch": 0.9722986607961842,
      "grad_norm": 0.8407339453697205,
      "learning_rate": 4.274544983324841e-05,
      "loss": 0.5392,
      "step": 2650
    },
    {
      "epoch": 0.9759677123463585,
      "grad_norm": 0.9661375880241394,
      "learning_rate": 4.267012226230894e-05,
      "loss": 0.5544,
      "step": 2660
    },
    {
      "epoch": 0.9796367638965328,
      "grad_norm": 0.7821788787841797,
      "learning_rate": 4.259447274538565e-05,
      "loss": 0.5233,
      "step": 2670
    },
    {
      "epoch": 0.983305815446707,
      "grad_norm": 0.850843608379364,
      "learning_rate": 4.251850266079712e-05,
      "loss": 0.5274,
      "step": 2680
    },
    {
      "epoch": 0.9869748669968813,
      "grad_norm": 0.9794067144393921,
      "learning_rate": 4.2442213392702635e-05,
      "loss": 0.5513,
      "step": 2690
    },
    {
      "epoch": 0.9906439185470556,
      "grad_norm": 0.8385506868362427,
      "learning_rate": 4.2365606331076925e-05,
      "loss": 0.5775,
      "step": 2700
    },
    {
      "epoch": 0.9943129700972299,
      "grad_norm": 0.9123114347457886,
      "learning_rate": 4.2288682871684857e-05,
      "loss": 0.5587,
      "step": 2710
    },
    {
      "epoch": 0.9979820216474041,
      "grad_norm": 0.7605298161506653,
      "learning_rate": 4.2211444416056e-05,
      "loss": 0.5513,
      "step": 2720
    },
    {
      "epoch": 1.0014676206200697,
      "grad_norm": 0.7635568380355835,
      "learning_rate": 4.2133892371459074e-05,
      "loss": 0.5474,
      "step": 2730
    },
    {
      "epoch": 1.005136672170244,
      "grad_norm": 0.7955774664878845,
      "learning_rate": 4.2056028150876356e-05,
      "loss": 0.5035,
      "step": 2740
    },
    {
      "epoch": 1.0088057237204182,
      "grad_norm": 0.9981663823127747,
      "learning_rate": 4.1977853172977885e-05,
      "loss": 0.5216,
      "step": 2750
    },
    {
      "epoch": 1.0124747752705925,
      "grad_norm": 0.9269798398017883,
      "learning_rate": 4.189936886209563e-05,
      "loss": 0.5254,
      "step": 2760
    },
    {
      "epoch": 1.0161438268207668,
      "grad_norm": 0.8262214660644531,
      "learning_rate": 4.182057664819757e-05,
      "loss": 0.4942,
      "step": 2770
    },
    {
      "epoch": 1.019812878370941,
      "grad_norm": 0.922914445400238,
      "learning_rate": 4.174147796686158e-05,
      "loss": 0.5553,
      "step": 2780
    },
    {
      "epoch": 1.0234819299211153,
      "grad_norm": 1.0055451393127441,
      "learning_rate": 4.1662074259249305e-05,
      "loss": 0.5247,
      "step": 2790
    },
    {
      "epoch": 1.0271509814712896,
      "grad_norm": 0.9538084864616394,
      "learning_rate": 4.158236697207996e-05,
      "loss": 0.5204,
      "step": 2800
    },
    {
      "epoch": 1.0308200330214639,
      "grad_norm": 1.0916240215301514,
      "learning_rate": 4.1502357557603856e-05,
      "loss": 0.5386,
      "step": 2810
    },
    {
      "epoch": 1.0344890845716381,
      "grad_norm": 0.9748235940933228,
      "learning_rate": 4.142204747357604e-05,
      "loss": 0.5763,
      "step": 2820
    },
    {
      "epoch": 1.0381581361218126,
      "grad_norm": 0.7713705897331238,
      "learning_rate": 4.134143818322967e-05,
      "loss": 0.5162,
      "step": 2830
    },
    {
      "epoch": 1.041827187671987,
      "grad_norm": 0.8903515338897705,
      "learning_rate": 4.1260531155249397e-05,
      "loss": 0.525,
      "step": 2840
    },
    {
      "epoch": 1.0454962392221612,
      "grad_norm": 0.9214364290237427,
      "learning_rate": 4.117932786374459e-05,
      "loss": 0.5369,
      "step": 2850
    },
    {
      "epoch": 1.0491652907723354,
      "grad_norm": 0.7038514614105225,
      "learning_rate": 4.109782978822248e-05,
      "loss": 0.5196,
      "step": 2860
    },
    {
      "epoch": 1.0528343423225097,
      "grad_norm": 0.8205967545509338,
      "learning_rate": 4.1016038413561186e-05,
      "loss": 0.5065,
      "step": 2870
    },
    {
      "epoch": 1.056503393872684,
      "grad_norm": 0.8811222314834595,
      "learning_rate": 4.093395522998269e-05,
      "loss": 0.5115,
      "step": 2880
    },
    {
      "epoch": 1.0601724454228583,
      "grad_norm": 0.8891407251358032,
      "learning_rate": 4.085158173302568e-05,
      "loss": 0.5174,
      "step": 2890
    },
    {
      "epoch": 1.0638414969730325,
      "grad_norm": 0.887023389339447,
      "learning_rate": 4.076891942351827e-05,
      "loss": 0.5155,
      "step": 2900
    },
    {
      "epoch": 1.0675105485232068,
      "grad_norm": 0.9760738611221313,
      "learning_rate": 4.068596980755071e-05,
      "loss": 0.4976,
      "step": 2910
    },
    {
      "epoch": 1.071179600073381,
      "grad_norm": 1.1278280019760132,
      "learning_rate": 4.060273439644787e-05,
      "loss": 0.5324,
      "step": 2920
    },
    {
      "epoch": 1.0748486516235554,
      "grad_norm": 0.9721632599830627,
      "learning_rate": 4.0519214706741816e-05,
      "loss": 0.4998,
      "step": 2930
    },
    {
      "epoch": 1.0785177031737296,
      "grad_norm": 1.069064974784851,
      "learning_rate": 4.0435412260144034e-05,
      "loss": 0.534,
      "step": 2940
    },
    {
      "epoch": 1.082186754723904,
      "grad_norm": 0.8873580098152161,
      "learning_rate": 4.035132858351785e-05,
      "loss": 0.4854,
      "step": 2950
    },
    {
      "epoch": 1.0858558062740782,
      "grad_norm": 0.9535754919052124,
      "learning_rate": 4.026696520885049e-05,
      "loss": 0.5328,
      "step": 2960
    },
    {
      "epoch": 1.0895248578242525,
      "grad_norm": 0.9886404871940613,
      "learning_rate": 4.0182323673225255e-05,
      "loss": 0.5672,
      "step": 2970
    },
    {
      "epoch": 1.0931939093744267,
      "grad_norm": 0.8983646631240845,
      "learning_rate": 4.009740551879347e-05,
      "loss": 0.4869,
      "step": 2980
    },
    {
      "epoch": 1.096862960924601,
      "grad_norm": 1.092265248298645,
      "learning_rate": 4.00122122927464e-05,
      "loss": 0.5259,
      "step": 2990
    },
    {
      "epoch": 1.1005320124747753,
      "grad_norm": 0.9941574335098267,
      "learning_rate": 3.9926745547287044e-05,
      "loss": 0.5286,
      "step": 3000
    },
    {
      "epoch": 1.1005320124747753,
      "eval_loss": 0.5367289781570435,
      "eval_runtime": 239.7673,
      "eval_samples_per_second": 2.527,
      "eval_steps_per_second": 2.527,
      "step": 3000
    },
    {
      "epoch": 1.1042010640249496,
      "grad_norm": 1.0637037754058838,
      "learning_rate": 3.984100683960189e-05,
      "loss": 0.546,
      "step": 3010
    },
    {
      "epoch": 1.1078701155751238,
      "grad_norm": 0.7903811931610107,
      "learning_rate": 3.97549977318325e-05,
      "loss": 0.5193,
      "step": 3020
    },
    {
      "epoch": 1.111539167125298,
      "grad_norm": 1.04246985912323,
      "learning_rate": 3.9668719791047106e-05,
      "loss": 0.4993,
      "step": 3030
    },
    {
      "epoch": 1.1152082186754724,
      "grad_norm": 1.1459685564041138,
      "learning_rate": 3.958217458921197e-05,
      "loss": 0.5275,
      "step": 3040
    },
    {
      "epoch": 1.1188772702256466,
      "grad_norm": 0.8469519019126892,
      "learning_rate": 3.949536370316285e-05,
      "loss": 0.523,
      "step": 3050
    },
    {
      "epoch": 1.122546321775821,
      "grad_norm": 0.8984081149101257,
      "learning_rate": 3.940828871457616e-05,
      "loss": 0.4932,
      "step": 3060
    },
    {
      "epoch": 1.1262153733259952,
      "grad_norm": 0.8882035613059998,
      "learning_rate": 3.932095120994025e-05,
      "loss": 0.4785,
      "step": 3070
    },
    {
      "epoch": 1.1298844248761695,
      "grad_norm": 1.0641158819198608,
      "learning_rate": 3.9233352780526446e-05,
      "loss": 0.5181,
      "step": 3080
    },
    {
      "epoch": 1.1335534764263437,
      "grad_norm": 1.1235672235488892,
      "learning_rate": 3.914549502236007e-05,
      "loss": 0.5176,
      "step": 3090
    },
    {
      "epoch": 1.137222527976518,
      "grad_norm": 1.1215784549713135,
      "learning_rate": 3.905737953619135e-05,
      "loss": 0.4993,
      "step": 3100
    },
    {
      "epoch": 1.1408915795266923,
      "grad_norm": 0.7564018964767456,
      "learning_rate": 3.8969007927466286e-05,
      "loss": 0.531,
      "step": 3110
    },
    {
      "epoch": 1.1445606310768666,
      "grad_norm": 0.898160457611084,
      "learning_rate": 3.888038180629735e-05,
      "loss": 0.5125,
      "step": 3120
    },
    {
      "epoch": 1.1482296826270408,
      "grad_norm": 1.1156057119369507,
      "learning_rate": 3.87915027874342e-05,
      "loss": 0.5102,
      "step": 3130
    },
    {
      "epoch": 1.1518987341772151,
      "grad_norm": 0.9025706648826599,
      "learning_rate": 3.870237249023424e-05,
      "loss": 0.5284,
      "step": 3140
    },
    {
      "epoch": 1.1555677857273894,
      "grad_norm": 0.9641231298446655,
      "learning_rate": 3.861299253863309e-05,
      "loss": 0.5072,
      "step": 3150
    },
    {
      "epoch": 1.1592368372775637,
      "grad_norm": 1.1992841958999634,
      "learning_rate": 3.852336456111505e-05,
      "loss": 0.5113,
      "step": 3160
    },
    {
      "epoch": 1.162905888827738,
      "grad_norm": 0.9995589256286621,
      "learning_rate": 3.843349019068338e-05,
      "loss": 0.5323,
      "step": 3170
    },
    {
      "epoch": 1.1665749403779122,
      "grad_norm": 1.133537769317627,
      "learning_rate": 3.834337106483059e-05,
      "loss": 0.5342,
      "step": 3180
    },
    {
      "epoch": 1.1702439919280865,
      "grad_norm": 0.9323656558990479,
      "learning_rate": 3.825300882550855e-05,
      "loss": 0.5328,
      "step": 3190
    },
    {
      "epoch": 1.1739130434782608,
      "grad_norm": 0.871662974357605,
      "learning_rate": 3.8162405119098646e-05,
      "loss": 0.5209,
      "step": 3200
    },
    {
      "epoch": 1.177582095028435,
      "grad_norm": 0.9234001040458679,
      "learning_rate": 3.807156159638171e-05,
      "loss": 0.5174,
      "step": 3210
    },
    {
      "epoch": 1.1812511465786095,
      "grad_norm": 1.092403769493103,
      "learning_rate": 3.7980479912507994e-05,
      "loss": 0.5018,
      "step": 3220
    },
    {
      "epoch": 1.1849201981287838,
      "grad_norm": 1.297141194343567,
      "learning_rate": 3.7889161726967006e-05,
      "loss": 0.5119,
      "step": 3230
    },
    {
      "epoch": 1.188589249678958,
      "grad_norm": 0.7372556328773499,
      "learning_rate": 3.779760870355724e-05,
      "loss": 0.5086,
      "step": 3240
    },
    {
      "epoch": 1.1922583012291323,
      "grad_norm": 0.826324999332428,
      "learning_rate": 3.7705822510355925e-05,
      "loss": 0.5023,
      "step": 3250
    },
    {
      "epoch": 1.1959273527793066,
      "grad_norm": 0.9262144565582275,
      "learning_rate": 3.7613804819688555e-05,
      "loss": 0.4995,
      "step": 3260
    },
    {
      "epoch": 1.199596404329481,
      "grad_norm": 0.9617217183113098,
      "learning_rate": 3.752155730809849e-05,
      "loss": 0.4849,
      "step": 3270
    },
    {
      "epoch": 1.2032654558796552,
      "grad_norm": 0.7965459823608398,
      "learning_rate": 3.742908165631636e-05,
      "loss": 0.5156,
      "step": 3280
    },
    {
      "epoch": 1.2069345074298294,
      "grad_norm": 1.0194956064224243,
      "learning_rate": 3.733637954922948e-05,
      "loss": 0.5094,
      "step": 3290
    },
    {
      "epoch": 1.2106035589800037,
      "grad_norm": 0.9794409275054932,
      "learning_rate": 3.724345267585112e-05,
      "loss": 0.4974,
      "step": 3300
    },
    {
      "epoch": 1.214272610530178,
      "grad_norm": 0.9531334042549133,
      "learning_rate": 3.7150302729289744e-05,
      "loss": 0.5362,
      "step": 3310
    },
    {
      "epoch": 1.2179416620803523,
      "grad_norm": 1.0231926441192627,
      "learning_rate": 3.7056931406718176e-05,
      "loss": 0.5352,
      "step": 3320
    },
    {
      "epoch": 1.2216107136305265,
      "grad_norm": 0.9047032594680786,
      "learning_rate": 3.6963340409342666e-05,
      "loss": 0.5065,
      "step": 3330
    },
    {
      "epoch": 1.2252797651807008,
      "grad_norm": 0.8732335567474365,
      "learning_rate": 3.6869531442371876e-05,
      "loss": 0.4992,
      "step": 3340
    },
    {
      "epoch": 1.228948816730875,
      "grad_norm": 1.000060796737671,
      "learning_rate": 3.6775506214985836e-05,
      "loss": 0.5386,
      "step": 3350
    },
    {
      "epoch": 1.2326178682810494,
      "grad_norm": 0.9516342282295227,
      "learning_rate": 3.668126644030482e-05,
      "loss": 0.5169,
      "step": 3360
    },
    {
      "epoch": 1.2362869198312236,
      "grad_norm": 0.9891219139099121,
      "learning_rate": 3.658681383535807e-05,
      "loss": 0.5115,
      "step": 3370
    },
    {
      "epoch": 1.239955971381398,
      "grad_norm": 0.8148437738418579,
      "learning_rate": 3.649215012105258e-05,
      "loss": 0.5023,
      "step": 3380
    },
    {
      "epoch": 1.2436250229315722,
      "grad_norm": 1.100064992904663,
      "learning_rate": 3.6397277022141694e-05,
      "loss": 0.5289,
      "step": 3390
    },
    {
      "epoch": 1.2472940744817465,
      "grad_norm": 0.722948431968689,
      "learning_rate": 3.6302196267193726e-05,
      "loss": 0.4907,
      "step": 3400
    },
    {
      "epoch": 1.2509631260319207,
      "grad_norm": 1.1131923198699951,
      "learning_rate": 3.620690958856042e-05,
      "loss": 0.5241,
      "step": 3410
    },
    {
      "epoch": 1.254632177582095,
      "grad_norm": 0.9331019520759583,
      "learning_rate": 3.61114187223454e-05,
      "loss": 0.5172,
      "step": 3420
    },
    {
      "epoch": 1.2583012291322693,
      "grad_norm": 0.8633185029029846,
      "learning_rate": 3.6015725408372565e-05,
      "loss": 0.5238,
      "step": 3430
    },
    {
      "epoch": 1.2619702806824435,
      "grad_norm": 0.8492324352264404,
      "learning_rate": 3.591983139015436e-05,
      "loss": 0.4956,
      "step": 3440
    },
    {
      "epoch": 1.2656393322326178,
      "grad_norm": 0.9706494808197021,
      "learning_rate": 3.5823738414860025e-05,
      "loss": 0.5126,
      "step": 3450
    },
    {
      "epoch": 1.269308383782792,
      "grad_norm": 1.0284154415130615,
      "learning_rate": 3.572744823328376e-05,
      "loss": 0.5023,
      "step": 3460
    },
    {
      "epoch": 1.2729774353329664,
      "grad_norm": 1.0125406980514526,
      "learning_rate": 3.56309625998128e-05,
      "loss": 0.5085,
      "step": 3470
    },
    {
      "epoch": 1.2766464868831406,
      "grad_norm": 0.9410109519958496,
      "learning_rate": 3.553428327239551e-05,
      "loss": 0.5166,
      "step": 3480
    },
    {
      "epoch": 1.280315538433315,
      "grad_norm": 0.8887771964073181,
      "learning_rate": 3.543741201250929e-05,
      "loss": 0.5128,
      "step": 3490
    },
    {
      "epoch": 1.2839845899834892,
      "grad_norm": 1.0279946327209473,
      "learning_rate": 3.534035058512851e-05,
      "loss": 0.5439,
      "step": 3500
    },
    {
      "epoch": 1.2839845899834892,
      "eval_loss": 0.5326447486877441,
      "eval_runtime": 231.1877,
      "eval_samples_per_second": 2.621,
      "eval_steps_per_second": 2.621,
      "step": 3500
    },
    {
      "epoch": 1.2876536415336637,
      "grad_norm": 0.8505242466926575,
      "learning_rate": 3.5243100758692386e-05,
      "loss": 0.4946,
      "step": 3510
    },
    {
      "epoch": 1.291322693083838,
      "grad_norm": 0.8635669946670532,
      "learning_rate": 3.514566430507268e-05,
      "loss": 0.4952,
      "step": 3520
    },
    {
      "epoch": 1.2949917446340122,
      "grad_norm": 1.0726934671401978,
      "learning_rate": 3.504804299954149e-05,
      "loss": 0.5287,
      "step": 3530
    },
    {
      "epoch": 1.2986607961841865,
      "grad_norm": 0.9249968528747559,
      "learning_rate": 3.495023862073887e-05,
      "loss": 0.5158,
      "step": 3540
    },
    {
      "epoch": 1.3023298477343608,
      "grad_norm": 1.1182197332382202,
      "learning_rate": 3.485225295064044e-05,
      "loss": 0.5082,
      "step": 3550
    },
    {
      "epoch": 1.305998899284535,
      "grad_norm": 1.0571675300598145,
      "learning_rate": 3.4754087774524905e-05,
      "loss": 0.5325,
      "step": 3560
    },
    {
      "epoch": 1.3096679508347093,
      "grad_norm": 1.2827324867248535,
      "learning_rate": 3.465574488094152e-05,
      "loss": 0.5439,
      "step": 3570
    },
    {
      "epoch": 1.3133370023848836,
      "grad_norm": 0.8562873005867004,
      "learning_rate": 3.455722606167754e-05,
      "loss": 0.4925,
      "step": 3580
    },
    {
      "epoch": 1.3170060539350579,
      "grad_norm": 1.012946367263794,
      "learning_rate": 3.4458533111725515e-05,
      "loss": 0.5304,
      "step": 3590
    },
    {
      "epoch": 1.3206751054852321,
      "grad_norm": 0.8904183506965637,
      "learning_rate": 3.435966782925066e-05,
      "loss": 0.5034,
      "step": 3600
    },
    {
      "epoch": 1.3243441570354064,
      "grad_norm": 1.0000728368759155,
      "learning_rate": 3.4260632015558047e-05,
      "loss": 0.4989,
      "step": 3610
    },
    {
      "epoch": 1.3280132085855807,
      "grad_norm": 0.8009348511695862,
      "learning_rate": 3.4161427475059745e-05,
      "loss": 0.5217,
      "step": 3620
    },
    {
      "epoch": 1.331682260135755,
      "grad_norm": 1.1289713382720947,
      "learning_rate": 3.406205601524205e-05,
      "loss": 0.5382,
      "step": 3630
    },
    {
      "epoch": 1.3353513116859292,
      "grad_norm": 0.9382407665252686,
      "learning_rate": 3.3962519446632454e-05,
      "loss": 0.5194,
      "step": 3640
    },
    {
      "epoch": 1.3390203632361035,
      "grad_norm": 1.0790501832962036,
      "learning_rate": 3.3862819582766714e-05,
      "loss": 0.5341,
      "step": 3650
    },
    {
      "epoch": 1.3426894147862778,
      "grad_norm": 0.9315184950828552,
      "learning_rate": 3.376295824015581e-05,
      "loss": 0.4932,
      "step": 3660
    },
    {
      "epoch": 1.346358466336452,
      "grad_norm": 0.8551687598228455,
      "learning_rate": 3.366293723825278e-05,
      "loss": 0.5172,
      "step": 3670
    },
    {
      "epoch": 1.3500275178866263,
      "grad_norm": 0.8260353803634644,
      "learning_rate": 3.356275839941967e-05,
      "loss": 0.5142,
      "step": 3680
    },
    {
      "epoch": 1.3536965694368006,
      "grad_norm": 1.059957504272461,
      "learning_rate": 3.346242354889427e-05,
      "loss": 0.4911,
      "step": 3690
    },
    {
      "epoch": 1.3573656209869749,
      "grad_norm": 0.8368703126907349,
      "learning_rate": 3.336193451475685e-05,
      "loss": 0.5271,
      "step": 3700
    },
    {
      "epoch": 1.3610346725371492,
      "grad_norm": 0.8385125994682312,
      "learning_rate": 3.326129312789692e-05,
      "loss": 0.5201,
      "step": 3710
    },
    {
      "epoch": 1.3647037240873234,
      "grad_norm": 0.8766797780990601,
      "learning_rate": 3.316050122197977e-05,
      "loss": 0.5174,
      "step": 3720
    },
    {
      "epoch": 1.3683727756374977,
      "grad_norm": 0.8743470907211304,
      "learning_rate": 3.305956063341314e-05,
      "loss": 0.5369,
      "step": 3730
    },
    {
      "epoch": 1.372041827187672,
      "grad_norm": 0.9249287247657776,
      "learning_rate": 3.2958473201313744e-05,
      "loss": 0.5125,
      "step": 3740
    },
    {
      "epoch": 1.3757108787378463,
      "grad_norm": 0.8530007004737854,
      "learning_rate": 3.285724076747375e-05,
      "loss": 0.4865,
      "step": 3750
    },
    {
      "epoch": 1.3793799302880205,
      "grad_norm": 1.0500656366348267,
      "learning_rate": 3.275586517632724e-05,
      "loss": 0.5127,
      "step": 3760
    },
    {
      "epoch": 1.3830489818381948,
      "grad_norm": 0.9515796899795532,
      "learning_rate": 3.2654348274916566e-05,
      "loss": 0.4799,
      "step": 3770
    },
    {
      "epoch": 1.386718033388369,
      "grad_norm": 0.7839356064796448,
      "learning_rate": 3.255269191285874e-05,
      "loss": 0.5155,
      "step": 3780
    },
    {
      "epoch": 1.3903870849385433,
      "grad_norm": 1.1705440282821655,
      "learning_rate": 3.245089794231171e-05,
      "loss": 0.533,
      "step": 3790
    },
    {
      "epoch": 1.3940561364887176,
      "grad_norm": 0.935599684715271,
      "learning_rate": 3.2348968217940626e-05,
      "loss": 0.5146,
      "step": 3800
    },
    {
      "epoch": 1.397725188038892,
      "grad_norm": 1.0857276916503906,
      "learning_rate": 3.224690459688406e-05,
      "loss": 0.5061,
      "step": 3810
    },
    {
      "epoch": 1.4013942395890662,
      "grad_norm": 0.9415270686149597,
      "learning_rate": 3.214470893872015e-05,
      "loss": 0.5311,
      "step": 3820
    },
    {
      "epoch": 1.4050632911392404,
      "grad_norm": 0.9964818954467773,
      "learning_rate": 3.2042383105432695e-05,
      "loss": 0.4809,
      "step": 3830
    },
    {
      "epoch": 1.4087323426894147,
      "grad_norm": 0.92458176612854,
      "learning_rate": 3.193992896137728e-05,
      "loss": 0.4953,
      "step": 3840
    },
    {
      "epoch": 1.412401394239589,
      "grad_norm": 0.947990357875824,
      "learning_rate": 3.183734837324727e-05,
      "loss": 0.5165,
      "step": 3850
    },
    {
      "epoch": 1.4160704457897633,
      "grad_norm": 0.9327725172042847,
      "learning_rate": 3.1734643210039855e-05,
      "loss": 0.5266,
      "step": 3860
    },
    {
      "epoch": 1.4197394973399375,
      "grad_norm": 1.0861709117889404,
      "learning_rate": 3.163181534302192e-05,
      "loss": 0.5147,
      "step": 3870
    },
    {
      "epoch": 1.4234085488901118,
      "grad_norm": 1.0089092254638672,
      "learning_rate": 3.152886664569598e-05,
      "loss": 0.5113,
      "step": 3880
    },
    {
      "epoch": 1.427077600440286,
      "grad_norm": 0.9725763201713562,
      "learning_rate": 3.142579899376609e-05,
      "loss": 0.5156,
      "step": 3890
    },
    {
      "epoch": 1.4307466519904604,
      "grad_norm": 0.9345846772193909,
      "learning_rate": 3.132261426510361e-05,
      "loss": 0.5251,
      "step": 3900
    },
    {
      "epoch": 1.4344157035406346,
      "grad_norm": 0.9671109318733215,
      "learning_rate": 3.121931433971302e-05,
      "loss": 0.5233,
      "step": 3910
    },
    {
      "epoch": 1.438084755090809,
      "grad_norm": 0.8192123770713806,
      "learning_rate": 3.1115901099697656e-05,
      "loss": 0.4956,
      "step": 3920
    },
    {
      "epoch": 1.4417538066409832,
      "grad_norm": 0.8485032320022583,
      "learning_rate": 3.1012376429225424e-05,
      "loss": 0.5077,
      "step": 3930
    },
    {
      "epoch": 1.4454228581911575,
      "grad_norm": 0.9765728116035461,
      "learning_rate": 3.090874221449448e-05,
      "loss": 0.5118,
      "step": 3940
    },
    {
      "epoch": 1.4490919097413317,
      "grad_norm": 0.8579782247543335,
      "learning_rate": 3.080500034369883e-05,
      "loss": 0.5258,
      "step": 3950
    },
    {
      "epoch": 1.4527609612915062,
      "grad_norm": 0.8543968200683594,
      "learning_rate": 3.0701152706993985e-05,
      "loss": 0.506,
      "step": 3960
    },
    {
      "epoch": 1.4564300128416805,
      "grad_norm": 0.908636212348938,
      "learning_rate": 3.0597201196462463e-05,
      "loss": 0.5093,
      "step": 3970
    },
    {
      "epoch": 1.4600990643918548,
      "grad_norm": 1.1897763013839722,
      "learning_rate": 3.049314770607935e-05,
      "loss": 0.5117,
      "step": 3980
    },
    {
      "epoch": 1.463768115942029,
      "grad_norm": 0.8877365589141846,
      "learning_rate": 3.0388994131677784e-05,
      "loss": 0.5355,
      "step": 3990
    },
    {
      "epoch": 1.4674371674922033,
      "grad_norm": 1.057456135749817,
      "learning_rate": 3.0284742370914403e-05,
      "loss": 0.5437,
      "step": 4000
    },
    {
      "epoch": 1.4674371674922033,
      "eval_loss": 0.527490496635437,
      "eval_runtime": 232.7571,
      "eval_samples_per_second": 2.604,
      "eval_steps_per_second": 2.604,
      "step": 4000
    },
    {
      "epoch": 1.4711062190423776,
      "grad_norm": 0.9717181324958801,
      "learning_rate": 3.0180394323234813e-05,
      "loss": 0.5174,
      "step": 4010
    },
    {
      "epoch": 1.4747752705925519,
      "grad_norm": 0.9128007292747498,
      "learning_rate": 3.0075951889838917e-05,
      "loss": 0.5422,
      "step": 4020
    },
    {
      "epoch": 1.4784443221427261,
      "grad_norm": 0.9310988783836365,
      "learning_rate": 2.9971416973646293e-05,
      "loss": 0.5082,
      "step": 4030
    },
    {
      "epoch": 1.4821133736929004,
      "grad_norm": 0.9611682295799255,
      "learning_rate": 2.9866791479261584e-05,
      "loss": 0.5054,
      "step": 4040
    },
    {
      "epoch": 1.4857824252430747,
      "grad_norm": 1.0387334823608398,
      "learning_rate": 2.976207731293971e-05,
      "loss": 0.5022,
      "step": 4050
    },
    {
      "epoch": 1.489451476793249,
      "grad_norm": 1.3275202512741089,
      "learning_rate": 2.9657276382551185e-05,
      "loss": 0.5064,
      "step": 4060
    },
    {
      "epoch": 1.4931205283434232,
      "grad_norm": 0.9811340570449829,
      "learning_rate": 2.955239059754737e-05,
      "loss": 0.4846,
      "step": 4070
    },
    {
      "epoch": 1.4967895798935975,
      "grad_norm": 0.9878092408180237,
      "learning_rate": 2.944742186892561e-05,
      "loss": 0.4749,
      "step": 4080
    },
    {
      "epoch": 1.5004586314437718,
      "grad_norm": 0.8789183497428894,
      "learning_rate": 2.9342372109194516e-05,
      "loss": 0.5037,
      "step": 4090
    },
    {
      "epoch": 1.504127682993946,
      "grad_norm": 0.9945605397224426,
      "learning_rate": 2.923724323233904e-05,
      "loss": 0.5306,
      "step": 4100
    },
    {
      "epoch": 1.5077967345441203,
      "grad_norm": 1.070317029953003,
      "learning_rate": 2.9132037153785634e-05,
      "loss": 0.5195,
      "step": 4110
    },
    {
      "epoch": 1.5114657860942946,
      "grad_norm": 1.0403907299041748,
      "learning_rate": 2.9026755790367376e-05,
      "loss": 0.5076,
      "step": 4120
    },
    {
      "epoch": 1.5151348376444689,
      "grad_norm": 0.9972668886184692,
      "learning_rate": 2.8921401060288966e-05,
      "loss": 0.4863,
      "step": 4130
    },
    {
      "epoch": 1.5188038891946432,
      "grad_norm": 0.9783010482788086,
      "learning_rate": 2.8815974883091884e-05,
      "loss": 0.5068,
      "step": 4140
    },
    {
      "epoch": 1.5224729407448174,
      "grad_norm": 1.2028930187225342,
      "learning_rate": 2.871047917961933e-05,
      "loss": 0.5217,
      "step": 4150
    },
    {
      "epoch": 1.5261419922949917,
      "grad_norm": 1.1120834350585938,
      "learning_rate": 2.8604915871981265e-05,
      "loss": 0.5138,
      "step": 4160
    },
    {
      "epoch": 1.529811043845166,
      "grad_norm": 1.0339429378509521,
      "learning_rate": 2.8499286883519398e-05,
      "loss": 0.5128,
      "step": 4170
    },
    {
      "epoch": 1.5334800953953405,
      "grad_norm": 1.006658911705017,
      "learning_rate": 2.83935941387721e-05,
      "loss": 0.497,
      "step": 4180
    },
    {
      "epoch": 1.5371491469455147,
      "grad_norm": 0.9148851037025452,
      "learning_rate": 2.8287839563439395e-05,
      "loss": 0.4922,
      "step": 4190
    },
    {
      "epoch": 1.540818198495689,
      "grad_norm": 0.854830265045166,
      "learning_rate": 2.8182025084347836e-05,
      "loss": 0.5055,
      "step": 4200
    },
    {
      "epoch": 1.5444872500458633,
      "grad_norm": 1.1474218368530273,
      "learning_rate": 2.8076152629415403e-05,
      "loss": 0.5061,
      "step": 4210
    },
    {
      "epoch": 1.5481563015960376,
      "grad_norm": 1.024875521659851,
      "learning_rate": 2.797022412761641e-05,
      "loss": 0.5323,
      "step": 4220
    },
    {
      "epoch": 1.5518253531462118,
      "grad_norm": 0.9536452293395996,
      "learning_rate": 2.7864241508946305e-05,
      "loss": 0.5162,
      "step": 4230
    },
    {
      "epoch": 1.5554944046963861,
      "grad_norm": 0.8775179386138916,
      "learning_rate": 2.7758206704386545e-05,
      "loss": 0.4977,
      "step": 4240
    },
    {
      "epoch": 1.5591634562465604,
      "grad_norm": 0.9244831204414368,
      "learning_rate": 2.7652121645869412e-05,
      "loss": 0.5094,
      "step": 4250
    },
    {
      "epoch": 1.5628325077967347,
      "grad_norm": 0.9842005372047424,
      "learning_rate": 2.7545988266242785e-05,
      "loss": 0.5158,
      "step": 4260
    },
    {
      "epoch": 1.566501559346909,
      "grad_norm": 1.0604709386825562,
      "learning_rate": 2.7439808499234957e-05,
      "loss": 0.5062,
      "step": 4270
    },
    {
      "epoch": 1.5701706108970832,
      "grad_norm": 1.0026077032089233,
      "learning_rate": 2.73335842794194e-05,
      "loss": 0.5217,
      "step": 4280
    },
    {
      "epoch": 1.5738396624472575,
      "grad_norm": 0.9699780344963074,
      "learning_rate": 2.7227317542179477e-05,
      "loss": 0.5211,
      "step": 4290
    },
    {
      "epoch": 1.5775087139974318,
      "grad_norm": 1.0255078077316284,
      "learning_rate": 2.7121010223673237e-05,
      "loss": 0.528,
      "step": 4300
    },
    {
      "epoch": 1.581177765547606,
      "grad_norm": 0.9601745009422302,
      "learning_rate": 2.7014664260798096e-05,
      "loss": 0.5243,
      "step": 4310
    },
    {
      "epoch": 1.5848468170977803,
      "grad_norm": 1.0979671478271484,
      "learning_rate": 2.6908281591155572e-05,
      "loss": 0.522,
      "step": 4320
    },
    {
      "epoch": 1.5885158686479546,
      "grad_norm": 1.161711573600769,
      "learning_rate": 2.6801864153015977e-05,
      "loss": 0.5091,
      "step": 4330
    },
    {
      "epoch": 1.5921849201981289,
      "grad_norm": 1.0911256074905396,
      "learning_rate": 2.6695413885283065e-05,
      "loss": 0.4858,
      "step": 4340
    },
    {
      "epoch": 1.5958539717483031,
      "grad_norm": 0.8395224213600159,
      "learning_rate": 2.6588932727458786e-05,
      "loss": 0.5005,
      "step": 4350
    },
    {
      "epoch": 1.5995230232984774,
      "grad_norm": 1.23264741897583,
      "learning_rate": 2.648242261960786e-05,
      "loss": 0.4969,
      "step": 4360
    },
    {
      "epoch": 1.6031920748486517,
      "grad_norm": 0.9221340417861938,
      "learning_rate": 2.6375885502322506e-05,
      "loss": 0.5152,
      "step": 4370
    },
    {
      "epoch": 1.606861126398826,
      "grad_norm": 0.83207768201828,
      "learning_rate": 2.6269323316687027e-05,
      "loss": 0.4855,
      "step": 4380
    },
    {
      "epoch": 1.6105301779490002,
      "grad_norm": 1.1201894283294678,
      "learning_rate": 2.616273800424246e-05,
      "loss": 0.5117,
      "step": 4390
    },
    {
      "epoch": 1.6141992294991745,
      "grad_norm": 1.1243469715118408,
      "learning_rate": 2.6056131506951232e-05,
      "loss": 0.4911,
      "step": 4400
    },
    {
      "epoch": 1.6178682810493488,
      "grad_norm": 0.9399608969688416,
      "learning_rate": 2.5949505767161725e-05,
      "loss": 0.5151,
      "step": 4410
    },
    {
      "epoch": 1.621537332599523,
      "grad_norm": 1.1602848768234253,
      "learning_rate": 2.584286272757295e-05,
      "loss": 0.5065,
      "step": 4420
    },
    {
      "epoch": 1.6252063841496973,
      "grad_norm": 1.1268662214279175,
      "learning_rate": 2.5736204331199088e-05,
      "loss": 0.4974,
      "step": 4430
    },
    {
      "epoch": 1.6288754356998716,
      "grad_norm": 0.9943903088569641,
      "learning_rate": 2.5629532521334115e-05,
      "loss": 0.5169,
      "step": 4440
    },
    {
      "epoch": 1.6325444872500459,
      "grad_norm": 0.9009532928466797,
      "learning_rate": 2.552284924151642e-05,
      "loss": 0.5044,
      "step": 4450
    },
    {
      "epoch": 1.6362135388002201,
      "grad_norm": 1.0662145614624023,
      "learning_rate": 2.5416156435493366e-05,
      "loss": 0.5007,
      "step": 4460
    },
    {
      "epoch": 1.6398825903503944,
      "grad_norm": 1.0880720615386963,
      "learning_rate": 2.5309456047185876e-05,
      "loss": 0.5265,
      "step": 4470
    },
    {
      "epoch": 1.6435516419005687,
      "grad_norm": 0.9624683856964111,
      "learning_rate": 2.5202750020653027e-05,
      "loss": 0.5174,
      "step": 4480
    },
    {
      "epoch": 1.647220693450743,
      "grad_norm": 0.817380964756012,
      "learning_rate": 2.50960403000566e-05,
      "loss": 0.4912,
      "step": 4490
    },
    {
      "epoch": 1.6508897450009172,
      "grad_norm": 1.1110498905181885,
      "learning_rate": 2.4989328829625713e-05,
      "loss": 0.5092,
      "step": 4500
    },
    {
      "epoch": 1.6508897450009172,
      "eval_loss": 0.5229318737983704,
      "eval_runtime": 231.3578,
      "eval_samples_per_second": 2.619,
      "eval_steps_per_second": 2.619,
      "step": 4500
    }
  ],
  "logging_steps": 10,
  "max_steps": 8178,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.454944400297165e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
